#!/usr/bin/env python3
"""
æ€§èƒ½ç›‘æ§å’Œç®¡ç†è„šæœ¬
æä¾›ç³»ç»Ÿæ€§èƒ½ç›‘æ§ã€ç¼“å­˜ç®¡ç†å’Œæ€§èƒ½ä¼˜åŒ–å·¥å…·
"""

import asyncio
import argparse
import json
import time
from datetime import datetime, timedelta
from typing import Dict, Any, Optional
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.core.config import get_settings
from src.core.monitoring import get_metrics_collector, get_system_collector
from src.core.security import get_rate_limiter
from src.core.performance import get_query_cache, get_query_monitor, get_database_optimizer
from src.core.database import get_db
from src.utils.cache import cache_manager


settings = get_settings()


class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§ç®¡ç†å™¨"""

    def __init__(self):
        self.metrics_collector = get_metrics_collector()
        self.rate_limiter = get_rate_limiter()
        self.query_cache = get_query_cache()
        self.query_monitor = get_query_monitor()
        self.db_optimizer = get_database_optimizer()

    async def show_system_status(self):
        """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ"""
        print("=" * 80)
        print("ç³»ç»Ÿæ€§èƒ½çŠ¶æ€æ¦‚è§ˆ")
        print("=" * 80)
        print(f"æ£€æŸ¥æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ç¯å¢ƒ: {settings.ENVIRONMENT}")
        print(f"æ€§èƒ½ç›‘æ§: {'å¯ç”¨' if settings.ENABLE_METRICS else 'ç¦ç”¨'}")
        print(f"é™æµåŠŸèƒ½: {'å¯ç”¨' if settings.RATE_LIMIT_ENABLED else 'ç¦ç”¨'}")

        # ç³»ç»ŸæŒ‡æ ‡
        print("\nç³»ç»ŸæŒ‡æ ‡:")
        print("-" * 40)
        system_stats = self.metrics_collector.get_system_stats()
        print(f"CPUä½¿ç”¨ç‡: {system_stats.get('cpu_percent', 0):.1f}%")
        print(f"å†…å­˜ä½¿ç”¨ç‡: {system_stats.get('memory_percent', 0):.1f}%")
        print(f"ç£ç›˜ä½¿ç”¨ç‡: {system_stats.get('disk_usage_percent', 0):.1f}%")
        print(f"æ´»è·ƒè¿æ¥æ•°: {system_stats.get('active_connections', 0)}")
        print(f"è¿è¡Œæ—¶é—´: {system_stats.get('uptime_seconds', 0):.0f}ç§’")

        # è¯·æ±‚ç»Ÿè®¡
        print("\nè¯·æ±‚ç»Ÿè®¡ (æœ€è¿‘1å°æ—¶):")
        print("-" * 40)
        request_stats = self.metrics_collector.get_request_stats(minutes=60)
        print(f"æ€»è¯·æ±‚æ•°: {request_stats['total_requests']}")
        print(f"å¹³å‡å“åº”æ—¶é—´: {request_stats['avg_response_time']:.3f}s")
        print(f"æœ€å°å“åº”æ—¶é—´: {request_stats['min_response_time']:.3f}s")
        print(f"æœ€å¤§å“åº”æ—¶é—´: {request_stats['max_response_time']:.3f}s")
        print(f"é”™è¯¯ç‡: {request_stats['error_rate']:.2f}%")
        print(f"è¯·æ±‚é¢‘ç‡: {request_stats['requests_per_minute']:.2f} req/min")

        # ç¼“å­˜ç»Ÿè®¡
        print("\nç¼“å­˜ç»Ÿè®¡:")
        print("-" * 40)
        cache_stats = self.query_cache.get_stats()
        print(f"ç¼“å­˜å‘½ä¸­æ•°: {cache_stats['hit_count']}")
        print(f"ç¼“å­˜æœªå‘½ä¸­æ•°: {cache_stats['miss_count']}")
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:.2f}%")
        print(f"ç¼“å­˜æ¡ç›®æ•°: {cache_stats['cached_entries']}")

        # é™æµç»Ÿè®¡
        print("\né™æµç»Ÿè®¡:")
        print("-" * 40)
        print(f"æ´»è·ƒé™æµè®¡æ•°å™¨: {len(self.rate_limiter.counters)}")
        print(f"æ´»è·ƒä»¤ç‰Œæ¡¶: {len(self.rate_limiter.buckets)}")
        print(f"é™æµè§„åˆ™æ•°: {len(self.rate_limiter.rules)}")

        print("=" * 80)

    async def show_performance_details(self):
        """æ˜¾ç¤ºè¯¦ç»†æ€§èƒ½ä¿¡æ¯"""
        print("=" * 80)
        print("è¯¦ç»†æ€§èƒ½åˆ†æ")
        print("=" * 80)

        # æ€§èƒ½æ€»ç»“
        performance_summary = self.metrics_collector.get_performance_summary()

        print("\næœ€æ…¢çš„ç«¯ç‚¹:")
        print("-" * 40)
        slowest_endpoints = performance_summary.get('slowest_endpoints', [])
        if slowest_endpoints:
            for i, endpoint in enumerate(slowest_endpoints[:10], 1):
                print(f"{i:2d}. {endpoint['path']} - {endpoint['avg_response_time']:.3f}s")
        else:
            print("æš‚æ— æ•°æ®")

        print("\né”™è¯¯ç‡æœ€é«˜çš„ç«¯ç‚¹:")
        print("-" * 40)
        error_endpoints = performance_summary.get('error_endpoints', [])
        if error_endpoints:
            for i, endpoint in enumerate(error_endpoints[:10], 1):
                print(f"{i:2d}. {endpoint['path']} - {endpoint['error_rate']:.2f}%")
        else:
            print("æš‚æ— é”™è¯¯")

        # æŸ¥è¯¢æ€§èƒ½
        print("\næ•°æ®åº“æŸ¥è¯¢ç»Ÿè®¡:")
        print("-" * 40)
        query_stats = self.query_monitor.get_query_stats()
        print(f"æ€»æŸ¥è¯¢æ•°: {query_stats['total_queries']}")
        print(f"å¹³å‡æ‰§è¡Œæ—¶é—´: {query_stats['avg_execution_time']:.3f}s")
        print(f"ç¼“å­˜å‘½ä¸­ç‡: {query_stats['cache_hit_rate']:.2f}%")

        if query_stats.get('query_types'):
            print("\næŸ¥è¯¢ç±»å‹åˆ†å¸ƒ:")
            for query_type, count in query_stats['query_types'].items():
                print(f"  {query_type}: {count}")

        if query_stats.get('table_activity'):
            print("\nè¡¨æ´»è·ƒåº¦ (å‰10):")
            for table, count in list(query_stats['table_activity'].items())[:10]:
                print(f"  {table}: {count}")

        # æ…¢æŸ¥è¯¢
        print("\næ…¢æŸ¥è¯¢ (å‰5):")
        print("-" * 40)
        slow_queries = self.query_monitor.get_slow_queries(limit=5)
        if slow_queries:
            for i, sq in enumerate(slow_queries, 1):
                print(f"{i}. æ‰§è¡Œæ—¶é—´: {sq['execution_time']:.3f}s, æ¬¡æ•°: {sq['count']}")
                print(f"   æŸ¥è¯¢: {sq['query'][:100]}...")
                print()
        else:
            print("æš‚æ— æ…¢æŸ¥è¯¢")

        print("=" * 80)

    async def show_optimization_suggestions(self):
        """æ˜¾ç¤ºä¼˜åŒ–å»ºè®®"""
        print("=" * 80)
        print("æ€§èƒ½ä¼˜åŒ–å»ºè®®")
        print("=" * 80)

        # è·å–æ•°æ®åº“ä¼˜åŒ–åˆ†æ
        analysis = None
        try:
            async for db in get_db():
                analysis = await self.db_optimizer.analyze_performance(db)
                break
        except Exception as e:
            print(f"æ— æ³•è¿æ¥æ•°æ®åº“è¿›è¡Œåˆ†æ: {e}")
            return

        suggestions = analysis.get('optimization_suggestions', []) if analysis else []

        if not suggestions:
            print("âœ… å½“å‰ç³»ç»Ÿæ€§èƒ½è‰¯å¥½ï¼Œæš‚æ— ä¼˜åŒ–å»ºè®®")
        else:
            print(f"å‘ç° {len(suggestions)} ä¸ªä¼˜åŒ–å»ºè®®:")
            print()

            for i, suggestion in enumerate(suggestions, 1):
                priority_icon = {
                    'high': 'ğŸ”´',
                    'medium': 'ğŸŸ¡',
                    'low': 'ğŸŸ¢'
                }.get(suggestion.get('priority', 'medium'), 'âšª')

                print(f"{i}. {priority_icon} [{suggestion.get('priority', 'medium').upper()}] {suggestion.get('type', 'general').upper()}")
                print(f"   {suggestion.get('message', '')}")

                if suggestion.get('details'):
                    print("   è¯¦æƒ…:")
                    for detail in suggestion['details'][:3]:
                        print(f"     - {detail}")
                print()

        print("=" * 80)

    async def clear_cache(self, cache_type: str = "all"):
        """æ¸…ç†ç¼“å­˜"""
        print(f"æ¸…ç†ç¼“å­˜: {cache_type}")

        if cache_type in ["all", "query"]:
            await self.query_cache.clear_all()
            print("âœ… æŸ¥è¯¢ç¼“å­˜å·²æ¸…ç†")

        if cache_type in ["all", "redis"]:
            try:
                # æ¸…ç†Redisç¼“å­˜
                pattern = f"{cache_manager.prefix}:*"
                keys = await cache_manager.redis_client.keys(pattern) if hasattr(cache_manager, 'redis_client') else []
                if keys:
                    for key in keys:
                        await cache_manager.delete(key)
                    print(f"âœ… Redisç¼“å­˜å·²æ¸…ç† ({len(keys)} ä¸ªé”®)")
                else:
                    print("âœ… Redisç¼“å­˜ä¸ºç©º")
            except Exception as e:
                print(f"âŒ æ¸…ç†Redisç¼“å­˜å¤±è´¥: {e}")

        if cache_type in ["all", "metrics"]:
            self.metrics_collector.clear_old_metrics(hours=0)
            print("âœ… ç›‘æ§æŒ‡æ ‡å·²æ¸…ç†")

        if cache_type in ["all", "slow_queries"]:
            self.query_monitor.clear_slow_queries()
            print("âœ… æ…¢æŸ¥è¯¢è®°å½•å·²æ¸…ç†")

    async def cleanup_old_data(self, hours: int = 24):
        """æ¸…ç†æ—§æ•°æ®"""
        print(f"æ¸…ç† {hours} å°æ—¶å‰çš„æ—§æ•°æ®...")

        # æ¸…ç†æ—§çš„ç›‘æ§æ•°æ®
        self.metrics_collector.clear_old_metrics(hours=hours)

        # æ¸…ç†æ—§çš„é™æµè®¡æ•°å™¨
        self.rate_limiter.cleanup_old_counters()

        print("âœ… æ—§æ•°æ®æ¸…ç†å®Œæˆ")

    async def export_metrics(self, output_file: str | None = None):
        """å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡"""
        if not output_file:
            output_file = f"performance_metrics_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"

        print(f"å¯¼å‡ºæ€§èƒ½æŒ‡æ ‡åˆ°: {output_file}")

        # æ”¶é›†æ‰€æœ‰æŒ‡æ ‡
        metrics_data = {
            'timestamp': datetime.now().isoformat(),
            'system_stats': self.metrics_collector.get_system_stats(),
            'request_stats': self.metrics_collector.get_request_stats(),
            'path_stats': self.metrics_collector.get_path_stats(),
            'cache_stats': self.query_cache.get_stats(),
            'query_stats': self.query_monitor.get_query_stats(),
            'slow_queries': self.query_monitor.get_slow_queries(limit=20),
            'rate_limit_info': {
                'active_counters': len(self.rate_limiter.counters),
                'active_buckets': len(self.rate_limiter.buckets),
                'rules_count': len(self.rate_limiter.rules)
            }
        }

        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(metrics_data, f, indent=2, ensure_ascii=False, default=str)
            print(f"âœ… æŒ‡æ ‡å¯¼å‡ºå®Œæˆ: {output_file}")
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")

    async def monitor_real_time(self, duration: int = 60, interval: int = 5):
        """å®æ—¶ç›‘æ§"""
        print(f"å¼€å§‹å®æ—¶ç›‘æ§ (æŒç»­ {duration} ç§’, æ¯ {interval} ç§’æ›´æ–°)")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        print("=" * 80)

        start_time = time.time()

        try:
            while time.time() - start_time < duration:
                # æ¸…å± (åœ¨æ”¯æŒçš„ç»ˆç«¯ä¸Š)
                os.system('clear' if os.name == 'posix' else 'cls')

                # æ˜¾ç¤ºå®æ—¶çŠ¶æ€
                print(f"å®æ—¶ç›‘æ§ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                print("=" * 50)

                # ç³»ç»Ÿèµ„æº
                system_stats = self.metrics_collector.get_system_stats()
                print(f"CPU: {system_stats.get('cpu_percent', 0):5.1f}% | ", end="")
                print(f"å†…å­˜: {system_stats.get('memory_percent', 0):5.1f}% | ", end="")
                print(f"æ´»è·ƒè¿æ¥: {system_stats.get('active_connections', 0):3d}")

                # æœ€è¿‘è¯·æ±‚ç»Ÿè®¡
                recent_stats = self.metrics_collector.get_request_stats(minutes=1)
                print(f"è¯·æ±‚/åˆ†é’Ÿ: {recent_stats['requests_per_minute']:6.1f} | ", end="")
                print(f"å¹³å‡å“åº”æ—¶é—´: {recent_stats['avg_response_time']:6.3f}s | ", end="")
                print(f"é”™è¯¯ç‡: {recent_stats['error_rate']:5.2f}%")

                # ç¼“å­˜çŠ¶æ€
                cache_stats = self.query_cache.get_stats()
                print(f"ç¼“å­˜å‘½ä¸­ç‡: {cache_stats['hit_rate']:5.1f}% | ", end="")
                print(f"ç¼“å­˜æ¡ç›®: {cache_stats['cached_entries']:4d}")

                print("-" * 50)

                await asyncio.sleep(interval)

        except KeyboardInterrupt:
            print("\nç›‘æ§å·²åœæ­¢")

    async def health_check(self):
        """å¥åº·æ£€æŸ¥"""
        print("æ‰§è¡Œç³»ç»Ÿå¥åº·æ£€æŸ¥...")
        print("=" * 60)

        checks = []

        # æ£€æŸ¥ç³»ç»Ÿèµ„æº
        system_stats = self.metrics_collector.get_system_stats()
        cpu_usage = system_stats.get('cpu_percent', 0)
        memory_usage = system_stats.get('memory_percent', 0)

        checks.append({
            'name': 'CPUä½¿ç”¨ç‡',
            'status': 'OK' if cpu_usage < 80 else 'WARNING' if cpu_usage < 95 else 'CRITICAL',
            'value': f"{cpu_usage:.1f}%",
            'threshold': '< 80% (OK), < 95% (WARNING)'
        })

        checks.append({
            'name': 'å†…å­˜ä½¿ç”¨ç‡',
            'status': 'OK' if memory_usage < 80 else 'WARNING' if memory_usage < 95 else 'CRITICAL',
            'value': f"{memory_usage:.1f}%",
            'threshold': '< 80% (OK), < 95% (WARNING)'
        })

        # æ£€æŸ¥å“åº”æ—¶é—´
        request_stats = self.metrics_collector.get_request_stats(minutes=60)
        avg_response_time = request_stats['avg_response_time']

        checks.append({
            'name': 'å¹³å‡å“åº”æ—¶é—´',
            'status': 'OK' if avg_response_time < 1.0 else 'WARNING' if avg_response_time < 3.0 else 'CRITICAL',
            'value': f"{avg_response_time:.3f}s",
            'threshold': '< 1.0s (OK), < 3.0s (WARNING)'
        })

        # æ£€æŸ¥é”™è¯¯ç‡
        error_rate = request_stats['error_rate']

        checks.append({
            'name': 'é”™è¯¯ç‡',
            'status': 'OK' if error_rate < 1.0 else 'WARNING' if error_rate < 5.0 else 'CRITICAL',
            'value': f"{error_rate:.2f}%",
            'threshold': '< 1% (OK), < 5% (WARNING)'
        })

        # æ£€æŸ¥ç¼“å­˜å‘½ä¸­ç‡
        cache_stats = self.query_cache.get_stats()
        hit_rate = cache_stats['hit_rate']

        checks.append({
            'name': 'ç¼“å­˜å‘½ä¸­ç‡',
            'status': 'OK' if hit_rate > 70 else 'WARNING' if hit_rate > 50 else 'CRITICAL',
            'value': f"{hit_rate:.2f}%",
            'threshold': '> 70% (OK), > 50% (WARNING)'
        })

        # æ˜¾ç¤ºç»“æœ
        ok_count = sum(1 for check in checks if check['status'] == 'OK')
        warning_count = sum(1 for check in checks if check['status'] == 'WARNING')
        critical_count = sum(1 for check in checks if check['status'] == 'CRITICAL')

        print(f"å¥åº·æ£€æŸ¥ç»“æœ: {ok_count} OK, {warning_count} WARNING, {critical_count} CRITICAL")
        print()

        for check in checks:
            status_icon = {'OK': 'âœ…', 'WARNING': 'âš ï¸', 'CRITICAL': 'âŒ'}[check['status']]
            print(f"{status_icon} {check['name']:<20} {check['value']:<15} ({check['threshold']})")

        print("=" * 60)

        overall_status = 'CRITICAL' if critical_count > 0 else 'WARNING' if warning_count > 0 else 'OK'
        print(f"æ•´ä½“çŠ¶æ€: {overall_status}")

        return overall_status == 'OK'


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="æ€§èƒ½ç›‘æ§å’Œç®¡ç†å·¥å…·")
    parser.add_argument('command', choices=[
        'status', 'details', 'suggestions', 'clear-cache', 'cleanup',
        'export', 'monitor', 'health'
    ], help='æ‰§è¡Œçš„å‘½ä»¤')
    parser.add_argument('--cache-type', choices=['all', 'query', 'redis', 'metrics', 'slow_queries'],
                       default='all', help='ç¼“å­˜ç±»å‹ (ç”¨äº clear-cache)')
    parser.add_argument('--hours', type=int, default=24, help='æ¸…ç†å°æ—¶æ•° (ç”¨äº cleanup)')
    parser.add_argument('--output', help='è¾“å‡ºæ–‡ä»¶ (ç”¨äº export)')
    parser.add_argument('--duration', type=int, default=60, help='ç›‘æ§æŒç»­æ—¶é—´ç§’æ•° (ç”¨äº monitor)')
    parser.add_argument('--interval', type=int, default=5, help='ç›‘æ§æ›´æ–°é—´éš”ç§’æ•° (ç”¨äº monitor)')

    args = parser.parse_args()

    monitor = PerformanceMonitor()

    try:
        if args.command == 'status':
            await monitor.show_system_status()
        elif args.command == 'details':
            await monitor.show_performance_details()
        elif args.command == 'suggestions':
            await monitor.show_optimization_suggestions()
        elif args.command == 'clear-cache':
            await monitor.clear_cache(args.cache_type)
        elif args.command == 'cleanup':
            await monitor.cleanup_old_data(args.hours)
        elif args.command == 'export':
            await monitor.export_metrics(args.output)
        elif args.command == 'monitor':
            await monitor.monitor_real_time(args.duration, args.interval)
        elif args.command == 'health':
            healthy = await monitor.health_check()
            sys.exit(0 if healthy else 1)

    except KeyboardInterrupt:
        print("\næ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"æ‰§è¡Œå‡ºé”™: {e}")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
