#!/usr/bin/env python3
"""
åç«¯å¯¹æ¥å®Œæ•´æ€§æ£€æŸ¥å·¥å…·
æ£€æŸ¥æ•°æ®åº“ã€AIæœåŠ¡ã€å†…éƒ¨å„å±‚ä¹‹é—´çš„å¯¹æ¥æƒ…å†µ
"""

import ast
import json
import os
import re
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Set, Tuple


class BackendAlignmentAnalyzer:
    """åç«¯å¯¹æ¥åˆ†æå™¨"""

    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.src_path = self.project_root / "src"

        # å­˜å‚¨åˆ†æç»“æœ
        self.models: Dict[str, Dict] = {}
        self.repositories: Dict[str, Dict] = {}
        self.services: Dict[str, Dict] = {}
        self.api_endpoints: Dict[str, Dict] = {}
        self.migrations: List[str] = []

        # å¯¹æ¥é—®é¢˜
        self.issues: Dict[str, List[str]] = defaultdict(list)

    def analyze(self):
        """æ‰§è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸ” å¼€å§‹åç«¯å¯¹æ¥å®Œæ•´æ€§æ£€æŸ¥...\n")

        # 1. åˆ†ææ•°æ®æ¨¡å‹
        self.analyze_models()

        # 2. åˆ†æRepositoryå±‚
        self.analyze_repositories()

        # 3. åˆ†æServiceå±‚
        self.analyze_services()

        # 4. åˆ†æAPIå±‚
        self.analyze_api_endpoints()

        # 5. åˆ†ææ•°æ®åº“è¿ç§»
        self.analyze_migrations()

        # 6. æ£€æŸ¥AIæœåŠ¡å¯¹æ¥
        self.analyze_ai_service()

        # 7. æ£€æŸ¥é…ç½®å®Œæ•´æ€§
        self.analyze_configuration()

        # 8. ç”ŸæˆæŠ¥å‘Š
        self.generate_report()

    def analyze_models(self):
        """åˆ†ææ•°æ®æ¨¡å‹"""
        print("ğŸ“Š åˆ†ææ•°æ®æ¨¡å‹...")
        models_path = self.src_path / "models"

        for py_file in models_path.glob("*.py"):
            if py_file.name.startswith("_"):
                continue

            content = py_file.read_text(encoding="utf-8")

            # æŸ¥æ‰¾æ¨¡å‹ç±»å®šä¹‰
            class_pattern = r"class\s+(\w+)\(BaseModel\):"
            matches = re.finditer(class_pattern, content)

            for match in matches:
                model_name = match.group(1)
                self.models[model_name] = {
                    "file": py_file.name,
                    "table_name": self._extract_table_name(content, model_name),
                    "relationships": self._extract_relationships(content, model_name),
                }

        print(f"   æ‰¾åˆ° {len(self.models)} ä¸ªæ¨¡å‹\n")

    def analyze_repositories(self):
        """åˆ†æRepositoryå±‚"""
        print("ğŸ—„ï¸  åˆ†æRepositoryå±‚...")
        repo_path = self.src_path / "repositories"

        for py_file in repo_path.glob("*.py"):
            if py_file.name.startswith("_") or py_file.name == "base_repository.py":
                continue

            content = py_file.read_text(encoding="utf-8")

            # æŸ¥æ‰¾Repositoryç±»
            class_pattern = r"class\s+(\w+Repository)"
            matches = re.finditer(class_pattern, content)

            for match in matches:
                repo_name = match.group(1)
                self.repositories[repo_name] = {
                    "file": py_file.name,
                    "model": self._extract_repo_model(content, repo_name),
                    "methods": self._extract_repo_methods(content, repo_name),
                }

        print(f"   æ‰¾åˆ° {len(self.repositories)} ä¸ªRepository\n")

    def analyze_services(self):
        """åˆ†æServiceå±‚"""
        print("âš™ï¸  åˆ†æServiceå±‚...")
        service_path = self.src_path / "services"

        for py_file in service_path.glob("*.py"):
            if py_file.name.startswith("_"):
                continue

            content = py_file.read_text(encoding="utf-8")

            # æŸ¥æ‰¾Serviceç±»
            class_pattern = r"class\s+(\w+Service)"
            matches = re.finditer(class_pattern, content)

            for match in matches:
                service_name = match.group(1)
                self.services[service_name] = {
                    "file": py_file.name,
                    "repositories": self._extract_service_repos(content),
                    "methods": self._extract_service_methods(content, service_name),
                }

        print(f"   æ‰¾åˆ° {len(self.services)} ä¸ªService\n")

    def analyze_api_endpoints(self):
        """åˆ†æAPIç«¯ç‚¹"""
        print("ğŸŒ åˆ†æAPIç«¯ç‚¹...")
        api_path = self.src_path / "api" / "v1"

        if not api_path.exists():
            print("   âš ï¸  æœªæ‰¾åˆ°APIç›®å½•\n")
            return

        for py_file in api_path.glob("*.py"):
            if py_file.name.startswith("_"):
                continue

            content = py_file.read_text(encoding="utf-8")

            # æŸ¥æ‰¾è·¯ç”±å®šä¹‰
            route_pattern = r'@router\.(get|post|put|delete|patch)\(["\']([^"\']+)'
            matches = re.finditer(route_pattern, content)

            for match in matches:
                method, path = match.group(1), match.group(2)
                endpoint_key = f"{method.upper()} {path}"
                self.api_endpoints[endpoint_key] = {
                    "file": py_file.name,
                    "method": method.upper(),
                    "path": path,
                }

        print(f"   æ‰¾åˆ° {len(self.api_endpoints)} ä¸ªAPIç«¯ç‚¹\n")

    def analyze_migrations(self):
        """åˆ†ææ•°æ®åº“è¿ç§»"""
        print("ğŸ”„ åˆ†ææ•°æ®åº“è¿ç§»...")
        migrations_path = self.project_root / "alembic" / "versions"

        if not migrations_path.exists():
            self.issues["migrations"].append("æœªæ‰¾åˆ°è¿ç§»ç›®å½•")
            return

        for py_file in migrations_path.glob("*.py"):
            self.migrations.append(py_file.name)

        print(f"   æ‰¾åˆ° {len(self.migrations)} ä¸ªè¿ç§»æ–‡ä»¶\n")

    def analyze_ai_service(self):
        """åˆ†æAIæœåŠ¡å¯¹æ¥"""
        print("ğŸ¤– åˆ†æé˜¿é‡Œäº‘ç™¾ç‚¼AIå¯¹æ¥...")

        bailian_file = self.src_path / "services" / "bailian_service.py"
        if not bailian_file.exists():
            self.issues["ai_service"].append("æœªæ‰¾åˆ°BailianServiceå®ç°")
            return

        content = bailian_file.read_text(encoding="utf-8")

        # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
        required_configs = [
            "DASHSCOPE_API_KEY",
            "BAILIAN_APP_ID",
            "HOMEWORK_CORRECTION_APP_ID",
            "LEARNING_ASSISTANT_APP_ID",
            "KNOWLEDGE_QA_APP_ID",
        ]

        for config in required_configs:
            if config not in content:
                self.issues["ai_service"].append(f"ç¼ºå°‘é…ç½®é¡¹: {config}")

        # æ£€æŸ¥APIè°ƒç”¨æ–¹æ³•
        api_methods = re.findall(r"async def (\w+)\(", content)
        print(f"   æ‰¾åˆ° {len(api_methods)} ä¸ªAIæœåŠ¡æ–¹æ³•")

        # æ£€æŸ¥é”™è¯¯å¤„ç†
        if "try:" not in content or "except" not in content:
            self.issues["ai_service"].append("ç¼ºå°‘é”™è¯¯å¤„ç†æœºåˆ¶")

        # æ£€æŸ¥è¶…æ—¶è®¾ç½®
        if "timeout" not in content:
            self.issues["ai_service"].append("æœªè®¾ç½®APIè°ƒç”¨è¶…æ—¶")

        print()

    def analyze_configuration(self):
        """åˆ†æé…ç½®å®Œæ•´æ€§"""
        print("âš™ï¸  åˆ†æé…ç½®å®Œæ•´æ€§...")

        config_file = self.src_path / "core" / "config.py"
        if not config_file.exists():
            self.issues["configuration"].append("æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
            return

        content = config_file.read_text(encoding="utf-8")

        # æ£€æŸ¥å¿…è¦çš„é…ç½®ç»„
        required_sections = [
            "DATABASE_URL",
            "REDIS_URL",
            "DASHSCOPE_API_KEY",
            "SECRET_KEY",
            "UPLOAD_DIR",
        ]

        for section in required_sections:
            if section not in content:
                self.issues["configuration"].append(f"ç¼ºå°‘é…ç½®é¡¹: {section}")

        print(f"   é…ç½®æ£€æŸ¥å®Œæˆ\n")

    def check_model_repository_alignment(self):
        """æ£€æŸ¥Modelä¸Repositoryå¯¹é½"""
        print("ğŸ”— æ£€æŸ¥Modelâ†”Repositoryå¯¹é½...")

        # æ£€æŸ¥æ¯ä¸ªModelæ˜¯å¦æœ‰å¯¹åº”çš„Repository
        models_without_repo = []
        for model_name in self.models.keys():
            expected_repo = f"{model_name}Repository"
            if expected_repo not in self.repositories:
                models_without_repo.append(model_name)

        if models_without_repo:
            self.issues["model_repository"].append(
                f"ä»¥ä¸‹æ¨¡å‹ç¼ºå°‘Repository: {', '.join(models_without_repo)}"
            )

        # æ£€æŸ¥Repositoryæ˜¯å¦å¼•ç”¨äº†æ­£ç¡®çš„Model
        for repo_name, repo_info in self.repositories.items():
            if repo_info["model"]:
                expected_model = repo_name.replace("Repository", "")
                if repo_info["model"] != expected_model:
                    self.issues["model_repository"].append(
                        f"{repo_name} å¼•ç”¨çš„æ¨¡å‹({repo_info['model']})ä¸åŒ¹é…"
                    )

        print(f"   å‘ç° {len(self.issues['model_repository'])} ä¸ªå¯¹é½é—®é¢˜\n")

    def check_service_repository_alignment(self):
        """æ£€æŸ¥Serviceä¸Repositoryå¯¹é½"""
        print("ğŸ”— æ£€æŸ¥Serviceâ†”Repositoryå¯¹é½...")

        for service_name, service_info in self.services.items():
            if not service_info["repositories"]:
                self.issues["service_repository"].append(
                    f"{service_name} æœªä½¿ç”¨ä»»ä½•Repository"
                )

        print(f"   å‘ç° {len(self.issues['service_repository'])} ä¸ªå¯¹é½é—®é¢˜\n")

    def generate_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ åç«¯å¯¹æ¥å®Œæ•´æ€§åˆ†ææŠ¥å‘Š")
        print("=" * 60 + "\n")

        # 1. åŸºç¡€ç»Ÿè®¡
        print("ğŸ“Š åŸºç¡€ç»Ÿè®¡:")
        print(f"   - æ•°æ®æ¨¡å‹: {len(self.models)} ä¸ª")
        print(f"   - Repository: {len(self.repositories)} ä¸ª")
        print(f"   - Service: {len(self.services)} ä¸ª")
        print(f"   - APIç«¯ç‚¹: {len(self.api_endpoints)} ä¸ª")
        print(f"   - æ•°æ®åº“è¿ç§»: {len(self.migrations)} ä¸ª")
        print()

        # 2. æ‰§è¡Œå¯¹é½æ£€æŸ¥
        self.check_model_repository_alignment()
        self.check_service_repository_alignment()

        # 3. é—®é¢˜æ±‡æ€»
        total_issues = sum(len(issues) for issues in self.issues.values())

        if total_issues == 0:
            print("âœ… æœªå‘ç°å¯¹æ¥é—®é¢˜ï¼åç«¯å„å±‚å¯¹é½çŠ¶æ€è‰¯å¥½ã€‚\n")
        else:
            print(f"âš ï¸  å‘ç° {total_issues} ä¸ªå¯¹æ¥é—®é¢˜:\n")

            for category, issues in self.issues.items():
                if issues:
                    print(f"   ã€{category}ã€‘")
                    for issue in issues:
                        print(f"      âŒ {issue}")
                    print()

        # 4. è¯¦ç»†ä¿¡æ¯
        print("\n" + "-" * 60)
        print("ğŸ“„ è¯¦ç»†ä¿¡æ¯")
        print("-" * 60 + "\n")

        print(f"æ•°æ®æ¨¡å‹åˆ—è¡¨ ({len(self.models)}):")
        for model_name, model_info in sorted(self.models.items()):
            print(
                f"   - {model_name} (è¡¨: {model_info['table_name']}, æ–‡ä»¶: {model_info['file']})"
            )

        print(f"\nRepositoryåˆ—è¡¨ ({len(self.repositories)}):")
        for repo_name, repo_info in sorted(self.repositories.items()):
            print(
                f"   - {repo_name} (æ¨¡å‹: {repo_info['model']}, æ–‡ä»¶: {repo_info['file']})"
            )

        print(f"\nServiceåˆ—è¡¨ ({len(self.services)}):")
        for service_name, service_info in sorted(self.services.items()):
            repos = (
                ", ".join(service_info["repositories"])
                if service_info["repositories"]
                else "æ— "
            )
            print(
                f"   - {service_name} (ä½¿ç”¨ä»“å‚¨: {repos}, æ–‡ä»¶: {service_info['file']})"
            )

        # 5. ç”ŸæˆJSONæŠ¥å‘Š
        report_data = {
            "summary": {
                "models_count": len(self.models),
                "repositories_count": len(self.repositories),
                "services_count": len(self.services),
                "api_endpoints_count": len(self.api_endpoints),
                "migrations_count": len(self.migrations),
                "total_issues": total_issues,
            },
            "models": self.models,
            "repositories": self.repositories,
            "services": self.services,
            "api_endpoints": self.api_endpoints,
            "issues": dict(self.issues),
        }

        report_path = self.project_root / "reports" / "backend_alignment_report.json"
        report_path.parent.mkdir(exist_ok=True)

        with open(report_path, "w", encoding="utf-8") as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

        # 6. ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report()

    def generate_markdown_report(self):
        """ç”ŸæˆMarkdownæ ¼å¼æŠ¥å‘Š"""
        report_path = self.project_root / "BACKEND_ALIGNMENT_REPORT.md"

        total_issues = sum(len(issues) for issues in self.issues.values())
        status_emoji = "âœ…" if total_issues == 0 else "âš ï¸"

        content = f"""# åç«¯å¯¹æ¥å®Œæ•´æ€§åˆ†ææŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {self._get_timestamp()}  
**å¯¹é½çŠ¶æ€**: {status_emoji} {'å®Œå…¨å¯¹é½' if total_issues == 0 else f'å‘ç° {total_issues} ä¸ªé—®é¢˜'}

---

## ğŸ“Š åŸºç¡€ç»Ÿè®¡

| ç±»åˆ« | æ•°é‡ |
|------|------|
| æ•°æ®æ¨¡å‹ (Models) | {len(self.models)} |
| æ•°æ®ä»“å‚¨ (Repositories) | {len(self.repositories)} |
| ä¸šåŠ¡æœåŠ¡ (Services) | {len(self.services)} |
| APIç«¯ç‚¹ (Endpoints) | {len(self.api_endpoints)} |
| æ•°æ®åº“è¿ç§» (Migrations) | {len(self.migrations)} |

---

## ğŸ” å¯¹æ¥æ£€æŸ¥ç»“æœ

### 1. æ•°æ®åº“å¯¹æ¥ (Models â†” Database)

"""

        # Modelsåˆ—è¡¨
        content += f"**æ•°æ®æ¨¡å‹** ({len(self.models)} ä¸ª):\n\n"
        for model_name, model_info in sorted(self.models.items()):
            content += f"- `{model_name}` â†’ è¡¨ `{model_info['table_name']}` (å®šä¹‰äº `{model_info['file']}`)\n"

        content += "\n"

        # Repositoryåˆ—è¡¨
        content += f"### 2. Repositoryå±‚å¯¹æ¥ (Models â†” Repositories)\n\n"
        content += f"**æ•°æ®ä»“å‚¨** ({len(self.repositories)} ä¸ª):\n\n"
        for repo_name, repo_info in sorted(self.repositories.items()):
            content += f"- `{repo_name}` â†’ æ¨¡å‹ `{repo_info['model']}` (å®šä¹‰äº `{repo_info['file']}`)\n"

        content += "\n"

        # Serviceåˆ—è¡¨
        content += f"### 3. Serviceå±‚å¯¹æ¥ (Repositories â†” Services)\n\n"
        content += f"**ä¸šåŠ¡æœåŠ¡** ({len(self.services)} ä¸ª):\n\n"
        for service_name, service_info in sorted(self.services.items()):
            repos = (
                ", ".join([f"`{r}`" for r in service_info["repositories"]])
                if service_info["repositories"]
                else "æ— "
            )
            content += f"- `{service_name}` â†’ ä½¿ç”¨ä»“å‚¨: {repos} (å®šä¹‰äº `{service_info['file']}`)\n"

        content += "\n"

        # é—®é¢˜æ±‡æ€»
        if total_issues > 0:
            content += f"## âš ï¸ å‘ç°çš„é—®é¢˜ ({total_issues} ä¸ª)\n\n"

            for category, issues in self.issues.items():
                if issues:
                    content += f"### {category.replace('_', ' ').title()}\n\n"
                    for issue in issues:
                        content += f"- âŒ {issue}\n"
                    content += "\n"
        else:
            content += "## âœ… æœªå‘ç°é—®é¢˜\n\næ‰€æœ‰å¯¹æ¥æ£€æŸ¥é€šè¿‡ï¼\n\n"

        # å»ºè®®
        content += """---

## ğŸ’¡ æ”¹è¿›å»ºè®®

### ç«‹å³ä¿®å¤ (P0)
"""

        if self.issues.get("model_repository"):
            content += (
                "1. **è¡¥å……ç¼ºå¤±çš„Repository**: ä¸ºæ¯ä¸ªModelåˆ›å»ºå¯¹åº”çš„Repositoryç±»\n"
            )

        if self.issues.get("ai_service"):
            content += "2. **å®Œå–„AIæœåŠ¡é…ç½®**: æ·»åŠ ç¼ºå¤±çš„é…ç½®é¡¹å’Œé”™è¯¯å¤„ç†\n"

        if self.issues.get("configuration"):
            content += "3. **è¡¥å……ç¯å¢ƒé…ç½®**: æ·»åŠ ç¼ºå¤±çš„å¿…è¦é…ç½®é¡¹\n"

        content += """
### ä¼˜åŒ–å»ºè®® (P1)
1. ä¸ºæ‰€æœ‰Repositoryæ·»åŠ å•å…ƒæµ‹è¯•
2. å®Œå–„Serviceå±‚çš„ä¸šåŠ¡é€»è¾‘éªŒè¯
3. æ·»åŠ APIç«¯ç‚¹çš„é›†æˆæµ‹è¯•
4. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½

### é•¿æœŸæ”¹è¿› (P2)
1. å®ç°å®Œæ•´çš„Repositoryæ¨¡å¼ (ä¸ºæ‰€æœ‰Model)
2. æ·»åŠ Serviceå±‚çš„ä¾èµ–æ³¨å…¥
3. å®ç°ç»Ÿä¸€çš„å¼‚å¸¸å¤„ç†æœºåˆ¶
4. æ·»åŠ æ€§èƒ½ç›‘æ§å’Œæ—¥å¿—è®°å½•

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [æ•°æ®è®¿é—®å±‚æ–‡æ¡£](docs/architecture/data-access-layer.md)
- [APIè®¾è®¡æ–‡æ¡£](docs/api/README.md)
- [å¼€å‘æŒ‡å—](docs/guide/backend-development.md)
"""

        with open(report_path, "w", encoding="utf-8") as f:
            f.write(content)

        print(f"ğŸ“„ MarkdownæŠ¥å‘Šå·²ä¿å­˜: {report_path}\n")

    # ===== è¾…åŠ©æ–¹æ³• =====

    def _extract_table_name(self, content: str, model_name: str) -> str:
        """æå–è¡¨å"""
        pattern = (
            rf'class {model_name}\(BaseModel\):.*?__tablename__\s*=\s*["\'](\w+)["\']'
        )
        match = re.search(pattern, content, re.DOTALL)
        return match.group(1) if match else "æœªçŸ¥"

    def _extract_relationships(self, content: str, model_name: str) -> List[str]:
        """æå–å…³ç³»å­—æ®µ"""
        pattern = r'relationship\(["\'](\w+)["\']\)'
        return re.findall(pattern, content)

    def _extract_repo_model(self, content: str, repo_name: str) -> str:
        """æå–Repositoryå…³è”çš„Model"""
        pattern = rf"class {repo_name}.*?BaseRepository\[(\w+)\]"
        match = re.search(pattern, content)
        return match.group(1) if match else "æœªçŸ¥"

    def _extract_repo_methods(self, content: str, repo_name: str) -> List[str]:
        """æå–Repositoryçš„æ–¹æ³•"""
        pattern = rf"class {repo_name}.*?(?=class|\Z)"
        class_content = re.search(pattern, content, re.DOTALL)
        if not class_content:
            return []

        method_pattern = r"async def (\w+)\("
        return re.findall(method_pattern, class_content.group(0))

    def _extract_service_repos(self, content: str) -> List[str]:
        """æå–Serviceä½¿ç”¨çš„Repository"""
        pattern = r"self\.(\w+_repository)\s*="
        repos = re.findall(pattern, content)
        return list(set(repos))

    def _extract_service_methods(self, content: str, service_name: str) -> List[str]:
        """æå–Serviceçš„æ–¹æ³•"""
        pattern = rf"class {service_name}.*?(?=class|\Z)"
        class_content = re.search(pattern, content, re.DOTALL)
        if not class_content:
            return []

        method_pattern = r"async def (\w+)\("
        return re.findall(method_pattern, class_content.group(0))

    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime

        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")


def main():
    """ä¸»å‡½æ•°"""
    import sys

    # è·å–é¡¹ç›®æ ¹ç›®å½•
    if len(sys.argv) > 1:
        project_root = sys.argv[1]
    else:
        project_root = os.getcwd()

    # åˆ›å»ºåˆ†æå™¨å¹¶æ‰§è¡Œåˆ†æ
    analyzer = BackendAlignmentAnalyzer(project_root)
    analyzer.analyze()


if __name__ == "__main__":
    main()
