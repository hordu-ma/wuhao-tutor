#!/usr/bin/env python3
"""
ä¿®å¤ç™¾ç‚¼VLæ¨¡å‹APIç«¯ç‚¹é—®é¢˜

æ ¸å¿ƒé—®é¢˜ï¼šVLæ¨¡å‹éœ€è¦ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼çš„ç«¯ç‚¹ï¼Œè€Œä¸æ˜¯åŸç”ŸAPIç«¯ç‚¹
è§£å†³æ–¹æ¡ˆï¼šä¸ºVLæ¨¡å‹ä½¿ç”¨ä¸åŒçš„APIè°ƒç”¨é€»è¾‘
"""

import sys

sys.path.insert(0, "/Users/liguoma/my-devs/python/wuhao-tutor")

import shutil
from pathlib import Path


def create_fixed_bailian_service():
    """ä¿®å¤ç™¾ç‚¼æœåŠ¡ä»¥æ”¯æŒVLæ¨¡å‹"""

    # å¤‡ä»½åŸæ–‡ä»¶
    original_file = Path(
        "/Users/liguoma/my-devs/python/wuhao-tutor/src/services/bailian_service.py"
    )
    backup_file = original_file.with_suffix(".py.backup2")

    if not backup_file.exists():
        shutil.copy2(original_file, backup_file)
        print(f"âœ… å·²å¤‡ä»½åŸæ–‡ä»¶: {backup_file}")

    # è¯»å–åŸæ–‡ä»¶å†…å®¹
    with open(original_file, "r", encoding="utf-8") as f:
        content = f.read()

    # æ·»åŠ OpenAIå…¼å®¹æ¨¡å¼æ”¯æŒ
    openai_import = """import asyncio
import json
import logging
import time
from dataclasses import asdict, dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Union

import httpx
from pydantic import BaseModel, Field

from src.core.config import get_settings
from src.core.exceptions import (
    BailianAuthError,
    BailianRateLimitError,
    BailianServiceError,
    BailianTimeoutError,
)"""

    # æ·»åŠ VLæ¨¡å‹ä¸“ç”¨æ–¹æ³•
    vl_methods = '''
    async def _call_vl_model_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨VLæ¨¡å‹ä¸“ç”¨APIï¼ˆOpenAIå…¼å®¹æ¨¡å¼ï¼‰
        
        VLæ¨¡å‹ä½¿ç”¨ä¸åŒçš„ç«¯ç‚¹å’Œè¯·æ±‚æ ¼å¼
        """
        # VLæ¨¡å‹ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼ç«¯ç‚¹
        url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
        
        # è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
        openai_payload = self._convert_to_openai_format(payload)
        
        try:
            response = await self.client.post(url, json=openai_payload)
            
            # å¤„ç†HTTPé”™è¯¯
            if response.status_code == 401:
                raise BailianAuthError("APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            elif response.status_code == 429:
                retry_after = response.headers.get("Retry-After", 60)
                raise BailianRateLimitError(f"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·{retry_after}ç§’åé‡è¯•")
            elif response.status_code >= 400:
                error_text = response.text
                raise BailianServiceError(
                    f"VLæ¨¡å‹HTTPé”™è¯¯ {response.status_code}: {error_text}"
                )
            
            # è§£æJSONå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                raise BailianServiceError(f"VLæ¨¡å‹æ— æ•ˆçš„JSONå“åº”: {response.text}")
            
            # è½¬æ¢å›æ ‡å‡†æ ¼å¼
            return self._convert_from_openai_format(response_data)
            
        except httpx.TimeoutException:
            raise BailianTimeoutError(f"VLæ¨¡å‹APIè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰")
        except httpx.RequestError as e:
            raise BailianServiceError(f"VLæ¨¡å‹ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}") from e

    def _convert_to_openai_format(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†åŸç”ŸAPIæ ¼å¼è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
        """
        model = payload.get("model", "qwen-vl-max")
        messages = payload.get("input", {}).get("messages", [])
        parameters = payload.get("parameters", {})
        
        openai_payload = {
            "model": model,
            "messages": messages,
            "max_tokens": parameters.get("max_tokens", 1500),
            "temperature": parameters.get("temperature", 0.7),
            "top_p": parameters.get("top_p", 0.8),
        }
        
        logger.debug(f"è½¬æ¢ä¸ºOpenAIæ ¼å¼: {openai_payload}")
        return openai_payload

    def _convert_from_openai_format(self, response_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†OpenAIæ ¼å¼å“åº”è½¬æ¢ä¸ºåŸç”ŸAPIæ ¼å¼
        """
        choices = response_data.get("choices", [])
        if not choices:
            raise BailianServiceError("VLæ¨¡å‹å“åº”ä¸­æ²¡æœ‰choices")
        
        message = choices[0].get("message", {})
        content = message.get("content", "")
        
        # æ„å»ºæ ‡å‡†å“åº”æ ¼å¼
        standard_response = {
            "output": {
                "text": content,
                "choices": [{"message": {"content": content}}]
            },
            "usage": response_data.get("usage", {}),
            "request_id": response_data.get("id", ""),
        }
        
        return standard_response

    def _is_vl_model(self, model: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºVLæ¨¡å‹
        """
        vl_models = ["qwen-vl-max", "qwen-vl-plus", "qwen-vl-max-latest"]
        return model in vl_models
'''

    # ä¿®æ”¹ _call_bailian_api æ–¹æ³•ä»¥æ”¯æŒVLæ¨¡å‹
    old_call_api = '''    async def _call_bailian_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨ç™¾ç‚¼API

        Args:
            payload: è¯·æ±‚è½½è·

        Returns:
            Dict: APIå“åº”æ•°æ®

        Raises:
            BailianServiceError: å„ç§APIè°ƒç”¨é”™è¯¯
        """
        url = f"{self.base_url}/services/aigc/text-generation/generation"'''

    new_call_api = '''    async def _call_bailian_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨ç™¾ç‚¼API

        Args:
            payload: è¯·æ±‚è½½è·

        Returns:
            Dict: APIå“åº”æ•°æ®

        Raises:
            BailianServiceError: å„ç§APIè°ƒç”¨é”™è¯¯
        """
        model = payload.get("model", "")
        
        # VLæ¨¡å‹ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼
        if self._is_vl_model(model):
            logger.info(f"ä½¿ç”¨VLæ¨¡å‹OpenAIå…¼å®¹æ¨¡å¼: {model}")
            return await self._call_vl_model_api(payload)
        
        # æ™®é€šæ¨¡å‹ä½¿ç”¨åŸç”ŸAPI
        url = f"{self.base_url}/services/aigc/text-generation/generation"'''

    # æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«VLæ–¹æ³•
    if "_call_vl_model_api" in content:
        print("âš ï¸  VLæ¨¡å‹æ–¹æ³•å·²å­˜åœ¨ï¼Œè·³è¿‡æ·»åŠ ")
    else:
        # åœ¨ç±»çš„æœ«å°¾æ·»åŠ VLæ–¹æ³•
        class_end = content.rfind("    def _log_response(")
        if class_end != -1:
            insert_pos = content.rfind("\n", 0, class_end)
            content = content[:insert_pos] + vl_methods + content[insert_pos:]
            print("âœ… å·²æ·»åŠ VLæ¨¡å‹ä¸“ç”¨æ–¹æ³•")
        else:
            print("âŒ æœªæ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®")

    # æ›¿æ¢ _call_bailian_api æ–¹æ³•
    if old_call_api in content:
        content = content.replace(old_call_api, new_call_api)
        print("âœ… å·²ä¿®å¤APIè°ƒç”¨æ–¹æ³•")
    else:
        print("âš ï¸  APIè°ƒç”¨æ–¹æ³•å¯èƒ½å·²ä¿®å¤")

    # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶
    with open(original_file, "w", encoding="utf-8") as f:
        f.write(content)

    print(f"âœ… å·²ä¿å­˜ä¿®å¤åçš„æ–‡ä»¶: {original_file}")
    return True


def create_test_vl_api():
    """åˆ›å»ºæµ‹è¯•VL APIçš„è„šæœ¬"""

    test_script = '''#!/usr/bin/env python3
"""
æµ‹è¯•ä¿®å¤åçš„VLæ¨¡å‹API

ä½¿ç”¨å®˜æ–¹ç¤ºä¾‹å›¾ç‰‡éªŒè¯OpenAIå…¼å®¹æ¨¡å¼æ˜¯å¦å·¥ä½œæ­£å¸¸
"""

import asyncio
import sys
sys.path.insert(0, "/Users/liguoma/my-devs/python/wuhao-tutor")

from src.services.bailian_service import ChatMessage, MessageRole, BailianService, AIContext
from typing import List, Union, Dict, Any


async def test_vl_openai_mode():
    """æµ‹è¯•VLæ¨¡å‹OpenAIå…¼å®¹æ¨¡å¼"""
    print("ğŸ§ª æµ‹è¯•VLæ¨¡å‹OpenAIå…¼å®¹æ¨¡å¼...")
    
    # ä½¿ç”¨å®˜æ–¹ç¤ºä¾‹å›¾ç‰‡
    test_image = "https://help-static-aliyun-doc.aliyuncs.com/file-manage-files/zh-CN/20241022/emyrja/dog_and_girl.jpeg"
    
    messages: List[Union[Dict[str, Any], ChatMessage]] = [
        ChatMessage(
            role=MessageRole.SYSTEM,
            content="You are a helpful assistant."
        ),
        ChatMessage(
            role=MessageRole.USER,
            content="è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹",
            image_urls=[test_image]
        )
    ]
    
    bailian_service = BailianService()
    context = AIContext(user_id="test_user", session_id="test_session")
    
    try:
        print(f"ğŸ“· æµ‹è¯•å›¾ç‰‡: {test_image}")
        print("ğŸ“¤ å‘é€VLæ¨¡å‹è¯·æ±‚...")
        
        response = await bailian_service.chat_completion(
            messages=messages,
            context=context,
            max_tokens=500,
            temperature=0.7
        )
        
        print("ğŸ“¥ VLæ¨¡å‹å“åº”:")
        print(f"   æˆåŠŸ: {response.success}")
        print(f"   æ¨¡å‹: {response.model}")
        print(f"   Tokenä½¿ç”¨: {response.tokens_used}")
        print(f"   å¤„ç†æ—¶é—´: {response.processing_time:.2f}ç§’")
        
        if response.success:
            print(f"\\nğŸ¤– AIå›å¤:")
            print(response.content)
            
            # æ£€æŸ¥æ˜¯å¦çœŸçš„çœ‹åˆ°äº†å›¾ç‰‡
            if any(keyword in response.content for keyword in ["å›¾ç‰‡", "å›¾åƒ", "å¥³å£«", "ç‹—", "æµ·æ»©"]):
                print("\\nâœ… VLæ¨¡å‹æˆåŠŸè¯†åˆ«å›¾ç‰‡å†…å®¹ï¼")
                return True
            else:
                print("\\nâš ï¸  VLæ¨¡å‹å›å¤äº†ï¼Œä½†å¯èƒ½æœªæ­£ç¡®è¯†åˆ«å›¾ç‰‡")
                return False
        else:
            print(f"\\nâŒ VLæ¨¡å‹è°ƒç”¨å¤±è´¥: {response.error_message}")
            return False
            
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_normal_model():
    """æµ‹è¯•æ™®é€šæ¨¡å‹æ˜¯å¦ä»æ­£å¸¸å·¥ä½œ"""
    print("\\nğŸ”§ æµ‹è¯•æ™®é€šæ¨¡å‹å…¼å®¹æ€§...")
    
    messages: List[Union[Dict[str, Any], ChatMessage]] = [
        ChatMessage(
            role=MessageRole.USER,
            content="ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"
        )
    ]
    
    bailian_service = BailianService()
    context = AIContext(user_id="test_user", session_id="test_session")
    
    try:
        print("ğŸ“¤ å‘é€æ™®é€šæ¨¡å‹è¯·æ±‚...")
        
        response = await bailian_service.chat_completion(
            messages=messages,
            context=context,
            max_tokens=200,
            temperature=0.7
        )
        
        print("ğŸ“¥ æ™®é€šæ¨¡å‹å“åº”:")
        print(f"   æˆåŠŸ: {response.success}")
        print(f"   æ¨¡å‹: {response.model}")
        
        if response.success:
            print(f"   ğŸ¤– AIå›å¤: {response.content[:100]}...")
            print("   âœ… æ™®é€šæ¨¡å‹å·¥ä½œæ­£å¸¸")
            return True
        else:
            print(f"   âŒ æ™®é€šæ¨¡å‹å¤±è´¥: {response.error_message}")
            return False
            
    except Exception as e:
        print(f"âŒ æ™®é€šæ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ VLæ¨¡å‹APIç«¯ç‚¹ä¿®å¤æµ‹è¯•")
    print("=" * 40)
    
    # æµ‹è¯•VLæ¨¡å‹
    vl_success = await test_vl_openai_mode()
    
    # æµ‹è¯•æ™®é€šæ¨¡å‹å…¼å®¹æ€§
    normal_success = await test_normal_model()
    
    print("\\nğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print(f"   VLæ¨¡å‹: {'âœ… æˆåŠŸ' if vl_success else 'âŒ å¤±è´¥'}")
    print(f"   æ™®é€šæ¨¡å‹: {'âœ… æˆåŠŸ' if normal_success else 'âŒ å¤±è´¥'}")
    
    if vl_success:
        print("\\nğŸ‰ VLæ¨¡å‹ä¿®å¤æˆåŠŸï¼")
        print("   ç°åœ¨å¯ä»¥æ­£å¸¸è¯†åˆ«å’Œåˆ†æå›¾ç‰‡å†…å®¹äº†")
        print("\\nğŸš€ ä¸‹ä¸€æ­¥:")
        print("   1. éƒ¨ç½²åˆ°ç”Ÿäº§ç¯å¢ƒ")
        print("   2. æµ‹è¯•å›¾ç‰‡ä¸Šä¼ +VLè¯†åˆ«å®Œæ•´æµç¨‹")
    else:
        print("\\nğŸ˜ VLæ¨¡å‹ä»æœ‰é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•")


if __name__ == "__main__":
    asyncio.run(main())
'''

    test_file = Path(
        "/Users/liguoma/my-devs/python/wuhao-tutor/scripts/test_vl_openai_mode.py"
    )
    with open(test_file, "w", encoding="utf-8") as f:
        f.write(test_script)

    print(f"âœ… å·²åˆ›å»ºVLæµ‹è¯•è„šæœ¬: {test_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”§ ç™¾ç‚¼VLæ¨¡å‹APIç«¯ç‚¹ä¿®å¤å·¥å…·")
    print("=" * 50)

    print("ğŸ” é—®é¢˜åˆ†æ:")
    print("1. VLæ¨¡å‹éœ€è¦ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼ç«¯ç‚¹")
    print("2. å½“å‰ä½¿ç”¨çš„æ˜¯åŸç”ŸAPIç«¯ç‚¹ï¼Œä¸æ”¯æŒå¤šæ¨¡æ€è¾“å…¥")
    print("3. éœ€è¦ä¸ºVLæ¨¡å‹æ·»åŠ ä¸“ç”¨çš„APIè°ƒç”¨é€»è¾‘")

    # åº”ç”¨ä¿®å¤
    if create_fixed_bailian_service():
        print("\\nâœ… ä¿®å¤å®Œæˆ!")

        # åˆ›å»ºæµ‹è¯•è„šæœ¬
        create_test_vl_api()

        print("\\nğŸ“ ä¿®å¤å†…å®¹:")
        print("1. æ·»åŠ äº†VLæ¨¡å‹æ£€æµ‹é€»è¾‘")
        print("2. ä¸ºVLæ¨¡å‹ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼ç«¯ç‚¹")
        print("3. æ·»åŠ äº†æ ¼å¼è½¬æ¢æ–¹æ³•")
        print("4. ä¿æŒæ™®é€šæ¨¡å‹ä½¿ç”¨åŸç”ŸAPI")

        print("\\nğŸ§ª è¿è¡Œæµ‹è¯•:")
        print("   cd /Users/liguoma/my-devs/python/wuhao-tutor")
        print("   uv run python scripts/test_vl_openai_mode.py")

    else:
        print("âŒ ä¿®å¤å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç ç»“æ„")


if __name__ == "__main__":
    main()
