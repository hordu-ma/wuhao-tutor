#!/usr/bin/env python3
"""
é”™é¢˜çŸ¥è¯†ç‚¹å…³è”æ•°æ®å›å¡«è„šæœ¬

åŠŸèƒ½ï¼š
1. è¯»å–æ‰€æœ‰æœ‰ ai_feedback ä½†æ— çŸ¥è¯†ç‚¹å…³è”çš„é”™é¢˜
2. ä» ai_feedback ä¸­æå–çŸ¥è¯†ç‚¹
3. åˆ›å»ºçŸ¥è¯†ç‚¹å…³è”è®°å½•
4. æ›´æ–°çŸ¥è¯†ç‚¹æŒæ¡åº¦

ä½¿ç”¨æ–¹æ³•ï¼š
    python scripts/backfill_knowledge_associations.py [--dry-run] [--limit=100]

å‚æ•°ï¼š
    --dry-run: åªæ˜¾ç¤ºå°†è¦å¤„ç†çš„æ•°æ®ï¼Œä¸å®é™…å†™å…¥æ•°æ®åº“
    --limit: é™åˆ¶å¤„ç†çš„é”™é¢˜æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
"""

import asyncio
import json
import logging
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
from uuid import UUID

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from sqlalchemy import and_, select
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.config import get_settings
from src.core.database import AsyncSessionLocal
from src.core.logging import configure_logging, get_logger
from src.models.study import MistakeRecord
from src.services.knowledge_graph_service import KnowledgeGraphService

# é…ç½®æ—¥å¿—
configure_logging()
logger = get_logger(__name__)
settings = get_settings()


async def extract_knowledge_points_from_feedback(
    ai_feedback: Dict[str, Any]
) -> List[Dict[str, Any]]:
    """
    ä» AI feedback ä¸­æå–çŸ¥è¯†ç‚¹
    
    Args:
        ai_feedback: AI åé¦ˆæ•°æ®
        
    Returns:
        çŸ¥è¯†ç‚¹åˆ—è¡¨
    """
    knowledge_points = []
    
    # å°è¯•ä» knowledge_points å­—æ®µè·å–
    if "knowledge_points" in ai_feedback and ai_feedback["knowledge_points"]:
        kps = ai_feedback["knowledge_points"]
        
        # å¤„ç†ä¸åŒæ ¼å¼
        if isinstance(kps, list):
            for kp in kps:
                if isinstance(kp, dict):
                    knowledge_points.append(kp)
                elif isinstance(kp, str):
                    knowledge_points.append({"name": kp, "relevance": 0.7})
        elif isinstance(kps, str):
            # å•ä¸ªçŸ¥è¯†ç‚¹å­—ç¬¦ä¸²
            knowledge_points.append({"name": kps, "relevance": 0.7})
    
    # ä»å…¶ä»–å¯èƒ½çš„å­—æ®µæå–
    for field in ["æ¶‰åŠçŸ¥è¯†ç‚¹", "çŸ¥è¯†ç‚¹", "related_knowledge"]:
        if field in ai_feedback and ai_feedback[field]:
            items = ai_feedback[field]
            if isinstance(items, list):
                for item in items:
                    if isinstance(item, str):
                        knowledge_points.append({"name": item, "relevance": 0.6})
    
    return knowledge_points


async def backfill_single_mistake(
    session: AsyncSession,
    mistake: MistakeRecord,
    kg_service: KnowledgeGraphService,
    dry_run: bool = False,
) -> bool:
    """
    ä¸ºå•ä¸ªé”™é¢˜å›å¡«çŸ¥è¯†ç‚¹å…³è”
    
    Args:
        session: æ•°æ®åº“ä¼šè¯
        mistake: é”™é¢˜è®°å½•
        kg_service: çŸ¥è¯†å›¾è°±æœåŠ¡
        dry_run: æ˜¯å¦ä¸ºå¹²è¿è¡Œï¼ˆä¸å®é™…å†™å…¥ï¼‰
        
    Returns:
        æ˜¯å¦æˆåŠŸå¤„ç†
    """
    try:
        mistake_id = mistake.id
        user_id = mistake.user_id
        subject = mistake.subject
        
        # è§£æ ai_feedback
        ai_feedback = {}
        if mistake.ai_feedback:
            try:
                if isinstance(mistake.ai_feedback, str):
                    ai_feedback = json.loads(mistake.ai_feedback)
                elif isinstance(mistake.ai_feedback, dict):
                    ai_feedback = mistake.ai_feedback
            except json.JSONDecodeError:
                logger.warning(f"é”™é¢˜ {mistake_id} çš„ ai_feedback æ— æ³•è§£æ")
                return False
        
        # æå–çŸ¥è¯†ç‚¹
        knowledge_points = await extract_knowledge_points_from_feedback(ai_feedback)
        
        if not knowledge_points:
            logger.info(f"é”™é¢˜ {mistake_id} æ²¡æœ‰æå–åˆ°çŸ¥è¯†ç‚¹")
            return False
        
        logger.info(
            f"é”™é¢˜ {mistake_id} æå–åˆ° {len(knowledge_points)} ä¸ªçŸ¥è¯†ç‚¹: "
            f"{[kp.get('name') for kp in knowledge_points]}"
        )
        
        if dry_run:
            logger.info(f"[DRY-RUN] å°†ä¸ºé”™é¢˜ {mistake_id} åˆ›å»º {len(knowledge_points)} ä¸ªå…³è”")
            return True
        
        # è°ƒç”¨çŸ¥è¯†å›¾è°±æœåŠ¡åˆ›å»ºå…³è”
        associations = await kg_service.analyze_and_associate_knowledge_points(
            mistake_id=UUID(str(mistake_id)),
            user_id=UUID(str(user_id)),
            subject=subject or "æ•°å­¦",
            ocr_text=mistake.ocr_text,
            ai_feedback=ai_feedback,
        )
        
        if associations:
            logger.info(
                f"âœ… æˆåŠŸä¸ºé”™é¢˜ {mistake_id} åˆ›å»º {len(associations)} ä¸ªçŸ¥è¯†ç‚¹å…³è”"
            )
            return True
        else:
            logger.warning(f"âš ï¸ é”™é¢˜ {mistake_id} çŸ¥è¯†ç‚¹å…³è”åˆ›å»ºå¤±è´¥")
            return False
            
    except Exception as e:
        logger.error(f"å¤„ç†é”™é¢˜ {mistake_id} å¤±è´¥: {e}", exc_info=True)
        return False


async def main(dry_run: bool = False, limit: Optional[int] = None):
    """
    ä¸»å‡½æ•°
    
    Args:
        dry_run: æ˜¯å¦ä¸ºå¹²è¿è¡Œ
        limit: é™åˆ¶å¤„ç†çš„é”™é¢˜æ•°é‡
    """
    logger.info("=" * 60)
    logger.info("é”™é¢˜çŸ¥è¯†ç‚¹å…³è”æ•°æ®å›å¡«è„šæœ¬")
    logger.info(f"æ¨¡å¼: {'å¹²è¿è¡Œï¼ˆä¸å†™å…¥æ•°æ®åº“ï¼‰' if dry_run else 'æ­£å¼è¿è¡Œ'}")
    logger.info(f"é™åˆ¶: {limit if limit else 'æ— é™åˆ¶'}")
    logger.info("=" * 60)
    
    async with AsyncSessionLocal() as session:
        try:
            # æŸ¥è¯¢æ‰€æœ‰æœ‰ ai_feedback ä½†æ— çŸ¥è¯†ç‚¹å…³è”çš„é”™é¢˜
            from src.models.knowledge_graph import MistakeKnowledgePoint
            
            # å­æŸ¥è¯¢ï¼šå·²æœ‰å…³è”çš„é”™é¢˜ID
            subquery = select(MistakeKnowledgePoint.mistake_id).distinct()
            
            # ä¸»æŸ¥è¯¢ï¼šæœªå…³è”çš„é”™é¢˜
            stmt = (
                select(MistakeRecord)
                .where(
                    and_(
                        MistakeRecord.ai_feedback.is_not(None),
                        MistakeRecord.id.notin_(subquery),
                    )
                )
                .order_by(MistakeRecord.created_at.desc())
            )
            
            if limit:
                stmt = stmt.limit(limit)
            
            result = await session.execute(stmt)
            mistakes = result.scalars().all()
            
            total_count = len(mistakes)
            logger.info(f"æ‰¾åˆ° {total_count} æ¡éœ€è¦å¤„ç†çš„é”™é¢˜è®°å½•")
            
            if total_count == 0:
                logger.info("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æ•°æ®ï¼Œé€€å‡º")
                return
            
            # åˆå§‹åŒ–çŸ¥è¯†å›¾è°±æœåŠ¡
            kg_service = KnowledgeGraphService(session)
            
            # ç»Ÿè®¡
            success_count = 0
            failed_count = 0
            skipped_count = 0
            
            # é€æ¡å¤„ç†
            for index, mistake in enumerate(mistakes, 1):
                logger.info(f"[{index}/{total_count}] å¤„ç†é”™é¢˜ {mistake.id}")
                
                success = await backfill_single_mistake(
                    session, mistake, kg_service, dry_run
                )
                
                if success:
                    success_count += 1
                else:
                    skipped_count += 1
                
                # æ¯å¤„ç†10æ¡æäº¤ä¸€æ¬¡ï¼ˆéå¹²è¿è¡Œæ¨¡å¼ï¼‰
                if not dry_run and index % 10 == 0:
                    await session.commit()
                    logger.info(f"å·²æäº¤å‰ {index} æ¡æ•°æ®")
            
            # æœ€åæäº¤å‰©ä½™æ•°æ®
            if not dry_run:
                await session.commit()
                logger.info("âœ… æ‰€æœ‰æ•°æ®å·²æäº¤")
            
            # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
            logger.info("=" * 60)
            logger.info("å¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯ï¼š")
            logger.info(f"  æ€»è®¡: {total_count}")
            logger.info(f"  æˆåŠŸ: {success_count}")
            logger.info(f"  è·³è¿‡: {skipped_count}")
            logger.info(f"  å¤±è´¥: {failed_count}")
            logger.info("=" * 60)
            
            if dry_run:
                logger.info("ğŸ’¡ è¿™æ˜¯å¹²è¿è¡Œæ¨¡å¼ï¼Œæ•°æ®æœªå®é™…å†™å…¥æ•°æ®åº“")
                logger.info("ğŸ’¡ å¦‚éœ€æ­£å¼è¿è¡Œï¼Œè¯·å»æ‰ --dry-run å‚æ•°")
            
        except Exception as e:
            logger.error(f"è„šæœ¬æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            if not dry_run:
                await session.rollback()
            raise


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="é”™é¢˜çŸ¥è¯†ç‚¹å…³è”æ•°æ®å›å¡«è„šæœ¬")
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="å¹²è¿è¡Œæ¨¡å¼ï¼Œä¸å®é™…å†™å…¥æ•°æ®åº“",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="é™åˆ¶å¤„ç†çš„é”™é¢˜æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰",
    )
    
    args = parser.parse_args()
    
    # è¿è¡Œè„šæœ¬
    asyncio.run(main(dry_run=args.dry_run, limit=args.limit))
