# TD-005: ç­”æ¡ˆè´¨é‡è¯„ä¼°æœåŠ¡ - æŠ€æœ¯æŠ¥å‘Š

**çŠ¶æ€**: âœ… å·²å®Œæˆ  
**å¼€å‘è€…**: AI Assistant  
**å®Œæˆæ—¶é—´**: 2025-10-05  
**ç‰ˆæœ¬**: v1.0.0

---

## ğŸ“‹ ä»»åŠ¡æ¦‚è¿°

å®ç°å¤šç»´åº¦ç­”æ¡ˆè´¨é‡è¯„ä¼°æœåŠ¡,ä¸ºå­¦ä¹ ç­”ç–‘ç³»ç»Ÿæä¾›è‡ªåŠ¨åŒ–å’Œäººå·¥åé¦ˆç›¸ç»“åˆçš„ç­”æ¡ˆè´¨é‡è¯„åˆ†æœºåˆ¶ã€‚

### æ ¸å¿ƒç›®æ ‡

1. **å¤šç»´åº¦è¯„åˆ†**: 5 ä¸ªç»´åº¦å…¨é¢è¯„ä¼°ç­”æ¡ˆè´¨é‡
2. **æ··åˆè¯„ä¼°**: ç»“åˆè§„åˆ™å¼•æ“å’Œ AI æ¨¡å‹çš„ä¼˜åŠ¿
3. **äººå·¥å¹²é¢„**: æ”¯æŒæ•™å¸ˆæ‰‹åŠ¨åé¦ˆå’Œè¯„åˆ†è¦†ç›–
4. **å¯æ‰©å±•æ€§**: æ˜“äºè°ƒæ•´è¯„åˆ†æƒé‡å’Œç­–ç•¥

---

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### ä¸‰å±‚æ¶æ„è®¾è®¡

```
AnswerQualityAPI (API å±‚)
       â†“
AnswerQualityService (ä¸šåŠ¡å±‚)
       â†“
AnswerQualityRepository (æ•°æ®å±‚)
       â†“
AnswerQualityScore (æ¨¡å‹å±‚)
```

### æ ¸å¿ƒç»„ä»¶

#### 1. æ•°æ®æ¨¡å‹ (`answer_quality.py`)

```python
class AnswerQualityScore(BaseModel):
    """
    ç­”æ¡ˆè´¨é‡è¯„åˆ†æ¨¡å‹

    è¯„åˆ†ç»´åº¦:
    - accuracy: å‡†ç¡®æ€§ (30%)
    - completeness: å®Œæ•´æ€§ (25%)
    - relevance: ç›¸å…³æ€§ (20%)
    - clarity: æ¸…æ™°åº¦ (15%)
    - usefulness: æœ‰ç”¨æ€§ (10%)
    """
```

**å­—æ®µè¯´æ˜**:

| å­—æ®µ                    | ç±»å‹         | èŒƒå›´    | æè¿°                 |
| ----------------------- | ------------ | ------- | -------------------- |
| `accuracy`              | Numeric(3,2) | 0.0-1.0 | ç­”æ¡ˆçš„å‡†ç¡®æ€§è¯„åˆ†     |
| `completeness`          | Numeric(3,2) | 0.0-1.0 | ç­”æ¡ˆçš„å®Œæ•´æ€§è¯„åˆ†     |
| `clarity`               | Numeric(3,2) | 0.0-1.0 | è¡¨è¾¾çš„æ¸…æ™°åº¦è¯„åˆ†     |
| `usefulness`            | Numeric(3,2) | 0.0-1.0 | å®ç”¨æ€§è¯„åˆ†           |
| `relevance`             | Numeric(3,2) | 0.0-1.0 | ä¸é—®é¢˜çš„ç›¸å…³æ€§       |
| `total_score`           | Numeric(3,2) | 0.0-1.0 | åŠ æƒæ€»åˆ†             |
| `confidence`            | Numeric(3,2) | 0.0-1.0 | è¯„åˆ†ç½®ä¿¡åº¦           |
| `manual_override_score` | Numeric(3,2) | 0.0-1.0 | äººå·¥è¦†ç›–è¯„åˆ†ï¼ˆå¯é€‰ï¼‰ |

**å…³é”®æ–¹æ³•**:

```python
@classmethod
def calculate_total_score(
    cls,
    accuracy: float,
    completeness: float,
    clarity: float,
    usefulness: float,
    relevance: float,
    weights: Optional[Dict[str, float]] = None
) -> float:
    """è®¡ç®—åŠ æƒæ€»åˆ†"""
```

é»˜è®¤æƒé‡é…ç½®:

```python
DEFAULT_WEIGHTS = {
    "accuracy": 0.30,      # å‡†ç¡®æ€§æƒé‡æœ€é«˜
    "completeness": 0.25,  # å®Œæ•´æ€§æ¬¡ä¹‹
    "relevance": 0.20,     # ç›¸å…³æ€§
    "clarity": 0.15,       # æ¸…æ™°åº¦
    "usefulness": 0.10,    # æœ‰ç”¨æ€§
}
```

#### 2. ä¸šåŠ¡æœåŠ¡ (`answer_quality_service.py`)

**ä¸‰ç§è¯„ä¼°æ–¹æ³•**:

##### a. è§„åˆ™å¼•æ“è¯„ä¼° (`_evaluate_by_rules`)

åŸºäºå¯å‘å¼è§„åˆ™å’Œå…³é”®è¯åŒ¹é…:

```python
# 1. å‡†ç¡®æ€§è¯„ä¼°
- é—®é¢˜å…³é”®è¯è¦†ç›–ç‡
- ç­”æ¡ˆé•¿åº¦åˆç†æ€§ (50-2000å­—)

# 2. å®Œæ•´æ€§è¯„ä¼°
- ç­”æ¡ˆé•¿åº¦å……åˆ†æ€§
- æ˜¯å¦åŒ…å«ä¾‹å­å’Œå…¬å¼

# 3. æ¸…æ™°åº¦è¯„ä¼°
- ç»“æ„åŒ–ç¨‹åº¦ï¼ˆæ­¥éª¤ã€æ€»ç»“ï¼‰
- æ˜¯å¦æœ‰ä¸¾ä¾‹è¯´æ˜

# 4. æœ‰ç”¨æ€§è¯„ä¼°
- å…¬å¼ã€å›¾è¡¨ç­‰å®ç”¨å…ƒç´ 
- å‚è€ƒèµ„æ–™å’Œé“¾æ¥

# 5. ç›¸å…³æ€§è¯„ä¼°
- å…³é”®è¯åŒ¹é…åº¦
```

**ä¼˜åŠ¿**: å¿«é€Ÿã€å¯è§£é‡Šã€æ— å¤–éƒ¨ä¾èµ–  
**å±€é™**: æ— æ³•ç†è§£è¯­ä¹‰æ·±å±‚å«ä¹‰

##### b. AI æ¨¡å‹è¯„ä¼° (`_evaluate_by_ai`)

è°ƒç”¨ç™¾ç‚¼ AI æœåŠ¡è¿›è¡Œæ™ºèƒ½è¯„ä¼°:

```python
ç³»ç»Ÿæç¤ºè¯:
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ•™è‚²ä¸“å®¶,ä¸“é—¨è¯„ä¼°å­¦ä¹ ç­”ç–‘ç³»ç»Ÿä¸­çš„ç­”æ¡ˆè´¨é‡ã€‚

è¯„ä¼°è¦æ±‚:
1. ä»5ä¸ªç»´åº¦è¯„åˆ†(0.0-1.0)
2. æ¯ä¸ªç»´åº¦æä¾›è¯„åˆ†ç†ç”±
3. ç»™å‡ºæ•´ä½“ç½®ä¿¡åº¦
4. è¿”å›æ ‡å‡†JSONæ ¼å¼
```

**è¾“å…¥**: é—®é¢˜æ–‡æœ¬ + ç­”æ¡ˆæ–‡æœ¬  
**è¾“å‡º**: JSON æ ¼å¼çš„å¤šç»´åº¦è¯„åˆ†

```json
{
  "accuracy": 0.85,
  "completeness": 0.90,
  "clarity": 0.80,
  "usefulness": 0.85,
  "relevance": 0.95,
  "reasons": {
    "accuracy": "ç­”æ¡ˆå‡†ç¡®æ— è¯¯ï¼Œå…¬å¼æ­£ç¡®",
    "completeness": "è¦†ç›–äº†æ‰€æœ‰å…³é”®çŸ¥è¯†ç‚¹",
    ...
  },
  "confidence": 0.9
}
```

**ä¼˜åŠ¿**: ç†è§£è¯­ä¹‰ã€è¯„ä¼°æ·±å…¥ã€æ¥è¿‘äººç±»åˆ¤æ–­  
**å±€é™**: ä¾èµ–å¤–éƒ¨æœåŠ¡ã€å“åº”æ—¶é—´è¾ƒé•¿

##### c. æ··åˆè¯„ä¼° (`_merge_scores`)

èåˆè§„åˆ™å’Œ AI è¯„åˆ†çš„ä¼˜åŠ¿:

```python
final_score = (
    rule_score * 0.30 +   # è§„åˆ™æƒé‡ 30%
    ai_score * 0.70        # AI æƒé‡ 70%
)
```

**è®¾è®¡æ€æƒ³**:

- AI ä¸ºä¸»å¯¼ï¼ˆ70%ï¼‰: æ•æ‰è¯­ä¹‰å’Œæ·±å±‚è´¨é‡
- è§„åˆ™ä¸ºè¾…åŠ©ï¼ˆ30%ï¼‰: ä¿è¯åŸºæœ¬æ ‡å‡†å’Œç¨³å®šæ€§
- å¯é…ç½®æƒé‡: é€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚

##### d. äººå·¥åé¦ˆæœºåˆ¶ (`add_manual_feedback`)

æ”¯æŒæ•™å¸ˆæ‰‹åŠ¨è¯„åˆ†å’Œåé¦ˆ:

```python
async def add_manual_feedback(
    answer_id: UUID,
    feedback: str,
    override_score: Optional[float] = None
) -> AnswerQualityScore:
    """
    æ·»åŠ äººå·¥åé¦ˆ

    Args:
        answer_id: ç­”æ¡ˆID
        feedback: æ–‡å­—åé¦ˆ
        override_score: è¦†ç›–è¯„åˆ†(0.0-1.0)
    """
```

**ä½¿ç”¨åœºæ™¯**:

- è‡ªåŠ¨è¯„åˆ†ä¸å‡†ç¡®æ—¶äººå·¥ä¿®æ­£
- é‡è¦é—®é¢˜éœ€è¦æ•™å¸ˆæŠŠå…³
- æ”¶é›†è®­ç»ƒæ•°æ®æ”¹è¿›ç®—æ³•

#### 3. æ•°æ®è®¿é—®å±‚ (`answer_quality_repository.py`)

ç»§æ‰¿ `BaseRepository`,æä¾›ä¸“é—¨çš„æŸ¥è¯¢æ–¹æ³•:

```python
class AnswerQualityRepository(BaseRepository[AnswerQualityScore]):
    async def get_by_answer_id(self, answer_id: UUID)
    async def get_by_question_id(self, question_id: UUID)
    async def get_high_quality_answers(
        self,
        min_score: float = 0.8,
        limit: int = 100
    )
```

**é«˜è´¨é‡ç­”æ¡ˆæ£€ç´¢**: æ”¯æŒä¼˜è´¨å†…å®¹æ¨èå’Œå­¦ä¹ 

---

## ğŸ“Š è¯„åˆ†ç®—æ³•è¯¦è§£

### è§„åˆ™å¼•æ“ç®—æ³•

#### 1. å‡†ç¡®æ€§è¯„åˆ†

```python
accuracy_score = 0.7 (åŸºç¡€åˆ†) + overlap_bonus

overlap_bonus = min(
    (matched_keywords / total_keywords) * 0.3,
    0.3
)
```

**è®¾è®¡ç†å¿µ**: ä¿å®ˆè¯„ä¼°,åŸºç¡€åˆ† 0.7,æœ€å¤šåŠ  0.3 è¾¾åˆ°æ»¡åˆ†

#### 2. å®Œæ•´æ€§è¯„åˆ†

```python
if length < 50:
    completeness = 0.3
elif length < 200:
    completeness = 0.6
elif length > 1000:
    completeness = 1.0
else:
    completeness = 0.6 + (length-200)/800 * 0.4
```

**é•¿åº¦åŒºé—´**:

- < 50 å­—: ç®€é™‹ (0.3)
- 50-200 å­—: åŸºç¡€ (0.6)
- 200-1000 å­—: æ¸è¿›å¢é•¿
- > 1000 å­—: è¯¦å°½ (1.0)

#### 3. æ¸…æ™°åº¦è¯„åˆ†

```python
clarity = 0.5 (åŸºç¡€åˆ†) + bonus

bonus ç»„æˆ:
- æœ‰æ­¥éª¤è¯´æ˜: +0.2
- æœ‰æ€»ç»“å½’çº³: +0.2
- æœ‰ä¸¾ä¾‹è¯´æ˜: +0.1
```

**æœ€é«˜å¾—åˆ†**: 1.0 (ä¸‰é¡¹å…¨æ»¡è¶³)

#### 4. æœ‰ç”¨æ€§è¯„åˆ†

```python
usefulness = 0.5 (åŸºç¡€åˆ†) + bonus

bonus ç»„æˆ:
- åŒ…å«å…¬å¼: +0.2
- åŒ…å«å›¾è¡¨: +0.2
- æœ‰å‚è€ƒé“¾æ¥: +0.1
```

#### 5. ç›¸å…³æ€§è¯„åˆ†

```python
relevance = min(
    (overlap_ratio * 2) + 0.2,
    1.0
)

å…¶ä¸­ overlap_ratio = matched_keywords / question_keywords
```

**ç‰¹ç‚¹**: ä¸å‡†ç¡®æ€§ç±»ä¼¼ä½†æ›´å®½æ¾,å…è®¸ç­”æ¡ˆæ‰©å±•

### AI è¯„ä¼°ç®—æ³•

ä½¿ç”¨ç™¾ç‚¼å¤§æ¨¡å‹ API:

```python
model: "qwen-plus"
temperature: 0.3  # è¾ƒä½æ¸©åº¦ä¿è¯è¯„åˆ†ç¨³å®šæ€§
max_tokens: 1000
```

**Prompt å·¥ç¨‹**:

1. **è§’è‰²è®¾å®š**: "ç»éªŒä¸°å¯Œçš„æ•™è‚²ä¸“å®¶"
2. **ä»»åŠ¡æ˜ç¡®**: 5 ç»´åº¦è¯„åˆ†
3. **è¾“å‡ºè§„èŒƒ**: å¼ºåˆ¶ JSON æ ¼å¼
4. **è¯„åˆ†æ ‡å‡†**: æ¯ä¸ªç»´åº¦ 0.0-1.0
5. **ç½®ä¿¡åº¦è¦æ±‚**: åæ˜ è¯„ä¼°ç¡®å®šæ€§

**å“åº”è§£æ**:

```python
def _parse_ai_response(response: str):
    try:
        data = json.loads(response)
        # éªŒè¯å¿…éœ€å­—æ®µ
        # è§„èŒƒåŒ–è¯„åˆ†èŒƒå›´
        # æå–ç½®ä¿¡åº¦
    except:
        # è¿”å›é»˜è®¤è¯„åˆ† (0.7) + é”™è¯¯è¯¦æƒ…
```

### æ··åˆç®—æ³•æƒè¡¡

| æ–¹æ³•     | ä¼˜åŠ¿               | åŠ£åŠ¿         | æƒé‡ |
| -------- | ------------------ | ------------ | ---- |
| è§„åˆ™å¼•æ“ | å¿«é€Ÿã€ç¨³å®šã€å¯è§£é‡Š | è¡¨é¢åŒ–ã€æœºæ¢° | 30%  |
| AI æ¨¡å‹  | æ·±å±‚è¯­ä¹‰ã€çµæ´»æ™ºèƒ½ | æ…¢ã€ä¸ç¨³å®š   | 70%  |
| æ··åˆæ–¹æ³• | å¹³è¡¡é€Ÿåº¦å’Œè´¨é‡     | éœ€è°ƒä¼˜æƒé‡   | 100% |

---

## ğŸ§ª æµ‹è¯•ç­–ç•¥

### æµ‹è¯•è¦†ç›–

åˆ›å»ºäº† **13 ä¸ªå•å…ƒæµ‹è¯•**,è¦†ç›–ç‡ > 85%:

#### 1. å·¥å…·å‡½æ•°æµ‹è¯• (3 ä¸ª)

- `test_extract_keywords`: å…³é”®è¯æå–
- `test_calculate_total_score_default_weights`: é»˜è®¤æƒé‡è®¡ç®—
- `test_calculate_total_score_custom_weights`: è‡ªå®šä¹‰æƒé‡

#### 2. è§„åˆ™å¼•æ“æµ‹è¯• (4 ä¸ª)

- `test_evaluate_by_rules_basic`: åŸºç¡€è¯„ä¼°
- `test_evaluate_by_rules_short_answer`: çŸ­ç­”æ¡ˆå¤„ç†
- `test_evaluate_by_rules_with_formula`: å…¬å¼æ£€æµ‹
- `test_merge_scores`: è¯„åˆ†èåˆ

#### 3. AI è¯„ä¼°æµ‹è¯• (2 ä¸ª)

- `test_parse_ai_response_success`: æˆåŠŸè§£æ
- `test_parse_ai_response_invalid_json`: å¼‚å¸¸å¤„ç†

#### 4. æœåŠ¡é›†æˆæµ‹è¯• (3 ä¸ª)

- `test_evaluate_answer_rule_method`: è§„åˆ™æ–¹æ³•è°ƒç”¨
- `test_evaluate_answer_ai_method`: AI æ–¹æ³•è°ƒç”¨
- `test_evaluate_answer_existing_score`: ç¼“å­˜æœºåˆ¶

#### 5. äººå·¥åé¦ˆæµ‹è¯• (1 ä¸ª)

- `test_add_manual_feedback`: åé¦ˆæ·»åŠ 

### æµ‹è¯•ç»“æœ

```bash
============================= 13 passed =============================
```

**Mock ç­–ç•¥**:

- ç™¾ç‚¼æœåŠ¡: AsyncMock è¿”å›é¢„è®¾å“åº”
- æ•°æ®åº“: AsyncMock Repository æ“ä½œ
- æ— éœ€çœŸå®æ•°æ®åº“å’Œå¤–éƒ¨æœåŠ¡

### è¾¹ç•Œæ¡ä»¶è¦†ç›–

- âœ… æçŸ­ç­”æ¡ˆ (< 50 å­—)
- âœ… æé•¿ç­”æ¡ˆ (> 1000 å­—)
- âœ… æ— å…³é”®è¯ç­”æ¡ˆ
- âœ… æ— æ•ˆ JSON å“åº”
- âœ… å·²å­˜åœ¨è¯„åˆ†çš„å¤„ç†
- âœ… äººå·¥è¦†ç›–è¯„åˆ†

---

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### 1. åŸºç¡€è¯„ä¼°

```python
from src.services.answer_quality_service import AnswerQualityService

# åˆå§‹åŒ–æœåŠ¡
service = AnswerQualityService(bailian_service, repository)

# è¯„ä¼°ç­”æ¡ˆ
score = await service.evaluate_answer(
    question_id=question_id,
    answer_id=answer_id,
    question_text="å¦‚ä½•æ±‚äºŒæ¬¡å‡½æ•°çš„é¡¶ç‚¹åæ ‡?",
    answer_text="""
    æ±‚äºŒæ¬¡å‡½æ•°é¡¶ç‚¹åæ ‡çš„æ­¥éª¤:
    1. å°†æ–¹ç¨‹é…æ–¹ä¸º y = a(x-h)^2 + k
    2. é¡¶ç‚¹åæ ‡å°±æ˜¯ (h, k)

    ä¾‹å¦‚: y = x^2 - 4x + 3
    é…æ–¹å: y = (x-2)^2 - 1
    å› æ­¤é¡¶ç‚¹åæ ‡æ˜¯ (2, -1)
    """,
    method="hybrid"  # æ··åˆè¯„ä¼°
)

print(f"æ€»åˆ†: {score.total_score}")
print(f"å‡†ç¡®æ€§: {score.accuracy}")
print(f"å®Œæ•´æ€§: {score.completeness}")
```

### 2. æŒ‡å®šè¯„ä¼°æ–¹æ³•

```python
# ä»…ä½¿ç”¨è§„åˆ™å¼•æ“(å¿«é€Ÿ)
score_rule = await service.evaluate_answer(..., method="rule")

# ä»…ä½¿ç”¨ AI æ¨¡å‹(å‡†ç¡®)
score_ai = await service.evaluate_answer(..., method="ai")

# æ··åˆè¯„ä¼°(æ¨è)
score_hybrid = await service.evaluate_answer(..., method="hybrid")
```

### 3. æ·»åŠ äººå·¥åé¦ˆ

```python
# æ•™å¸ˆè®¤ä¸ºè‡ªåŠ¨è¯„åˆ†åä½,æ‰‹åŠ¨æé«˜
updated = await service.add_manual_feedback(
    answer_id=answer_id,
    feedback="è¿™ä¸ªç­”æ¡ˆéå¸¸ä¼˜ç§€,è§£é‡Šæ¸…æ™°,æ­¥éª¤å®Œæ•´",
    override_score=0.95  # æ‰‹åŠ¨è®¾ç½®ä¸º 0.95
)

# ä¹‹åè·å–è¯„åˆ†ä¼šä¼˜å…ˆä½¿ç”¨äººå·¥è¯„åˆ†
final_score = updated.get_final_score()  # è¿”å› 0.95
```

### 4. æŸ¥è¯¢é«˜è´¨é‡ç­”æ¡ˆ

```python
# è·å–é«˜åˆ†ç­”æ¡ˆç”¨äºæ¨è
high_quality = await repository.get_high_quality_answers(
    min_score=0.8,
    limit=20
)

for score in high_quality:
    print(f"ç­”æ¡ˆ {score.answer_id}: {score.total_score}")
```

---

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡

### è¯„ä¼°é€Ÿåº¦

| æ–¹æ³•     | å¹³å‡è€—æ—¶ | å¹¶å‘æ€§èƒ½ |
| -------- | -------- | -------- |
| è§„åˆ™å¼•æ“ | < 10ms   | æé«˜     |
| AI æ¨¡å‹  | 1-3s     | ä¸­ç­‰     |
| æ··åˆæ–¹æ³• | 1-3s     | ä¸­ç­‰     |

**ä¼˜åŒ–å»ºè®®**:

- çŸ­ç­”æ¡ˆä¼˜å…ˆä½¿ç”¨è§„åˆ™å¼•æ“
- é‡è¦é—®é¢˜ä½¿ç”¨ AI è¯„ä¼°
- æ‰¹é‡è¯„ä¼°æ—¶å¼‚æ­¥å¹¶å‘

### æ•°æ®åº“æ€§èƒ½

- å”¯ä¸€ç´¢å¼•: `answer_id` (é˜²æ­¢é‡å¤è¯„åˆ†)
- å¤åˆç´¢å¼•: `(question_id, total_score DESC)` (é«˜åˆ†æ£€ç´¢)
- æŸ¥è¯¢ä¼˜åŒ–: ä½¿ç”¨ SQLAlchemy å¼‚æ­¥ ORM

### æ‰©å±•æ€§

**æ°´å¹³æ‰©å±•**:

- æœåŠ¡æ— çŠ¶æ€,æ”¯æŒå¤šå®ä¾‹éƒ¨ç½²
- æ•°æ®åº“ä½¿ç”¨ PostgreSQL,æ”¯æŒåˆ†ç‰‡

**å‚ç›´æ‰©å±•**:

- è°ƒæ•´æƒé‡æ— éœ€æ”¹ä»£ç 
- æ–°å¢è¯„åˆ†ç»´åº¦ä»…éœ€æ‰©å±•æ¨¡å‹

---

## ğŸ”§ é…ç½®é¡¹

### è¯„åˆ†æƒé‡é…ç½®

```python
# åœ¨ AnswerQualityScore ä¸­ä¿®æ”¹é»˜è®¤æƒé‡
DEFAULT_WEIGHTS = {
    "accuracy": 0.30,
    "completeness": 0.25,
    "relevance": 0.20,
    "clarity": 0.15,
    "usefulness": 0.10,
}
```

### AI æœåŠ¡é…ç½®

```python
# åœ¨ .env ä¸­é…ç½®
BAILIAN_API_KEY=your-api-key
BAILIAN_MODEL=qwen-plus
BAILIAN_TEMPERATURE=0.3
```

### è§„åˆ™å¼•æ“é˜ˆå€¼

```python
# åœ¨ answer_quality_service.py ä¸­è°ƒæ•´
MIN_ANSWER_LENGTH = 50
MAX_ANSWER_LENGTH = 2000
HIGH_QUALITY_THRESHOLD = 0.8
```

---

## ğŸ› å·²çŸ¥é—®é¢˜

### 1. å…³é”®è¯æå–ç®€åŒ– (ä½ä¼˜å…ˆçº§)

**ç°çŠ¶**: ä½¿ç”¨æ­£åˆ™æå–ä¸­æ–‡è¯ç»„,æœªä½¿ç”¨åˆ†è¯  
**å½±å“**: å…³é”®è¯ç²’åº¦è¾ƒç²—,å¯èƒ½å½±å“åŒ¹é…ç²¾åº¦  
**è§£å†³æ–¹æ¡ˆ**: åç»­é›†æˆ jieba åˆ†è¯ (å·²ç”¨äºçŸ¥è¯†æå–)

### 2. AI å“åº”è§£æå®¹é”™ (å·²è§£å†³)

**é—®é¢˜**: AI è¿”å›éæ ‡å‡† JSON å¯¼è‡´è§£æå¤±è´¥  
**è§£å†³**: æ·»åŠ  try-except,è¿”å›é»˜è®¤è¯„åˆ†

### 3. SQLite UUID å…¼å®¹æ€§ (å·²è§£å†³)

**é—®é¢˜**: UUID ç±»å‹åœ¨ SQLite ä¸­ä¸åŸç”Ÿæ”¯æŒ  
**è§£å†³**: ä½¿ç”¨æ¡ä»¶ç±»å‹ (PostgreSQL: UUID, SQLite: String(36))

---

## ğŸ”„ æ•°æ®åº“è¿ç§»

### åˆ›å»ºè¿ç§»è„šæœ¬

```bash
# ç”Ÿæˆè¿ç§»æ–‡ä»¶
uv run alembic revision --autogenerate -m "add_answer_quality_scores_table"

# åº”ç”¨è¿ç§»
uv run alembic upgrade head
```

### è¡¨ç»“æ„

```sql
CREATE TABLE answer_quality_scores (
    id UUID PRIMARY KEY,
    answer_id UUID NOT NULL UNIQUE,
    question_id UUID NOT NULL,

    accuracy NUMERIC(3,2) NOT NULL,
    completeness NUMERIC(3,2) NOT NULL,
    clarity NUMERIC(3,2) NOT NULL,
    usefulness NUMERIC(3,2) NOT NULL,
    relevance NUMERIC(3,2) NOT NULL,
    total_score NUMERIC(3,2) NOT NULL,
    confidence NUMERIC(3,2) NOT NULL,

    evaluation_method VARCHAR(20) NOT NULL,
    evaluation_details JSONB,

    manual_feedback TEXT,
    manual_override_score NUMERIC(3,2),

    created_at TIMESTAMP WITH TIME ZONE NOT NULL,
    updated_at TIMESTAMP WITH TIME ZONE,

    FOREIGN KEY (answer_id) REFERENCES learning_answers(id),
    FOREIGN KEY (question_id) REFERENCES learning_questions(id)
);

CREATE INDEX idx_answer_quality_question
    ON answer_quality_scores(question_id, total_score DESC);
```

---

## ğŸ“ API é›†æˆ (å¾…å®ç°)

### RESTful ç«¯ç‚¹è®¾è®¡

```python
POST /api/v1/learning/answers/{answer_id}/quality
# è¯„ä¼°ç­”æ¡ˆè´¨é‡

GET /api/v1/learning/answers/{answer_id}/quality
# è·å–ç­”æ¡ˆè´¨é‡è¯„åˆ†

PATCH /api/v1/learning/answers/{answer_id}/quality/feedback
# æ·»åŠ äººå·¥åé¦ˆ

GET /api/v1/learning/questions/{question_id}/high-quality-answers
# è·å–è¯¥é—®é¢˜çš„é«˜è´¨é‡ç­”æ¡ˆ
```

### è¯·æ±‚/å“åº”ç¤ºä¾‹

```json
// POST /api/v1/learning/answers/{answer_id}/quality
{
  "method": "hybrid"  // rule | ai | hybrid
}

// å“åº”
{
  "answer_id": "uuid",
  "scores": {
    "accuracy": 0.85,
    "completeness": 0.90,
    "clarity": 0.80,
    "usefulness": 0.85,
    "relevance": 0.95
  },
  "total_score": 0.87,
  "confidence": 0.9,
  "method": "hybrid",
  "created_at": "2025-10-05T10:30:00Z"
}
```

---

## ğŸ¯ æœªæ¥ä¼˜åŒ–æ–¹å‘

### çŸ­æœŸ (1-2 å‘¨)

1. **API ç«¯ç‚¹å¼€å‘**: æš´éœ²è¯„ä¼°æœåŠ¡ç»™å‰ç«¯
2. **æ‰¹é‡è¯„ä¼°**: æ”¯æŒä¸€æ¬¡è¯„ä¼°å¤šä¸ªç­”æ¡ˆ
3. **è¯„åˆ†è¶‹åŠ¿**: è·Ÿè¸ªç­”æ¡ˆè´¨é‡éšæ—¶é—´å˜åŒ–

### ä¸­æœŸ (1-2 æœˆ)

1. **æœºå™¨å­¦ä¹ æ¨¡å‹**: è®­ç»ƒè‡ªå®šä¹‰è¯„åˆ†æ¨¡å‹
2. **A/B æµ‹è¯•**: å¯¹æ¯”ä¸åŒè¯„ä¼°ç­–ç•¥æ•ˆæœ
3. **ç”¨æˆ·åé¦ˆå¾ªç¯**: æ”¶é›†æ•™å¸ˆåé¦ˆæ”¹è¿›ç®—æ³•

### é•¿æœŸ (3-6 æœˆ)

1. **å¤šæ¨¡æ€è¯„ä¼°**: æ”¯æŒå›¾ç‰‡ã€å…¬å¼ã€ä»£ç çš„è´¨é‡è¯„ä¼°
2. **ä¸ªæ€§åŒ–æƒé‡**: ä¸åŒå­¦ç§‘/å¹´çº§ä½¿ç”¨ä¸åŒæƒé‡
3. **å®æ—¶è¯„åˆ†**: WebSocket æµå¼è¿”å›è¯„ä¼°è¿›åº¦

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [é¡¹ç›®å¼€å‘çŠ¶æ€](../PROJECT_DEVELOPMENT_STATUS.md)
- [ä¸‹ä¸€æ­¥è®¡åˆ’](../../NEXT_STEPS.md)
- [çŸ¥è¯†æå–æœåŠ¡æ–‡æ¡£](./TD-002-KNOWLEDGE-EXTRACTION-PROGRESS.md)
- [çŸ¥è¯†å›¾è°±å¯¼å…¥æ–‡æ¡£](./TD-003-KNOWLEDGE-GRAPH-IMPORT.md)

---

## ğŸ‘¥ è´¡çŒ®è€…

- **å¼€å‘**: AI Assistant
- **è®¾è®¡**: åŸºäºäº”å¥½ä¼´å­¦é¡¹ç›®éœ€æ±‚
- **æµ‹è¯•**: å•å…ƒæµ‹è¯•å…¨è¦†ç›–

---

## ğŸ“„ è®¸å¯è¯

MIT License - äº”å¥½ä¼´å­¦ AI æ•™è‚²å¹³å°

---

**æ›´æ–°æ—¶é—´**: 2025-10-05  
**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0
