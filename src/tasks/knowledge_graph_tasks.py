"""
çŸ¥è¯†å›¾è°±å®šæ—¶ä»»åŠ¡
å®ç°çŸ¥è¯†å›¾è°±å¿«ç…§çš„å®šæ—¶ç”Ÿæˆå’Œç»´æŠ¤

ä½œè€…: AI Agent
åˆ›å»ºæ—¶é—´: 2025-11-04
ç‰ˆæœ¬: v1.0
"""

import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Tuple
from uuid import UUID

from sqlalchemy import and_, distinct, select
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.database import AsyncSessionLocal
from src.core.logging import configure_logging, get_logger
from src.models.study import KnowledgeMastery, MistakeRecord
from src.services.knowledge_graph_service import KnowledgeGraphService

# é…ç½®æ—¥å¿—
configure_logging()
logger = get_logger(__name__)


async def generate_daily_snapshots() -> dict:
    """
    æ¯æ—¥å‡Œæ™¨3ç‚¹ç”ŸæˆçŸ¥è¯†å›¾è°±å¿«ç…§
    
    å·¥ä½œæµç¨‹:
    1. æŸ¥è¯¢æ‰€æœ‰æœ‰é”™é¢˜è®°å½•çš„ç”¨æˆ·
    2. ä¸ºæ¯ä¸ªç”¨æˆ·çš„æ¯ä¸ªå­¦ç§‘ç”Ÿæˆå¿«ç…§
    3. è®°å½•æˆåŠŸå’Œå¤±è´¥ç»Ÿè®¡
    4. æ¸…ç†30å¤©å‰çš„æ—§å¿«ç…§
    
    Returns:
        æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯
    """
    logger.info("=" * 60)
    logger.info("ğŸš€ å¼€å§‹æ‰§è¡ŒçŸ¥è¯†å›¾è°±å¿«ç…§å®šæ—¶ä»»åŠ¡")
    logger.info(f"â° æ‰§è¡Œæ—¶é—´: {datetime.now().isoformat()}")
    logger.info("=" * 60)
    
    stats = {
        "total_users": 0,
        "total_snapshots": 0,
        "success_count": 0,
        "failed_count": 0,
        "skipped_count": 0,
        "errors": []
    }
    
    async with AsyncSessionLocal() as db:
        try:
            # 1. æŸ¥è¯¢æœ‰é”™é¢˜è®°å½•çš„ç”¨æˆ·å’Œå­¦ç§‘
            users_subjects = await _get_users_with_mistakes(db)
            stats["total_users"] = len(set(user_id for user_id, _ in users_subjects))
            stats["total_snapshots"] = len(users_subjects)
            
            logger.info(
                f"ğŸ“Š æ‰¾åˆ° {stats['total_users']} ä¸ªç”¨æˆ·, "
                f"å…± {stats['total_snapshots']} ä¸ªå­¦ç§‘éœ€è¦ç”Ÿæˆå¿«ç…§"
            )
            
            if not users_subjects:
                logger.info("âœ… æ²¡æœ‰éœ€è¦å¤„ç†çš„æ•°æ®ï¼Œé€€å‡º")
                return stats
            
            # 2. ä¸ºæ¯ä¸ªç”¨æˆ·çš„æ¯ä¸ªå­¦ç§‘ç”Ÿæˆå¿«ç…§
            for user_id, subject in users_subjects:
                try:
                    # åˆ›å»ºæ–°çš„æ•°æ®åº“ä¼šè¯ï¼ˆé¿å…å•ä¸ªå¤±è´¥å½±å“æ•´ä½“ï¼‰
                    async with AsyncSessionLocal() as snapshot_db:
                        kg_service = KnowledgeGraphService(snapshot_db)
                        
                        # ç”Ÿæˆå¿«ç…§
                        snapshot = await kg_service.create_knowledge_graph_snapshot(
                            user_id=UUID(user_id),
                            subject=subject,
                            period_type="daily"
                        )
                        
                        await snapshot_db.commit()
                        
                        stats["success_count"] += 1
                        logger.info(
                            f"âœ… æˆåŠŸç”Ÿæˆå¿«ç…§: user={user_id}, subject={subject}, "
                            f"snapshot_id={snapshot.id}"
                        )
                
                except Exception as e:
                    stats["failed_count"] += 1
                    error_msg = f"user={user_id}, subject={subject}, error={str(e)}"
                    stats["errors"].append(error_msg)
                    logger.error(f"âŒ ç”Ÿæˆå¿«ç…§å¤±è´¥: {error_msg}", exc_info=True)
            
            # 3. æ¸…ç†30å¤©å‰çš„æ—§å¿«ç…§
            try:
                deleted_count = await _cleanup_old_snapshots(db, days=30)
                logger.info(f"ğŸ—‘ï¸ æ¸…ç†äº† {deleted_count} ä¸ªè¿‡æœŸå¿«ç…§(30å¤©å‰)")
            except Exception as e:
                logger.error(f"æ¸…ç†æ—§å¿«ç…§å¤±è´¥: {e}", exc_info=True)
            
            # 4. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            logger.info("=" * 60)
            logger.info("ğŸ“ˆ ä»»åŠ¡æ‰§è¡Œå®Œæˆ! ç»Ÿè®¡ä¿¡æ¯:")
            logger.info(f"  æ€»ç”¨æˆ·æ•°: {stats['total_users']}")
            logger.info(f"  æ€»å¿«ç…§æ•°: {stats['total_snapshots']}")
            logger.info(f"  æˆåŠŸ: {stats['success_count']}")
            logger.info(f"  å¤±è´¥: {stats['failed_count']}")
            logger.info(f"  è·³è¿‡: {stats['skipped_count']}")
            
            if stats["errors"]:
                logger.warning(f"  é”™è¯¯è¯¦æƒ…: {stats['errors'][:5]}")  # åªæ˜¾ç¤ºå‰5ä¸ª
            
            logger.info("=" * 60)
            
            return stats
            
        except Exception as e:
            logger.error(f"å®šæ—¶ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
            raise


async def _get_users_with_mistakes(db: AsyncSession) -> List[Tuple[str, str]]:
    """
    æŸ¥è¯¢æœ‰é”™é¢˜è®°å½•çš„ç”¨æˆ·å’Œå­¦ç§‘ç»„åˆ
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        
    Returns:
        [(user_id, subject), ...] åˆ—è¡¨
    """
    try:
        # æŸ¥è¯¢æ‰€æœ‰æœ‰é”™é¢˜è®°å½•çš„ç”¨æˆ·å’Œå­¦ç§‘ç»„åˆ
        # åªæŸ¥è¯¢æœ€è¿‘7å¤©æœ‰æ´»åŠ¨çš„
        seven_days_ago = datetime.now() - timedelta(days=7)
        
        stmt = (
            select(MistakeRecord.user_id, MistakeRecord.subject)
            .where(MistakeRecord.created_at >= seven_days_ago)
            .distinct()
        )
        
        result = await db.execute(stmt)
        rows = result.all()
        
        # è½¬æ¢ä¸º (user_id, subject) å…ƒç»„åˆ—è¡¨
        users_subjects = [(str(row[0]), str(row[1])) for row in rows]
        
        logger.debug(f"æŸ¥è¯¢åˆ° {len(users_subjects)} ä¸ªç”¨æˆ·-å­¦ç§‘ç»„åˆ")
        return users_subjects
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢ç”¨æˆ·é”™é¢˜è®°å½•å¤±è´¥: {e}", exc_info=True)
        return []


async def _cleanup_old_snapshots(db: AsyncSession, days: int = 30) -> int:
    """
    æ¸…ç†è¿‡æœŸçš„å¿«ç…§è®°å½•
    
    Args:
        db: æ•°æ®åº“ä¼šè¯
        days: ä¿ç•™å¤©æ•°ï¼ˆé»˜è®¤30å¤©ï¼‰
        
    Returns:
        åˆ é™¤çš„å¿«ç…§æ•°é‡
    """
    from src.models.knowledge_graph import UserKnowledgeGraphSnapshot
    from src.repositories.base_repository import BaseRepository
    
    try:
        cutoff_date = datetime.now() - timedelta(days=days)
        
        # æŸ¥è¯¢è¿‡æœŸå¿«ç…§
        stmt = select(UserKnowledgeGraphSnapshot).where(
            UserKnowledgeGraphSnapshot.created_at < cutoff_date
        )
        result = await db.execute(stmt)
        old_snapshots = result.scalars().all()
        
        # åˆ é™¤
        snapshot_repo = BaseRepository(UserKnowledgeGraphSnapshot, db)
        deleted_count = 0
        
        for snapshot in old_snapshots:
            snapshot_id = getattr(snapshot, "id", None)
            if snapshot_id:
                await snapshot_repo.delete(str(snapshot_id))
                deleted_count += 1
        
        await db.commit()
        
        return deleted_count
        
    except Exception as e:
        await db.rollback()
        logger.error(f"æ¸…ç†è¿‡æœŸå¿«ç…§å¤±è´¥: {e}", exc_info=True)
        return 0


async def generate_snapshot_for_user(
    user_id: str, 
    subject: str
) -> dict:
    """
    ä¸ºç‰¹å®šç”¨æˆ·ç”Ÿæˆå¿«ç…§ï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰
    
    Args:
        user_id: ç”¨æˆ·ID
        subject: å­¦ç§‘
        
    Returns:
        æ‰§è¡Œç»“æœ
    """
    logger.info(f"ğŸ¯ æ‰‹åŠ¨ç”Ÿæˆå¿«ç…§: user={user_id}, subject={subject}")
    
    result = {
        "success": False,
        "snapshot_id": None,
        "error": None
    }
    
    async with AsyncSessionLocal() as db:
        try:
            kg_service = KnowledgeGraphService(db)
            
            snapshot = await kg_service.create_knowledge_graph_snapshot(
                user_id=UUID(user_id),
                subject=subject,
                period_type="manual"
            )
            
            await db.commit()
            
            result["success"] = True
            result["snapshot_id"] = str(snapshot.id)
            
            logger.info(f"âœ… æ‰‹åŠ¨å¿«ç…§ç”ŸæˆæˆåŠŸ: snapshot_id={snapshot.id}")
            
        except Exception as e:
            result["error"] = str(e)
            logger.error(f"âŒ æ‰‹åŠ¨å¿«ç…§ç”Ÿæˆå¤±è´¥: {e}", exc_info=True)
    
    return result


# Celery ä»»åŠ¡åŒ…è£…ï¼ˆå¦‚æœä½¿ç”¨ Celeryï¼‰
try:
    from celery import shared_task
    
    @shared_task(name="knowledge_graph.generate_daily_snapshots")
    def celery_generate_daily_snapshots():
        """Celery ä»»åŠ¡åŒ…è£…"""
        return asyncio.run(generate_daily_snapshots())
    
    @shared_task(name="knowledge_graph.generate_snapshot_for_user")
    def celery_generate_snapshot_for_user(user_id: str, subject: str):
        """Celery ä»»åŠ¡åŒ…è£… - æ‰‹åŠ¨è§¦å‘"""
        return asyncio.run(generate_snapshot_for_user(user_id, subject))
        
except ImportError:
    logger.warning("Celery æœªå®‰è£…ï¼Œè·³è¿‡ Celery ä»»åŠ¡å®šä¹‰")


# å‘½ä»¤è¡Œæ‰§è¡Œå…¥å£
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="çŸ¥è¯†å›¾è°±å¿«ç…§ä»»åŠ¡")
    parser.add_argument(
        "--user-id",
        type=str,
        help="æŒ‡å®šç”¨æˆ·IDï¼ˆæ‰‹åŠ¨ç”Ÿæˆå¿«ç…§ï¼‰"
    )
    parser.add_argument(
        "--subject",
        type=str,
        help="æŒ‡å®šå­¦ç§‘ï¼ˆæ‰‹åŠ¨ç”Ÿæˆå¿«ç…§ï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.user_id and args.subject:
        # æ‰‹åŠ¨ç”Ÿæˆå•ä¸ªç”¨æˆ·å¿«ç…§
        result = asyncio.run(generate_snapshot_for_user(args.user_id, args.subject))
        print(f"æ‰§è¡Œç»“æœ: {result}")
    else:
        # æ‰¹é‡ç”Ÿæˆå¿«ç…§
        stats = asyncio.run(generate_daily_snapshots())
        print(f"æ‰§è¡Œç»Ÿè®¡: {stats}")
