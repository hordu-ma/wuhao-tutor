"""
å­¦ä¹ é—®ç­”æœåŠ¡
åŸºäºç™¾ç‚¼AIçš„æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹æœåŠ¡
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional, Tuple

from sqlalchemy import and_, desc, func, join, or_, select
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.orm import selectinload

from src.core.config import get_settings
from src.core.exceptions import (
    BailianServiceError,
    NotFoundError,
    ServiceError,
    ValidationError,
)
from src.models.homework import HomeworkReview, HomeworkSubmission
from src.models.learning import (
    Answer,
    ChatSession,
    LearningAnalytics,
    Question,
    QuestionType,
    SessionStatus,
)
from src.models.user import User
from src.repositories.base_repository import BaseRepository
from src.schemas.learning import (
    AnswerResponse,
    AskQuestionRequest,
    AskQuestionResponse,
    CreateSessionRequest,
    FeedbackRequest,
    LearningAnalyticsResponse,
    PaginatedResponse,
    QuestionHistoryQuery,
    QuestionResponse,
    SessionListQuery,
    SessionResponse,
)
from src.services.bailian_service import (
    AIContext,
    BailianService,
    ChatMessage,
    MessageRole,
    get_bailian_service,
)
from src.utils.cache import cache_key, cache_result
from src.utils.type_converters import (
    extract_orm_bool,
    extract_orm_int,
    extract_orm_str,
    extract_orm_uuid_str,
    safe_str,
    wrap_orm,
)

logger = logging.getLogger("learning_service")
settings = get_settings()


class LearningService:
    """å­¦ä¹ é—®ç­”æœåŠ¡"""

    def __init__(self, db: AsyncSession):
        self.db = db
        self.bailian_service = get_bailian_service()

        # åˆå§‹åŒ–ä»“å‚¨
        self.session_repo = BaseRepository(ChatSession, db)
        self.question_repo = BaseRepository(Question, db)
        self.answer_repo = BaseRepository(Answer, db)
        self.analytics_repo = BaseRepository(LearningAnalytics, db)

    # ========== é—®ç­”æ ¸å¿ƒåŠŸèƒ½ ==========

    async def ask_question(
        self, user_id: str, request: AskQuestionRequest
    ) -> AskQuestionResponse:
        """
        æé—®åŠŸèƒ½

        Args:
            user_id: ç”¨æˆ·ID
            request: æé—®è¯·æ±‚

        Returns:
            AskQuestionResponse: é—®ç­”å“åº”
        """
        start_time = time.time()

        try:
            # 1. è·å–æˆ–åˆ›å»ºä¼šè¯
            session = await self._get_or_create_session(user_id, request)

            # 2. ä¿å­˜é—®é¢˜
            question = await self._save_question(
                user_id, extract_orm_uuid_str(session, "id"), request
            )

            # 3. æ„å»ºAIä¸Šä¸‹æ–‡
            ai_context = await self._build_ai_context(
                user_id, session, request.use_context
            )

            # 4. æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = await self._build_conversation_messages(
                extract_orm_uuid_str(session, "id"),
                request,
                ai_context,
                request.include_history,
                request.max_history,
            )

            # 5. è°ƒç”¨AIç”Ÿæˆç­”æ¡ˆ
            # Convert ChatMessage objects to dict format if needed
            message_dicts = []
            for msg in messages:
                if hasattr(msg, "role") and hasattr(msg, "content"):
                    message_dicts.append(
                        {"role": msg.role.value, "content": msg.content}
                    )
                else:
                    message_dicts.append(msg)

            ai_response = await self.bailian_service.chat_completion(
                messages=message_dicts,
                context=ai_context,
                max_tokens=settings.AI_MAX_TOKENS,
                temperature=settings.AI_TEMPERATURE,
                top_p=settings.AI_TOP_P,
            )

            if not ai_response.success:
                raise BailianServiceError(f"AIè°ƒç”¨å¤±è´¥: {ai_response.error_message}")

            # 6. ä¿å­˜ç­”æ¡ˆ
            answer = await self._save_answer(
                extract_orm_uuid_str(question, "id"), ai_response
            )

            # 7. æ›´æ–°ä¼šè¯ç»Ÿè®¡
            await self._update_session_stats(
                extract_orm_uuid_str(session, "id"), ai_response.tokens_used
            )

            # 8. æ›´æ–°ç”¨æˆ·å­¦ä¹ åˆ†æ
            await self._update_learning_analytics(user_id, question, answer)

            # 9. æ„å»ºå“åº”
            processing_time = int((time.time() - start_time) * 1000)

            return AskQuestionResponse(
                question=QuestionResponse.model_validate(question),
                answer=AnswerResponse.model_validate(answer),
                session=SessionResponse.model_validate(session),
                processing_time=processing_time,
                tokens_used=ai_response.tokens_used,
            )

        except Exception as e:
            logger.error(
                f"æé—®å¤„ç†å¤±è´¥: {str(e)}", extra={"user_id": user_id}, exc_info=True
            )

            # æ›´æ–°é—®é¢˜çŠ¶æ€ä¸ºå¤±è´¥
            try:
                # å®‰å…¨åœ°è·å–questionå˜é‡
                question_var = locals().get("question")
                if question_var is not None:
                    await self.question_repo.update(
                        extract_orm_uuid_str(question_var, "id"),
                        {"is_processed": False},
                    )
            except:
                pass  # Ignore update errors during exception handling

            raise ServiceError(f"æé—®å¤„ç†å¤±è´¥: {str(e)}") from e

    async def _get_or_create_session(
        self, user_id: str, request: AskQuestionRequest
    ) -> ChatSession:
        """è·å–æˆ–åˆ›å»ºä¼šè¯"""
        if request.session_id:
            # è·å–ç°æœ‰ä¼šè¯
            session = await self.session_repo.get_by_id(request.session_id)
            if not session or extract_orm_uuid_str(session, "user_id") != user_id:
                raise NotFoundError("ä¼šè¯ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")

            # æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
            if extract_orm_bool(session, "status") == SessionStatus.ACTIVE.value:
                # ä¼šè¯æ´»è·ƒï¼Œæ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
                await self.session_repo.update(
                    extract_orm_uuid_str(session, "id"),
                    {"last_active_at": datetime.now().isoformat()},
                )

            return session
        else:
            # åˆ›å»ºæ–°ä¼šè¯
            session_title = await self._generate_session_title(request.content)
            session_data = {
                "user_id": user_id,
                "title": session_title,
                "subject": request.subject.value if request.subject else None,
                "status": SessionStatus.ACTIVE.value,
                "context_enabled": request.use_context,
                "last_active_at": datetime.utcnow().isoformat(),
            }
            return await self.session_repo.create(session_data)

    async def _generate_session_title(self, first_question: str) -> str:
        """ç”Ÿæˆä¼šè¯æ ‡é¢˜"""
        # ç®€å•çš„æ ‡é¢˜ç”Ÿæˆé€»è¾‘ï¼Œå–é—®é¢˜å‰30ä¸ªå­—ç¬¦
        title = first_question[:30]
        if len(first_question) > 30:
            title += "..."
        return title

    async def _save_question(
        self, user_id: str, session_id: str, request: AskQuestionRequest
    ) -> Question:
        """ä¿å­˜é—®é¢˜"""
        question_data = {
            "session_id": session_id,
            "user_id": user_id,
            "content": request.content,
            "question_type": (
                request.question_type.value if request.question_type else None
            ),
            "subject": request.subject.value if request.subject else None,
            "topic": request.topic,
            "difficulty_level": (
                request.difficulty_level.value if request.difficulty_level else None
            ),
            "context_data": (
                json.dumps(request.context_data) if request.context_data else None
            ),
            "has_images": bool(request.image_urls),
            "image_urls": (
                json.dumps(request.image_urls) if request.image_urls else None
            ),
            "is_processed": False,
        }
        return await self.question_repo.create(question_data)

    async def _build_ai_context(
        self, user_id: str, session: ChatSession, use_context: bool = True
    ) -> AIContext:
        """æ„å»ºAIè°ƒç”¨ä¸Šä¸‹æ–‡ï¼Œé›†æˆMCPä¸ªæ€§åŒ–å­¦æƒ…åˆ†æ"""
        context = AIContext(
            user_id=user_id,
            subject=extract_orm_str(session, "subject"),
            session_id=extract_orm_uuid_str(session, "id"),
        )

        if use_context:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_stmt = select(User).where(User.id == user_id)
            user_result = await self.db.execute(user_stmt)
            user = user_result.scalar_one_or_none()

            if user:
                context.grade_level = self._parse_grade_level(
                    extract_orm_str(user, "grade_level")
                )
                context.metadata = {
                    "user_school": extract_orm_str(user, "school"),
                    "user_class": extract_orm_str(user, "class_name"),
                    "learning_subjects": extract_orm_str(user, "study_subjects"),
                }

            # ğŸš€ NEW: é›†æˆ MCP ä¸ªæ€§åŒ–å­¦æƒ…ä¸Šä¸‹æ–‡
            try:
                from src.services.knowledge_context_builder import (
                    knowledge_context_builder,
                )

                # æ„å»ºç”¨æˆ·å­¦æƒ…ä¸Šä¸‹æ–‡
                learning_context = await knowledge_context_builder.build_context(
                    user_id=user_id,
                    subject=extract_orm_str(session, "subject"),
                    session_type="learning",
                )

                # å°†å­¦æƒ…åˆ†æç»“æœæ·»åŠ åˆ°AIä¸Šä¸‹æ–‡ä¸­
                if learning_context.weak_knowledge_points:
                    weak_points_summary = []
                    for point in learning_context.weak_knowledge_points[
                        :5
                    ]:  # å–å‰5ä¸ªæœ€ä¸¥é‡çš„
                        weak_points_summary.append(
                            {
                                "knowledge": point.knowledge_name,
                                "subject": point.subject,
                                "error_rate": round(point.error_rate * 100, 1),
                                "severity": round(point.severity_score * 100, 1),
                            }
                        )

                    context.metadata = context.metadata or {}
                    context.metadata.update(
                        {
                            "weak_knowledge_points": weak_points_summary,
                            "learning_pace": learning_context.learning_preferences.learning_pace,
                            "focus_duration": learning_context.learning_preferences.focus_duration,
                            "current_level": learning_context.context_summary.current_level,
                            "total_questions": learning_context.context_summary.total_questions,
                            "learning_streak": learning_context.context_summary.learning_streak,
                            "mcp_context_generated": True,
                        }
                    )

                    logger.info(
                        f"MCPä¸Šä¸‹æ–‡å·²æ„å»º - ç”¨æˆ·: {user_id}, è–„å¼±çŸ¥è¯†ç‚¹: {len(learning_context.weak_knowledge_points)}"
                    )
                else:
                    # æ–°ç”¨æˆ·æˆ–æ²¡æœ‰è¶³å¤Ÿæ•°æ®ï¼Œæ ‡è®°ä¸ºé¦–æ¬¡å­¦ä¹ 
                    context.metadata = context.metadata or {}
                    context.metadata.update(
                        {
                            "mcp_context_generated": True,
                            "is_new_learner": True,
                            "current_level": "beginner",
                        }
                    )
                    logger.info(f"MCPä¸Šä¸‹æ–‡å·²æ„å»º - æ–°å­¦ä¹ è€…: {user_id}")

            except Exception as e:
                logger.warning(f"MCPä¸Šä¸‹æ–‡æ„å»ºå¤±è´¥ï¼Œå›é€€åˆ°ä¼ ç»Ÿæ¨¡å¼: {str(e)}")
                # ç»§ç»­ä½¿ç”¨ä¼ ç»Ÿä¸Šä¸‹æ–‡ï¼Œä¸å½±å“ä¸»æµç¨‹
                context.metadata = context.metadata or {}
                context.metadata["mcp_context_failed"] = True

            # è·å–ç›¸å…³ä½œä¸šå†å²ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
            homework_context = await self._get_homework_context(
                user_id, extract_orm_str(session, "subject")
            )
            if homework_context:
                context.metadata = context.metadata or {}
                context.metadata.update(homework_context)

        return context

    def _parse_grade_level(self, grade_level: Optional[str]) -> Optional[int]:
        """è§£æå­¦æ®µä¸ºæ•°å­—"""
        if not grade_level:
            return None

        grade_mapping = {
            "junior_1": 7,
            "junior_2": 8,
            "junior_3": 9,
            "senior_1": 10,
            "senior_2": 11,
            "senior_3": 12,
        }
        return grade_mapping.get(grade_level)

    async def _get_homework_context(
        self, user_id: str, subject: Optional[str]
    ) -> Optional[Dict[str, Any]]:
        """è·å–ä½œä¸šç›¸å…³ä¸Šä¸‹æ–‡"""
        try:
            # è·å–æœ€è¿‘çš„ä½œä¸šè®°å½•
            stmt = (
                select(HomeworkSubmission)
                .options(selectinload(HomeworkSubmission.reviews))
                .where(HomeworkSubmission.user_id == user_id)
                .order_by(desc(HomeworkSubmission.created_at))
                .limit(5)
            )

            if subject:
                stmt = stmt.where(HomeworkSubmission.subject == subject)

            result = await self.db.execute(stmt)
            submissions = result.scalars().all()

            if not submissions:
                return None

            # åˆ†æé”™é¢˜å’ŒçŸ¥è¯†ç‚¹
            wrong_topics = []
            mastered_topics = []

            for submission in submissions:
                for review in submission.reviews:
                    if hasattr(review, "knowledge_points") and review.knowledge_points:
                        points = json.loads(review.knowledge_points)
                        if review.score and review.score < 80:  # å‡è®¾80åˆ†ä»¥ä¸‹ä¸ºé”™é¢˜
                            wrong_topics.extend(points)
                        else:
                            mastered_topics.extend(points)

            return {
                "recent_homework_count": len(submissions),
                "weak_knowledge_points": list(set(wrong_topics))[:10],
                "strong_knowledge_points": list(set(mastered_topics))[:10],
            }

        except Exception as e:
            logger.warning(f"è·å–ä½œä¸šä¸Šä¸‹æ–‡å¤±è´¥: {str(e)}")
            return None

    async def _build_conversation_messages(
        self,
        session_id: str,
        request: AskQuestionRequest,
        context: AIContext,
        include_history: bool = True,
        max_history: int = 10,
    ) -> List[ChatMessage]:
        """æ„å»ºå¯¹è¯æ¶ˆæ¯"""
        messages = []

        # 1. ç³»ç»Ÿæç¤ºè¯
        system_prompt = await self._build_system_prompt(context)
        messages.append(ChatMessage(role=MessageRole.SYSTEM, content=system_prompt))

        # 2. å†å²å¯¹è¯
        if include_history and max_history > 0:
            history_messages = await self._get_conversation_history(
                session_id, max_history
            )
            messages.extend(history_messages)

        # 3. å½“å‰é—®é¢˜
        user_message = request.content

        # å¦‚æœæœ‰å›¾ç‰‡ï¼Œæ·»åŠ å›¾ç‰‡æè¿°
        if request.image_urls:
            user_message += f"\n\n[ç”¨æˆ·ä¸Šä¼ äº†{len(request.image_urls)}å¼ å›¾ç‰‡]"

        messages.append(ChatMessage(role=MessageRole.USER, content=user_message))

        return messages

    async def _build_system_prompt(self, context: AIContext) -> str:
        """æ„å»ºç³»ç»Ÿæç¤ºè¯"""
        prompt_parts = [
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„K12å­¦ä¹ åŠ©æ•™ï¼Œåå«'äº”å¥½åŠ©æ•™'ï¼Œä¸“é—¨å¸®åŠ©åˆé«˜ä¸­å­¦ç”Ÿè§£å†³å­¦ä¹ é—®é¢˜ã€‚",
            "",
            "ä½ çš„èŒè´£åŒ…æ‹¬ï¼š",
            "1. å›ç­”å­¦ç§‘é—®é¢˜ï¼Œæä¾›æ¸…æ™°æ˜“æ‡‚çš„è§£é‡Š",
            "2. åˆ†æé¢˜ç›®ï¼Œæä¾›è¯¦ç»†çš„è§£é¢˜æ­¥éª¤",
            "3. æä¾›å­¦ä¹ æ–¹æ³•å’ŒæŠ€å·§å»ºè®®",
            "4. é¼“åŠ±å­¦ç”Ÿç§¯æå­¦ä¹ ï¼Œå»ºç«‹å­¦ä¹ ä¿¡å¿ƒ",
            "",
            "å›ç­”è¦æ±‚ï¼š",
            "1. ç”¨è¯­äº²åˆ‡å‹å¥½ï¼Œé€‚åˆä¸­å­¦ç”Ÿç†è§£",
            "2. é‡ç‚¹çŸ¥è¯†ç”¨**ç²—ä½“**æ ‡å‡º",
            "3. å¤æ‚æ¦‚å¿µè¦ä¸¾ä¾‹è¯´æ˜",
            "4. å¦‚æœæ˜¯æ•°å­¦é¢˜ï¼Œè¦å†™å‡ºè¯¦ç»†æ­¥éª¤",
            "5. å›ç­”å®Œé—®é¢˜åï¼Œå¯ä»¥æ¨èç›¸å…³çš„ç»ƒä¹ é¢˜å‹",
        ]

        # æ·»åŠ ç”¨æˆ·ä¸Šä¸‹æ–‡
        if context.grade_level:
            grade_name = self._get_grade_name(context.grade_level)
            prompt_parts.append(f"\nå­¦ç”Ÿå½“å‰å­¦æ®µï¼š{grade_name}")

        if context.subject:
            subject_name = self._get_subject_name(context.subject)
            prompt_parts.append(f"å½“å‰å­¦ç§‘ï¼š{subject_name}")

        if context.metadata:
            if context.metadata.get("user_school"):
                prompt_parts.append(f"å­¦ç”Ÿå­¦æ ¡ï¼š{context.metadata['user_school']}")

            if context.metadata.get("weak_knowledge_points"):
                weak_points = context.metadata["weak_knowledge_points"][:3]  # å–å‰3ä¸ª
                # weak_points æ˜¯ WeakKnowledgePoint å¯¹è±¡æˆ–å­—å…¸åˆ—è¡¨,éœ€è¦æå– knowledge_name
                if weak_points:
                    point_names = []
                    for point in weak_points:
                        if isinstance(point, dict):
                            point_names.append(point.get("knowledge_name", str(point)))
                        elif hasattr(point, "knowledge_name"):
                            point_names.append(point.knowledge_name)
                        else:
                            point_names.append(str(point))
                    if point_names:
                        prompt_parts.append(f"å­¦ç”Ÿè–„å¼±çŸ¥è¯†ç‚¹ï¼š{', '.join(point_names)}")

        prompt_parts.append("\nè¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œä¸ºå­¦ç”Ÿæä¾›ä¸ªæ€§åŒ–çš„å­¦ä¹ æŒ‡å¯¼ã€‚")

        return "\n".join(prompt_parts)

    def _get_grade_name(self, grade_level: int) -> str:
        """è·å–å­¦æ®µåç§°"""
        grade_mapping = {
            7: "åˆä¸€",
            8: "åˆäºŒ",
            9: "åˆä¸‰",
            10: "é«˜ä¸€",
            11: "é«˜äºŒ",
            12: "é«˜ä¸‰",
        }
        return grade_mapping.get(grade_level, f"å­¦æ®µ{grade_level}")

    def _get_subject_name(self, subject: str) -> str:
        """è·å–å­¦ç§‘åç§°"""
        subject_mapping = {
            "math": "æ•°å­¦",
            "chinese": "è¯­æ–‡",
            "english": "è‹±è¯­",
            "physics": "ç‰©ç†",
            "chemistry": "åŒ–å­¦",
            "biology": "ç”Ÿç‰©",
            "history": "å†å²",
            "geography": "åœ°ç†",
            "politics": "æ”¿æ²»",
        }
        return subject_mapping.get(subject, subject)

    async def _get_conversation_history(
        self, session_id: str, max_count: int
    ) -> List[ChatMessage]:
        """è·å–å¯¹è¯å†å²"""
        try:
            # è·å–æœ€è¿‘çš„é—®ç­”å¯¹
            stmt = (
                select(Question)
                .options(selectinload(Question.answer))
                .where(Question.session_id == session_id, Question.is_processed == True)
                .order_by(desc(Question.created_at))
                .limit(max_count)
            )

            result = await self.db.execute(stmt)
            questions = result.scalars().all()

            messages = []

            # æŒ‰æ—¶é—´æ­£åºæ’åˆ—ï¼ˆæ—§çš„åœ¨å‰ï¼‰
            for question in reversed(questions):
                messages.append(
                    ChatMessage(
                        role=MessageRole.USER,
                        content=extract_orm_str(question, "content"),
                    )
                )

                if question.answer:
                    messages.append(
                        ChatMessage(
                            role=MessageRole.ASSISTANT,
                            content=extract_orm_str(question.answer, "content"),
                        )
                    )

            return messages

        except Exception as e:
            logger.warning(f"è·å–å¯¹è¯å†å²å¤±è´¥: {str(e)}")
            return []

    async def _save_answer(self, question_id: str, ai_response) -> Answer:
        """ä¿å­˜AIç­”æ¡ˆ"""
        # åˆ†æç­”æ¡ˆç”Ÿæˆæ¨èå†…å®¹
        related_topics, suggested_questions = await self._analyze_answer_content(
            ai_response.content
        )

        answer_data = {
            "question_id": question_id,
            "content": ai_response.content,
            "model_name": ai_response.model,
            "tokens_used": ai_response.tokens_used,
            "generation_time": int(ai_response.processing_time * 1000),
            "confidence_score": 85,  # é»˜è®¤ç½®ä¿¡åº¦ï¼Œåç»­å¯é€šè¿‡åˆ†ææ”¹è¿›
            "related_topics": json.dumps(related_topics) if related_topics else None,
            "suggested_questions": (
                json.dumps(suggested_questions) if suggested_questions else None
            ),
        }

        answer = await self.answer_repo.create(answer_data)

        # æ›´æ–°é—®é¢˜çŠ¶æ€
        await self.question_repo.update(question_id, {"is_processed": True})

        return answer

    async def _analyze_answer_content(
        self, content: str
    ) -> Tuple[List[str], List[str]]:
        """åˆ†æç­”æ¡ˆå†…å®¹ï¼Œæå–ç›¸å…³è¯é¢˜å’Œæ¨èé—®é¢˜"""
        # è¿™é‡Œæ˜¯ç®€åŒ–çš„åˆ†æé€»è¾‘ï¼Œå®é™…å¯ä»¥ä½¿ç”¨NLPæŠ€æœ¯æ”¹è¿›
        related_topics = []
        suggested_questions = []

        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå¯ä»¥åç»­æ”¹è¿›ï¼‰
        if "äºŒæ¬¡å‡½æ•°" in content:
            related_topics.extend(["äºŒæ¬¡å‡½æ•°", "å‡½æ•°å›¾è±¡", "é…æ–¹æ³•"])
            suggested_questions.extend(
                ["å¦‚ä½•æ±‚äºŒæ¬¡å‡½æ•°çš„å¯¹ç§°è½´ï¼Ÿ", "äºŒæ¬¡å‡½æ•°çš„æœ€å€¼æ€ä¹ˆæ±‚ï¼Ÿ"]
            )
        elif "åŒ–å­¦æ–¹ç¨‹å¼" in content:
            related_topics.extend(["åŒ–å­¦æ–¹ç¨‹å¼", "åŒ–å­¦ååº”", "é…å¹³"])
            suggested_questions.extend(["å¦‚ä½•é…å¹³åŒ–å­¦æ–¹ç¨‹å¼ï¼Ÿ", "åŒ–å­¦ååº”ç±»å‹æœ‰å“ªäº›ï¼Ÿ"])

        return related_topics[:5], suggested_questions[:3]  # é™åˆ¶æ•°é‡

    async def _update_session_stats(self, session_id: str, tokens_used: int) -> None:
        """æ›´æ–°ä¼šè¯ç»Ÿè®¡"""
        session = await self.session_repo.get_by_id(session_id)
        if session:
            # æ›´æ–°ä¼šè¯ç»Ÿè®¡ä¿¡æ¯
            current_tokens = extract_orm_int(session, "total_tokens", 0) or 0
            current_question_count = extract_orm_int(session, "question_count", 0) or 0
            session_id_str = extract_orm_uuid_str(session, "id")

            await self.session_repo.update(
                session_id_str,
                {
                    "total_tokens": current_tokens + tokens_used,
                    "question_count": current_question_count + 1,  # å¢åŠ é—®é¢˜è®¡æ•°
                    "last_active_at": datetime.now().isoformat(),
                },
            )

    async def _update_learning_analytics(
        self, user_id: str, question: Question, answer: Answer
    ) -> None:
        """æ›´æ–°ç”¨æˆ·å­¦ä¹ åˆ†æ"""
        try:
            # è·å–æˆ–åˆ›å»ºå­¦ä¹ åˆ†æè®°å½•
            analytics = await self.analytics_repo.get_by_field("user_id", user_id)
            if not analytics:
                analytics_data = {
                    "user_id": user_id,
                    "total_questions": 1,
                    "total_sessions": 1,
                    "last_analyzed_at": datetime.utcnow().isoformat(),
                }
                await self.analytics_repo.create(analytics_data)
            else:
                # æ›´æ–°ç»Ÿè®¡
                await self.analytics_repo.update(
                    extract_orm_uuid_str(analytics, "id"),
                    {
                        "total_questions": (
                            extract_orm_int(analytics, "total_questions", 0) or 0
                        )
                        + 1,
                        "last_analyzed_at": datetime.utcnow().isoformat(),
                    },
                )

        except Exception as e:
            logger.warning(f"æ›´æ–°å­¦ä¹ åˆ†æå¤±è´¥: {str(e)}")

    # ========== ä¼šè¯ç®¡ç†åŠŸèƒ½ ==========

    async def create_session(
        self, user_id: str, request: CreateSessionRequest
    ) -> SessionResponse:
        """åˆ›å»ºæ–°ä¼šè¯"""
        session_data = {
            "user_id": user_id,
            "title": request.title,
            "subject": request.subject.value if request.subject else None,
            "grade_level": request.grade_level,
            "status": SessionStatus.ACTIVE.value,
            "context_enabled": request.context_enabled,
            "last_active_at": datetime.utcnow().isoformat(),
        }

        session = await self.session_repo.create(session_data)

        # å¦‚æœæœ‰åˆå§‹é—®é¢˜ï¼Œå¤„ç†ç¬¬ä¸€ä¸ªé—®é¢˜
        if request.initial_question:
            ask_request = AskQuestionRequest(
                content=request.initial_question,
                session_id=extract_orm_uuid_str(session, "id"),
                subject=request.subject,
                topic=None,
                difficulty_level=None,
            )
            await self.ask_question(user_id, ask_request)

        return SessionResponse.model_validate(session)

    async def get_session_list(
        self, user_id: str, query: SessionListQuery
    ) -> Dict[str, Any]:
        """è·å–ä¼šè¯åˆ—è¡¨"""
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = [ChatSession.user_id == user_id]

        if query.status:
            conditions.append(ChatSession.status == safe_str(query.status))

        if query.subject:
            conditions.append(ChatSession.subject == safe_str(query.subject))

        if query.search:
            conditions.append(ChatSession.title.contains(query.search))

        # è®¡ç®—æ€»æ•°
        count_stmt = select(func.count(ChatSession.id)).where(and_(*conditions))
        total_result = await self.db.execute(count_stmt)
        total = total_result.scalar()

        # æŸ¥è¯¢æ•°æ®
        stmt = (
            select(ChatSession)
            .where(and_(*conditions))
            .order_by(desc(ChatSession.last_active_at))
            .offset((query.page - 1) * query.size)
            .limit(query.size)
        )

        result = await self.db.execute(stmt)
        sessions = result.scalars().all()

        return {
            "total": total,
            "page": query.page,
            "size": query.size,
            "pages": (
                (total + query.size - 1) // query.size if total and query.size else 0
            ),
            "items": [SessionResponse.model_validate(session) for session in sessions],
        }

    async def get_question_history(
        self, user_id: str, query: QuestionHistoryQuery
    ) -> Dict[str, Any]:
        """è·å–é—®é¢˜å†å²"""
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        conditions = [Question.user_id == user_id]

        if query.session_id:
            conditions.append(Question.session_id == query.session_id)

        if query.subject:
            conditions.append(Question.subject == safe_str(query.subject))

        if query.question_type:
            conditions.append(Question.question_type == safe_str(query.question_type))

        if query.start_date:
            conditions.append(Question.created_at >= query.start_date.isoformat())

        if query.end_date:
            conditions.append(Question.created_at <= query.end_date.isoformat())

        # è®¡ç®—æ€»æ•°
        count_stmt = select(func.count(Question.id)).where(and_(*conditions))
        total_result = await self.db.execute(count_stmt)
        total = total_result.scalar()

        # æŸ¥è¯¢æ•°æ®
        stmt = (
            select(Question)
            .options(selectinload(Question.answer))
            .where(and_(*conditions))
            .order_by(desc(Question.created_at))
            .offset((query.page - 1) * query.size)
            .limit(query.size)
        )

        result = await self.db.execute(stmt)
        questions = result.scalars().all()

        # æ„å»ºé—®ç­”å¯¹
        items = []
        for question in questions:
            item = {
                "question": QuestionResponse.model_validate(question),
                "answer": (
                    AnswerResponse.model_validate(question.answer)
                    if question.answer
                    else None
                ),
            }
            items.append(item)

        return {
            "total": total,
            "page": query.page,
            "size": query.size,
            "pages": (
                (total + query.size - 1) // query.size if total and query.size else 0
            ),
            "items": items,
        }

    # ========== åé¦ˆå’Œè¯„ä»·åŠŸèƒ½ ==========

    async def submit_feedback(self, user_id: str, request: FeedbackRequest) -> bool:
        """æäº¤ç”¨æˆ·åé¦ˆ"""
        # éªŒè¯é—®é¢˜å½’å±
        question = await self.question_repo.get_by_id(request.question_id)
        if not question or extract_orm_uuid_str(question, "user_id") != user_id:
            raise NotFoundError("é—®é¢˜ä¸å­˜åœ¨æˆ–æ— æƒé™è®¿é—®")

        if not getattr(question, "answer", None):
            raise ValidationError("é—®é¢˜å°šæœªå›ç­”ï¼Œæ— æ³•æäº¤åé¦ˆ")

        # æ›´æ–°ç­”æ¡ˆåé¦ˆ
        answer_id = extract_orm_uuid_str(question.answer, "id")
        await self.answer_repo.update(
            answer_id,
            {
                "user_rating": request.rating,
                "user_feedback": request.feedback,
                "is_helpful": request.is_helpful,
            },
        )

        logger.info(
            "ç”¨æˆ·åé¦ˆå·²ä¿å­˜",
            extra={
                "user_id": user_id,
                "question_id": request.question_id,
                "rating": request.rating,
            },
        )

        return True

    # ========== å­¦ä¹ åˆ†æåŠŸèƒ½ ==========

    @cache_result(ttl=3600)  # ç¼“å­˜1å°æ—¶
    async def get_learning_analytics(
        self, user_id: str
    ) -> Optional[LearningAnalyticsResponse]:
        """è·å–å­¦ä¹ åˆ†æ"""
        analytics = await self.analytics_repo.get_by_field("user_id", user_id)
        if not analytics:
            return None

        # è·å–è¯¦ç»†ç»Ÿè®¡æ•°æ®
        subject_stats = await self._calculate_subject_stats(user_id)
        learning_pattern = await self._analyze_learning_pattern(user_id)

        # è®¡ç®—å¹³å‡è¯„åˆ†
        avg_rating_stmt = (
            select(func.avg(Answer.user_rating))
            .select_from(join(Answer, Question, Answer.question_id == Question.id))
            .where(Question.user_id == user_id, Answer.user_rating.isnot(None))
        )

        avg_rating_result = await self.db.execute(avg_rating_stmt)
        avg_rating = avg_rating_result.scalar() or 0.0

        # è®¡ç®—æ­£é¢åé¦ˆç‡
        positive_feedback_rate = await self._calculate_positive_feedback_rate(user_id)

        # ç”Ÿæˆæ”¹è¿›å»ºè®®
        improvement_suggestions = await self._generate_improvement_suggestions(
            user_id, subject_stats
        )

        # è¯†åˆ«çŸ¥è¯†ç¼ºå£
        knowledge_gaps = await self._identify_knowledge_gaps(user_id)

        # Get basic stats from analytics if available
        if analytics:
            total_questions = extract_orm_int(analytics, "total_questions", 0) or 0
            total_sessions = extract_orm_int(analytics, "total_sessions", 0) or 0
        else:
            total_questions = 0
            total_sessions = 0

        # Create a simple learning pattern
        from src.schemas.learning import DifficultyLevel, LearningPattern

        learning_pattern = LearningPattern(
            most_active_hour=14,
            most_active_day=1,
            avg_session_length=30,
            preferred_difficulty=DifficultyLevel.MEDIUM,
        )

        return LearningAnalyticsResponse(
            user_id=user_id,
            total_questions=total_questions,
            total_sessions=total_sessions,
            subject_stats=[],  # Simplified - needs proper conversion
            learning_pattern=learning_pattern,
            avg_rating=3.5,
            positive_feedback_rate=75,
            improvement_suggestions=["éœ€è¦æ›´å¤šç»ƒä¹ "],  # Simplified
            knowledge_gaps=["åŸºç¡€æ¦‚å¿µ"],  # Simplified
            last_analyzed_at=datetime.now(),
        )

    async def _calculate_subject_stats(self, user_id: str) -> List[Dict[str, Any]]:
        """è®¡ç®—å„å­¦ç§‘ç»Ÿè®¡"""
        # ç®€åŒ–å®ç°ï¼Œè¿”å›åŸºæœ¬ç»Ÿè®¡
        stmt = (
            select(
                Question.subject,
                func.count(Question.id).label("question_count"),
                func.avg(Question.difficulty_level).label("avg_difficulty"),
            )
            .where(Question.user_id == user_id, Question.subject.isnot(None))
            .group_by(Question.subject)
        )

        result = await self.db.execute(stmt)
        stats = []

        for row in result:
            stats.append(
                {
                    "subject": row.subject,
                    "question_count": row.question_count,
                    "avg_difficulty": float(row.avg_difficulty or 3.0),
                    "mastery_level": 75,  # é»˜è®¤æŒæ¡åº¦ï¼Œå¯ä»¥åç»­æ”¹è¿›
                }
            )

        return stats

    async def _analyze_learning_pattern(self, user_id: str) -> Dict[str, Any]:
        """åˆ†æå­¦ä¹ æ¨¡å¼"""
        return {
            "most_active_hour": 20,  # æ™šä¸Š8ç‚¹
            "most_active_day": 0,  # å‘¨æ—¥
            "avg_session_length": 30,  # 30åˆ†é’Ÿ
            "preferred_difficulty": 3,  # ä¸­ç­‰éš¾åº¦
        }

    async def _calculate_positive_feedback_rate(self, user_id: str) -> int:
        """è®¡ç®—æ­£é¢åé¦ˆç‡"""
        total_stmt = (
            select(func.count(Answer.id))
            .select_from(join(Answer, Question, Answer.question_id == Question.id))
            .where(Question.user_id == user_id, Answer.is_helpful.isnot(None))
        )

        positive_stmt = (
            select(func.count(Answer.id))
            .select_from(join(Answer, Question, Answer.question_id == Question.id))
            .where(Question.user_id == user_id, Answer.is_helpful == True)
        )

        total_result = await self.db.execute(total_stmt)
        positive_result = await self.db.execute(positive_stmt)

        total = total_result.scalar() or 0
        positive = positive_result.scalar() or 0

        return int((positive / total * 100) if total > 0 else 0)

    async def _generate_improvement_suggestions(
        self, user_id: str, subject_stats: List[Dict[str, Any]]
    ) -> List[str]:
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        suggestions = []

        # åŸºäºå­¦ç§‘ç»Ÿè®¡ç”Ÿæˆå»ºè®®
        for stat in subject_stats:
            if stat["question_count"] < 5:
                suggestions.append(
                    f"å»ºè®®å¢åŠ {self._get_subject_name(stat['subject'])}å­¦ç§‘çš„ç»ƒä¹ "
                )

            if stat["avg_difficulty"] < 2.5:
                suggestions.append(
                    f"å¯ä»¥å°è¯•{self._get_subject_name(stat['subject'])}æ›´æœ‰æŒ‘æˆ˜æ€§çš„é—®é¢˜"
                )

        return suggestions[:5]  # æœ€å¤š5ä¸ªå»ºè®®

    async def _identify_knowledge_gaps(self, user_id: str) -> List[str]:
        """è¯†åˆ«çŸ¥è¯†ç¼ºå£"""
        # åŸºäºé”™é¢˜å’Œä½åˆ†ä½œä¸šè¯†åˆ«çŸ¥è¯†ç¼ºå£
        gaps = []

        # ä»é—®é¢˜è¯é¢˜ä¸­åˆ†æ
        stmt = (
            select(Question.topic)
            .where(Question.user_id == user_id, Question.topic.isnot(None))
            .distinct()
        )

        result = await self.db.execute(stmt)
        topics = [row[0] for row in result]

        # ç®€åŒ–é€»è¾‘ï¼šå¦‚æœæŸä¸ªè¯é¢˜é—®å¾—æ¯”è¾ƒå¤šï¼Œå¯èƒ½æ˜¯è–„å¼±ç¯èŠ‚
        return topics[:5]


# ä¾èµ–æ³¨å…¥å‡½æ•°
def get_learning_service(db: AsyncSession) -> LearningService:
    """è·å–å­¦ä¹ é—®ç­”æœåŠ¡å®ä¾‹"""
    return LearningService(db)
