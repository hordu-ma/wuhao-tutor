"""
é”™é¢˜æ‰‹å†ŒæœåŠ¡å±‚
æä¾›é”™é¢˜ç®¡ç†ã€å¤ä¹ è®¡åˆ’ã€ç»Ÿè®¡åˆ†æç­‰ä¸šåŠ¡é€»è¾‘

ä½œè€…: AI Agent
åˆ›å»ºæ—¶é—´: 2025-10-12
ç‰ˆæœ¬: v1.0
"""

import json
import logging
import re
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from uuid import UUID

from sqlalchemy.ext.asyncio import AsyncSession

from src.core.exceptions import NotFoundError, ServiceError, ValidationError
from src.models.base import is_sqlite
from src.models.study import MistakeRecord, MistakeReview
from src.repositories.mistake_repository import MistakeRepository
from src.repositories.mistake_review_repository import MistakeReviewRepository
from src.schemas.mistake import (
    CreateMistakeRequest,
    MasteryProgressResponse,
    MistakeDetailResponse,
    MistakeListItem,
    MistakeListResponse,
    MistakeStatisticsResponse,
    ReviewCompleteRequest,
    ReviewCompleteResponse,
    ReviewHistoryResponse,
    TodayReviewResponse,
    TodayReviewTask,
    UpdateMistakeRequest,
)
from src.services.algorithms.spaced_repetition import SpacedRepetitionAlgorithm

logger = logging.getLogger(__name__)


class MistakeService:
    """é”™é¢˜æœåŠ¡"""

    def __init__(self, db: AsyncSession, bailian_service=None):
        self.db = db
        self.mistake_repo = MistakeRepository(MistakeRecord, db)
        self.review_repo = MistakeReviewRepository(MistakeReview, db)
        self.algorithm = SpacedRepetitionAlgorithm()
        self.bailian_service = bailian_service

    @staticmethod
    def _safe_extract_orm(obj: Any, attr: str, default: Any = None) -> Any:
        """å®‰å…¨åœ°ä»ORMå¯¹è±¡æå–å±æ€§å€¼"""
        try:
            value = getattr(obj, attr, default)
            # å¦‚æœæ˜¯Columnå¯¹è±¡ï¼Œè¿”å›é»˜è®¤å€¼
            if hasattr(value, "__class__") and "Column" in str(type(value)):
                return default
            return value if value is not None else default
        except Exception:
            return default

    async def _to_list_item(self, mistake: MistakeRecord) -> MistakeListItem:
        """è½¬æ¢ä¸ºåˆ—è¡¨é¡¹ï¼ˆåŒ…å«çŸ¥è¯†ç‚¹å…³è”ä¿¡æ¯ï¼‰"""
        from uuid import UUID as UUIDType

        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        # åœ¨SQLiteä¸­ï¼Œæ—¥æœŸå­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼›åœ¨PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡
        # éœ€è¦å¤„ç†ä¸¤ç§æƒ…å†µ
        def to_iso_string(value):
            """å°†æ—¥æœŸå­—æ®µè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²"""
            if value is None:
                return None
            if isinstance(value, str):
                return value  # SQLiteä¸­å·²ç»æ˜¯å­—ç¬¦ä¸²
            return value.isoformat()  # PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡

        def parse_json_field(value):
            """è§£æJSONå­—æ®µï¼Œå…¼å®¹å­—ç¬¦ä¸²å’Œå·²è§£æçš„å¯¹è±¡"""
            if value is None:
                return []
            if isinstance(value, list):
                return value  # å·²ç»æ˜¯åˆ—è¡¨
            if isinstance(value, str):
                try:
                    parsed = json.loads(value)
                    return parsed if isinstance(parsed, list) else []
                except (json.JSONDecodeError, ValueError):
                    return []
            return []

        # ğŸ¯ æŸ¥è¯¢çŸ¥è¯†ç‚¹å…³è”ä¿¡æ¯ï¼ˆç”¨äºåˆ—è¡¨é¡µæ˜¾ç¤ºæŒæ¡åº¦ï¼‰
        knowledge_point_associations = []
        try:
            from src.models.knowledge_graph import MistakeKnowledgePoint
            from src.models.study import KnowledgeMastery
            from src.repositories.base_repository import BaseRepository
            from src.repositories.knowledge_graph_repository import (
                MistakeKnowledgePointRepository,
            )

            mkp_repo = MistakeKnowledgePointRepository(MistakeKnowledgePoint, self.db)
            km_repo = BaseRepository(KnowledgeMastery, self.db)

            # æŸ¥è¯¢é”™é¢˜çš„çŸ¥è¯†ç‚¹å…³è”
            mistake_id = UUID(extract_orm_uuid_str(mistake, "id"))
            associations = await mkp_repo.find_by_mistake(mistake_id)

            # åªå–å‰3ä¸ªçŸ¥è¯†ç‚¹ï¼ˆåˆ—è¡¨é¡µä¸éœ€è¦å…¨éƒ¨æ˜¾ç¤ºï¼‰
            for assoc in associations[:3]:
                kp_id = UUID(str(getattr(assoc, "knowledge_point_id")))
                mastery = await km_repo.get_by_id(str(kp_id))

                knowledge_point_associations.append(
                    {
                        "association_id": str(getattr(assoc, "id")),
                        "knowledge_point_id": str(kp_id),
                        "knowledge_point_name": (
                            getattr(mastery, "knowledge_point", "æœªçŸ¥çŸ¥è¯†ç‚¹")
                            if mastery
                            else "æœªçŸ¥çŸ¥è¯†ç‚¹"
                        ),
                        "relevance_score": float(
                            str(getattr(assoc, "relevance_score", 0.0))
                        ),
                        "is_primary": getattr(assoc, "is_primary", False),
                        "mastery_level": (
                            float(str(getattr(mastery, "mastery_level", 0.0)))
                            if mastery
                            else 0.0
                        ),
                    }
                )

        except Exception as e:
            # çŸ¥è¯†ç‚¹å…³è”æŸ¥è¯¢å¤±è´¥ä¸å½±å“åˆ—è¡¨è¿”å›
            logger.warning(f"æŸ¥è¯¢é”™é¢˜ {mistake.id} çš„çŸ¥è¯†ç‚¹å…³è”å¤±è´¥: {e}")

        return MistakeListItem(
            id=UUID(extract_orm_uuid_str(mistake, "id")),
            title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
            subject=extract_orm_str(mistake, "subject"),
            difficulty_level=extract_orm_int(mistake, "difficulty_level"),
            source=extract_orm_str(mistake, "source"),
            source_id=None,
            mastery_status=extract_orm_str(mistake, "mastery_status"),
            correct_count=extract_orm_int(mistake, "correct_count") or 0,
            total_reviews=extract_orm_int(mistake, "review_count") or 0,
            next_review_date=to_iso_string(getattr(mistake, "next_review_at", None)),
            created_at=to_iso_string(getattr(mistake, "created_at", None)) or "",
            updated_at=to_iso_string(
                getattr(mistake, "updated_at", None)
            ),  # âœ… æ·»åŠ updated_at
            knowledge_points=parse_json_field(
                getattr(mistake, "knowledge_points", None)
            ),
            knowledge_point_associations=knowledge_point_associations,  # ğŸ¯ æ·»åŠ å…³è”ä¿¡æ¯
        )

    async def _to_detail_response(
        self, mistake: MistakeRecord
    ) -> MistakeDetailResponse:
        """è½¬æ¢ä¸ºè¯¦æƒ…å“åº”"""
        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        # åœ¨SQLiteä¸­ï¼Œæ—¥æœŸå­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼›åœ¨PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡
        # éœ€è¦å¤„ç†ä¸¤ç§æƒ…å†µ
        def to_iso_string(value):
            """å°†æ—¥æœŸå­—æ®µè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²"""
            if value is None:
                return None
            if isinstance(value, str):
                return value  # SQLiteä¸­å·²ç»æ˜¯å­—ç¬¦ä¸²
            return value.isoformat()  # PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡

        def parse_json_field(value):
            """è§£æJSONå­—æ®µï¼Œå…¼å®¹å­—ç¬¦ä¸²å’Œå·²è§£æçš„å¯¹è±¡"""
            if value is None:
                return []
            if isinstance(value, list):
                return value  # å·²ç»æ˜¯åˆ—è¡¨
            if isinstance(value, str):
                try:
                    parsed = json.loads(value)
                    return parsed if isinstance(parsed, list) else []
                except (json.JSONDecodeError, ValueError):
                    return []
            return []

        # ğŸ”§ [ä¿®å¤] è§£æAIåé¦ˆè·å–é¢˜ç›®å†…å®¹å’Œè§£æ
        ai_feedback = getattr(mistake, "ai_feedback", None)
        ai_feedback_dict = {}
        ai_full_answer = None  # å®Œæ•´çš„AIå›ç­”æ–‡æœ¬ï¼ˆæ¥è‡ªanswersè¡¨ï¼‰

        if ai_feedback:
            if isinstance(ai_feedback, dict):
                ai_feedback_dict = ai_feedback
            elif isinstance(ai_feedback, str):
                try:
                    parsed = json.loads(ai_feedback)
                    ai_feedback_dict = parsed if isinstance(parsed, dict) else {}
                except (json.JSONDecodeError, ValueError):
                    pass

        # ğŸ†• [æ–¹æ¡ˆAä¼˜åŒ–] å¦‚æœæ¥è‡ªlearningæ¨¡å—ï¼Œå°è¯•ä»answersè¡¨è·å–å®Œæ•´AIå›ç­”
        source = extract_orm_str(mistake, "source")
        source_question_id = extract_orm_str(mistake, "source_question_id")

        if source == "learning" and source_question_id:
            try:
                from sqlalchemy import select

                from src.models.learning import Answer

                # æŸ¥è¯¢answersè¡¨è·å–AIçš„å®Œæ•´å›ç­”
                stmt = select(Answer.content).where(
                    Answer.question_id == source_question_id
                )
                result = await self.db.execute(stmt)
                answer_row = result.scalar_one_or_none()

                if answer_row:
                    ai_full_answer = answer_row
                    logger.info(
                        f"ä»answersè¡¨è·å–åˆ°å®Œæ•´AIå›ç­”ï¼Œé•¿åº¦: {len(ai_full_answer)} å­—ç¬¦"
                    )
            except Exception as e:
                logger.warning(f"è·å–answersè¡¨æ•°æ®å¤±è´¥: {e}")
                # é™çº§å¤„ç†ï¼Œç»§ç»­ä½¿ç”¨ai_feedback

        # æå–é¢˜ç›®å†…å®¹(ä¼˜å…ˆOCR,å…¶æ¬¡AIåˆ†æ)
        question_content = extract_orm_str(mistake, "ocr_text") or ""
        if not question_content and ai_feedback_dict:
            question_content = (
                ai_feedback_dict.get("question", "")
                or ai_feedback_dict.get("content", "")
                or ai_feedback_dict.get("é¢˜ç›®", "")
            )

        # æå–è§£æ/ç­”æ¡ˆè¯´æ˜ï¼ˆä¼˜å…ˆä½¿ç”¨å®Œæ•´AIå›ç­”ï¼‰
        explanation = ai_full_answer if ai_full_answer else None

        if not explanation and ai_feedback_dict:
            explanation = (
                ai_feedback_dict.get("analysis", "")
                or ai_feedback_dict.get("explanation", "")
                or ai_feedback_dict.get("è§£æ", "")
                or ai_feedback_dict.get("feedback", "")
            )

        # æå–æ­£ç¡®ç­”æ¡ˆ(ä¼˜å…ˆæ•°æ®åº“,å…¶æ¬¡AIåé¦ˆ)
        correct_answer = extract_orm_str(mistake, "correct_answer")
        if not correct_answer and ai_feedback_dict:
            # å°è¯•ä»å¤šä¸ªå¯èƒ½çš„å­—æ®µæå–ç­”æ¡ˆ
            correct_answer = (
                ai_feedback_dict.get("correct_answer", "")
                or ai_feedback_dict.get("answer", "")
                or ai_feedback_dict.get("æ­£ç¡®ç­”æ¡ˆ", "")
                or ai_feedback_dict.get("å‚è€ƒç­”æ¡ˆ", "")
                or ai_feedback_dict.get("æ ‡å‡†ç­”æ¡ˆ", "")
                or ai_feedback_dict.get("solution", "")
                or ai_feedback_dict.get("è§£ç­”", "")
            )

        # ğŸ”§ [æ–¹æ¡ˆA] æ™ºèƒ½ç­”æ¡ˆæå–ä¸éªŒè¯
        if correct_answer:
            correct_answer = correct_answer.strip()

            # æ£€æŸ¥æ˜¯å¦ä¸ºæ— æ•ˆå ä½ç¬¦
            is_invalid = (
                not correct_answer  # ç©ºå­—ç¬¦ä¸²
                or correct_answer
                in ["**", "*", "å°**", "***", "ï¼Ÿ", "?", "-", "--"]  # æ— æ„ä¹‰ç¬¦å·
                or (
                    len(correct_answer) <= 3
                    and all(c in "*_-?ï¼Ÿ" for c in correct_answer)
                )  # çº¯ç¬¦å·
            )

            if is_invalid and (explanation or ai_full_answer):
                # ğŸ†• ä¼˜å…ˆä»å®Œæ•´AIå›ç­”ä¸­æå–ç­”æ¡ˆ
                text_to_extract = ai_full_answer if ai_full_answer else explanation

                # å°è¯•ä»æ–‡æœ¬ä¸­æå–ç­”æ¡ˆ(ä½¿ç”¨æ­£åˆ™åŒ¹é…)
                if text_to_extract:
                    # ğŸ” å…ˆæ£€æµ‹æ˜¯å¦ä¸ºå¤šå°é¢˜é¢˜ç›®
                    multi_answer_pattern = r"âœ…\s*\*\*ç­”æ¡ˆ[ï¼š:]\s*"
                    multi_answer_matches = re.findall(
                        multi_answer_pattern, text_to_extract, re.MULTILINE
                    )

                    # å¦‚æœæœ‰å¤šä¸ªç­”æ¡ˆæ ‡è®°ï¼ˆâ‰¥2ä¸ªï¼‰ï¼Œè¯´æ˜æ˜¯å¤šå°é¢˜ï¼Œä¸æå–å•ä¸ªç­”æ¡ˆ
                    if len(multi_answer_matches) >= 2:
                        correct_answer = "ğŸ“– æœ¬é¢˜åŒ…å«å¤šä¸ªå°é¢˜ï¼Œç­”æ¡ˆè¯·å‚è€ƒè§£æ"
                        is_invalid = False
                    else:
                        # å•å°é¢˜ï¼Œå°è¯•æå–ç­”æ¡ˆ
                        patterns = [
                            r"âœ…\s*\*\*ç­”æ¡ˆ[ï¼š:]\s*(.+?)\*\*",  # Markdownæ ¼å¼
                            r"âœ…\s*ç­”æ¡ˆ[ï¼š:]\s*(.+?)(?:\n|$)",  # å¸¦å‹¾æ ¼å¼
                            r"æ­£ç¡®ç­”æ¡ˆ[ï¼š:æ˜¯ä¸º]\s*[ï¼š:]?\s*(.+?)(?:[ã€‚\nï¼›;]|$)",
                            r"æ ‡å‡†ç­”æ¡ˆ[ï¼š:æ˜¯ä¸º]\s*[ï¼š:]?\s*(.+?)(?:[ã€‚\nï¼›;]|$)",
                            r"å‚è€ƒç­”æ¡ˆ[ï¼š:æ˜¯ä¸º]\s*[ï¼š:]?\s*(.+?)(?:[ã€‚\nï¼›;]|$)",
                            r"ç­”æ¡ˆ[ï¼š:æ˜¯ä¸º]\s*[ï¼š:]?\s*(.+?)(?:[ã€‚\nï¼›;]|$)",
                        ]
                        for pattern in patterns:
                            matches = re.findall(pattern, text_to_extract, re.MULTILINE)
                            if matches:
                                # å–ç¬¬ä¸€ä¸ªåŒ¹é…
                                extracted = matches[0].strip()
                                if extracted and len(extracted) > 0:
                                    correct_answer = extracted
                                    is_invalid = False
                                    break

            # å¦‚æœä»ç„¶æ— æ•ˆ,æ ¹æ®é¢˜ç›®ç±»å‹å†³å®šæç¤ºæ–‡æœ¬
            if is_invalid:
                if ai_feedback_dict:
                    category = ai_feedback_dict.get("category", "")
                    # å¯¹äºç©ºé¢˜ç›®æˆ–ä¸»è§‚é¢˜,ç»™å‡ºå‹å¥½æç¤º
                    if category == "empty_question":
                        correct_answer = "ğŸ“ æ­¤é¢˜ç›®æš‚æ— ç­”æ¡ˆè®°å½•,è¯·æŸ¥çœ‹é¢˜ç›®å›¾ç‰‡è‡ªè¡Œç†è§£"
                    elif category in ["subjective", "essay", "discussion"]:
                        correct_answer = (
                            "ğŸ’¡ æœ¬é¢˜ä¸ºä¸»è§‚é¢˜,æ— å›ºå®šç­”æ¡ˆ,è¯·å‚è€ƒè§£æç†è§£ç­”é¢˜æ€è·¯"
                        )
                    else:
                        correct_answer = "âš ï¸ ç­”æ¡ˆè¯†åˆ«å¤±è´¥,å»ºè®®æŸ¥çœ‹è§£ææˆ–å’¨è¯¢è€å¸ˆ"
                else:
                    correct_answer = "âš ï¸ ç­”æ¡ˆè¯†åˆ«å¤±è´¥,å»ºè®®æŸ¥çœ‹è§£ææˆ–å’¨è¯¢è€å¸ˆ"

        # ã€æ–°å¢ã€‘æŸ¥è¯¢çŸ¥è¯†ç‚¹å…³è”ä¿¡æ¯
        knowledge_point_associations = []
        try:
            from src.models.knowledge_graph import MistakeKnowledgePoint
            from src.models.study import KnowledgeMastery
            from src.repositories.base_repository import BaseRepository
            from src.repositories.knowledge_graph_repository import (
                MistakeKnowledgePointRepository,
            )

            mkp_repo = MistakeKnowledgePointRepository(MistakeKnowledgePoint, self.db)
            km_repo = BaseRepository(KnowledgeMastery, self.db)

            # æŸ¥è¯¢é”™é¢˜çš„çŸ¥è¯†ç‚¹å…³è”
            mistake_id = UUID(extract_orm_uuid_str(mistake, "id"))
            associations = await mkp_repo.find_by_mistake(mistake_id)

            # æ„å»ºçŸ¥è¯†ç‚¹å…³è”è¯¦æƒ…
            for assoc in associations:
                # æŸ¥è¯¢å¯¹åº”çš„çŸ¥è¯†ç‚¹æŒæ¡åº¦ä¿¡æ¯
                kp_id = UUID(str(getattr(assoc, "knowledge_point_id")))
                mastery = await km_repo.get_by_id(str(kp_id))

                knowledge_point_associations.append(
                    {
                        "association_id": str(getattr(assoc, "id")),
                        "knowledge_point_id": str(kp_id),
                        "knowledge_point_name": (
                            getattr(mastery, "knowledge_point", "æœªçŸ¥çŸ¥è¯†ç‚¹")
                            if mastery
                            else "æœªçŸ¥çŸ¥è¯†ç‚¹"
                        ),
                        "relevance_score": float(
                            str(getattr(assoc, "relevance_score", 0.0))
                        ),
                        "is_primary": getattr(assoc, "is_primary", False),
                        "error_type": getattr(assoc, "error_type", ""),
                        "error_reason": getattr(assoc, "error_reason"),
                        "mastery_level": (
                            float(str(getattr(mastery, "mastery_level", 0.0)))
                            if mastery
                            else 0.0
                        ),
                        "mastered": getattr(assoc, "mastered_after_review", False),
                        "review_count": getattr(assoc, "review_count", 0),
                        "last_review_result": getattr(assoc, "last_review_result"),
                    }
                )

            logger.debug(
                f"ä¸ºé”™é¢˜ {mistake_id} é™„åŠ äº† {len(knowledge_point_associations)} ä¸ªçŸ¥è¯†ç‚¹å…³è”"
            )
        except Exception as e:
            # çŸ¥è¯†ç‚¹å…³è”æŸ¥è¯¢å¤±è´¥ä¸å½±å“é”™é¢˜è¯¦æƒ…è¿”å›
            logger.warning(f"æŸ¥è¯¢çŸ¥è¯†ç‚¹å…³è”å¤±è´¥: {e}")

        # ï¿½ğŸ› ï¸ ä½¿ç”¨extract_orm_*å‡½æ•°æå–ORMå¯¹è±¡çš„å€¼
        return MistakeDetailResponse(
            id=UUID(extract_orm_uuid_str(mistake, "id")),
            title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
            description=None,
            subject=extract_orm_str(mistake, "subject"),
            difficulty_level=extract_orm_int(mistake, "difficulty_level"),
            source=extract_orm_str(mistake, "source"),
            source_id=None,
            question_content=question_content or "æš‚æ— é¢˜ç›®å†…å®¹",
            student_answer=extract_orm_str(mistake, "student_answer") or None,
            correct_answer=correct_answer or None,
            explanation=explanation,  # ğŸ”§ ä»AIåé¦ˆæå–
            knowledge_points=parse_json_field(
                getattr(mistake, "knowledge_points", None)
            ),
            mastery_status=extract_orm_str(mistake, "mastery_status"),
            correct_count=extract_orm_int(mistake, "correct_count") or 0,
            total_reviews=extract_orm_int(mistake, "review_count") or 0,
            next_review_date=to_iso_string(getattr(mistake, "next_review_at", None)),
            created_at=to_iso_string(getattr(mistake, "created_at", None)) or "",
            updated_at=to_iso_string(getattr(mistake, "updated_at", None)) or "",
            image_urls=parse_json_field(getattr(mistake, "image_urls", None)),
            knowledge_point_associations=knowledge_point_associations,  # ğŸ”§ æ–°å¢å­—æ®µ
        )

    async def get_mistake_list(
        self,
        user_id: UUID,
        page: int,
        page_size: int,
        filters: Optional[Dict] = None,
    ) -> MistakeListResponse:
        """
        è·å–é”™é¢˜åˆ—è¡¨

        Args:
            user_id: ç”¨æˆ·ID
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            filters: ç­›é€‰æ¡ä»¶ï¼ˆsubject, mastery_status, knowledge_pointç­‰ï¼‰

        Returns:
            é”™é¢˜åˆ—è¡¨å“åº”
        """
        subject = filters.get("subject") if filters else None
        mastery_status = filters.get("mastery_status") if filters else None
        knowledge_point = filters.get("knowledge_point") if filters else None
        knowledge_point_id = filters.get("knowledge_point_id") if filters else None
        category = filters.get("category") if filters else None
        source = filters.get("source") if filters else None

        # ã€æ–°å¢ã€‘å¦‚æœæŒ‡å®šäº† knowledge_pointï¼ˆåç§°ï¼‰ï¼Œå…ˆæŸ¥è¯¢å¯¹åº”çš„ knowledge_point_id
        if knowledge_point and not knowledge_point_id:
            try:
                from sqlalchemy import and_, select

                from src.models.study import KnowledgeMastery

                # æŸ¥è¯¢è¯¥ç”¨æˆ·è¯¥å­¦ç§‘è¯¥çŸ¥è¯†ç‚¹çš„æŒæ¡åº¦è®°å½•
                stmt = select(KnowledgeMastery.id).where(
                    and_(
                        KnowledgeMastery.user_id == str(user_id),
                        KnowledgeMastery.knowledge_point == knowledge_point,
                    )
                )
                if subject:
                    stmt = stmt.where(KnowledgeMastery.subject == subject)

                result = await self.db.execute(stmt)
                kp_id = result.scalar_one_or_none()

                if kp_id:
                    knowledge_point_id = str(kp_id)
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°è¯¥çŸ¥è¯†ç‚¹ï¼Œè¿”å›ç©ºåˆ—è¡¨
                    logger.info(
                        f"ç”¨æˆ· {user_id} åœ¨å­¦ç§‘ {subject} ä¸­æœªæ‰¾åˆ°çŸ¥è¯†ç‚¹ {knowledge_point}"
                    )
                    return MistakeListResponse(
                        items=[], total=0, page=page, page_size=page_size
                    )
            except Exception as e:
                logger.warning(f"æŸ¥è¯¢çŸ¥è¯†ç‚¹IDå¤±è´¥: {e}ï¼Œé™çº§åˆ°æ™®é€šæŸ¥è¯¢")
                knowledge_point_id = None

        # ã€æ–°å¢ã€‘å¦‚æœæŒ‡å®šäº† knowledge_point_idï¼Œä½¿ç”¨æ–°çš„æŸ¥è¯¢æ–¹æ³•
        if knowledge_point_id:
            try:
                items, total = await self.mistake_repo.find_by_knowledge_point_id(
                    user_id=user_id,
                    knowledge_point_id=UUID(knowledge_point_id),
                    subject=subject,
                    mastery_status=mastery_status,
                    page=page,
                    page_size=page_size,
                )
            except Exception as e:
                logger.warning(f"æŒ‰çŸ¥è¯†ç‚¹ç­›é€‰å¤±è´¥: {e}ï¼Œé™çº§åˆ°æ™®é€šæŸ¥è¯¢")
                # é™çº§å¤„ç†ï¼šå¦‚æœçŸ¥è¯†ç‚¹ç­›é€‰å¤±è´¥ï¼Œä½¿ç”¨æ™®é€šæŸ¥è¯¢
                items, total = await self.mistake_repo.find_by_user(
                    user_id=user_id,
                    subject=subject,
                    mastery_status=mastery_status,
                    category=category,
                    source=source,
                    page=page,
                    page_size=page_size,
                )
        else:
            # æ™®é€šæŸ¥è¯¢
            items, total = await self.mistake_repo.find_by_user(
                user_id=user_id,
                subject=subject,
                mastery_status=mastery_status,
                category=category,
                source=source,
                page=page,
                page_size=page_size,
            )

        # ğŸ¯ å¼‚æ­¥è½¬æ¢åˆ—è¡¨é¡¹ï¼ˆåŒ…å«çŸ¥è¯†ç‚¹å…³è”æŸ¥è¯¢ï¼‰
        list_items = []
        for item in items:
            list_item = await self._to_list_item(item)
            list_items.append(list_item)

        return MistakeListResponse(
            items=list_items,
            total=total,
            page=page,
            page_size=page_size,
        )

    async def get_mistake_detail(
        self, mistake_id: UUID, user_id: UUID
    ) -> MistakeDetailResponse:
        """
        è·å–é”™é¢˜è¯¦æƒ…

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            é”™é¢˜è¯¦æƒ…å“åº”
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        return await self._to_detail_response(mistake)

    async def create_mistake(
        self, user_id: UUID, request: CreateMistakeRequest
    ) -> MistakeDetailResponse:
        """
        åˆ›å»ºé”™é¢˜

        Args:
            user_id: ç”¨æˆ·ID
            request: åˆ›å»ºè¯·æ±‚

        Returns:
            é”™é¢˜è¯¦æƒ…å“åº”
        """
        # æ„é€ æ•°æ®
        data = {
            "user_id": (
                str(user_id) if is_sqlite else user_id
            ),  # SQLiteä½¿ç”¨å­—ç¬¦ä¸²ï¼ŒPostgreSQLä½¿ç”¨UUID
            "subject": request.subject,
            "title": request.title,
            "ocr_text": request.question_content,
            "image_urls": request.image_urls,
            "difficulty_level": request.difficulty_level or 2,
            "knowledge_points": request.knowledge_points,
            "mastery_status": "learning",
            "next_review_at": datetime.now() + timedelta(days=1),
            "source": "manual",
        }

        # åˆ›å»ºè®°å½•
        mistake = await self.mistake_repo.create(data)

        logger.info(f"Created mistake {mistake.id} for user {user_id}")

        # ã€æ–°å¢ã€‘è‡ªåŠ¨å…³è”çŸ¥è¯†ç‚¹
        try:
            from src.services.knowledge_graph_service import KnowledgeGraphService

            kg_service = KnowledgeGraphService(self.db, self.bailian_service)

            # æ„å»º AI åé¦ˆï¼ˆç”¨äºçŸ¥è¯†ç‚¹æå–ï¼‰
            ai_feedback = {
                "knowledge_points": request.knowledge_points or [],
                "question": request.question_content,
                "explanation": request.explanation,
            }

            # è°ƒç”¨çŸ¥è¯†å›¾è°±æœåŠ¡åˆ†æå¹¶å…³è”çŸ¥è¯†ç‚¹
            await kg_service.analyze_and_associate_knowledge_points(
                mistake_id=UUID(str(getattr(mistake, "id"))),
                user_id=user_id,
                subject=request.subject,
                ocr_text=request.question_content,
                ai_feedback=(
                    ai_feedback if ai_feedback.get("knowledge_points") else None
                ),
            )

            logger.info(f"å·²ä¸ºé”™é¢˜ {mistake.id} è‡ªåŠ¨å…³è”çŸ¥è¯†ç‚¹")
        except Exception as e:
            # çŸ¥è¯†ç‚¹å…³è”å¤±è´¥ä¸å½±å“é”™é¢˜åˆ›å»º
            logger.warning(f"çŸ¥è¯†ç‚¹è‡ªåŠ¨å…³è”å¤±è´¥: {e}")

        return await self._to_detail_response(mistake)

    async def update_mistake(
        self, mistake_id: UUID, user_id: UUID, request: UpdateMistakeRequest
    ) -> MistakeDetailResponse:
        """
        æ›´æ–°é”™é¢˜

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
            request: æ›´æ–°è¯·æ±‚

        Returns:
            æ›´æ–°åçš„é”™é¢˜è¯¦æƒ…
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        update_data = {}
        if request.title is not None:
            update_data["title"] = request.title
        if request.notes is not None:
            update_data["notes"] = request.notes
        if request.tags is not None:
            update_data["tags"] = request.tags

        if update_data:
            mistake = await self.mistake_repo.update(str(mistake_id), update_data)

        logger.info(f"Updated mistake {mistake_id}")

        return await self._to_detail_response(mistake)

    async def delete_mistake(self, mistake_id: UUID, user_id: UUID) -> None:
        """
        åˆ é™¤é”™é¢˜ï¼ˆçº§è”åˆ é™¤å…³è”æ•°æ®ï¼‰

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
        """
        from sqlalchemy import delete, select, text

        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        # ğŸ”§ Phase 8.3: åˆ é™¤å‰è®°å½•å—å½±å“çš„å­¦ç§‘
        affected_subjects = set()

        try:
            # æŸ¥è¯¢è¯¥é”™é¢˜å…³è”çš„çŸ¥è¯†ç‚¹ï¼Œæå–å­¦ç§‘ä¿¡æ¯
            from src.models.knowledge_graph import MistakeKnowledgePoint
            from src.models.study import KnowledgeMastery

            stmt = (
                select(KnowledgeMastery.subject)
                .join(
                    MistakeKnowledgePoint,
                    MistakeKnowledgePoint.knowledge_point_id == KnowledgeMastery.id,
                )
                .where(MistakeKnowledgePoint.mistake_id == str(mistake_id))
                .distinct()
            )

            result = await self.db.execute(stmt)
            subjects = result.scalars().all()
            affected_subjects = set(str(s) for s in subjects if s)

            if affected_subjects:
                logger.info(f"é”™é¢˜ {mistake_id} å½±å“çš„å­¦ç§‘: {affected_subjects}")
        except Exception as e:
            logger.warning(f"æŸ¥è¯¢å—å½±å“å­¦ç§‘å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œåˆ é™¤")

        # ğŸ”§ çº§è”åˆ é™¤ï¼šå…ˆåˆ é™¤å…³è”æ•°æ®ï¼Œå†åˆ é™¤é”™é¢˜
        mistake_id_str = str(mistake_id)

        # âœ… æ–¹æ¡ˆAï¼šä½¿ç”¨å®æ—¶è®¡ç®—ï¼Œæ— éœ€ç»´æŠ¤ mistake_count å­—æ®µ
        # åˆ é™¤å…³è”è®°å½•å³å¯ï¼Œå‰ç«¯æŸ¥è¯¢æ—¶ä¼šå®æ—¶ç»Ÿè®¡

        # 1. åˆ é™¤å¤ä¹ è®°å½• (mistake_review_sessions)
        await self.db.execute(
            text("DELETE FROM mistake_review_sessions WHERE mistake_id = :mid"),
            {"mid": mistake_id_str},
        )

        # 2. åˆ é™¤çŸ¥è¯†ç‚¹å…³è” (mistake_knowledge_points)
        await self.db.execute(
            text("DELETE FROM mistake_knowledge_points WHERE mistake_id = :mid"),
            {"mid": mistake_id_str},
        )

        # 3. åˆ é™¤é”™é¢˜è®°å½•
        await self.mistake_repo.delete(mistake_id_str)

        # æäº¤åˆ é™¤æ“ä½œ
        await self.db.commit()

        logger.info(f"Deleted mistake {mistake_id} with all associations")

        # ğŸ”§ Phase 8.3: åˆ é™¤åå¼‚æ­¥è§¦å‘å¿«ç…§æ›´æ–°
        if affected_subjects:
            try:
                from src.services.knowledge_graph_service import KnowledgeGraphService

                kg_service = KnowledgeGraphService(self.db, self.bailian_service)

                for subject in affected_subjects:
                    try:
                        await kg_service.create_knowledge_graph_snapshot(
                            user_id=user_id, subject=subject, period_type="auto_update"
                        )
                        logger.info(
                            f"âœ… å·²æ›´æ–°çŸ¥è¯†å›¾è°±å¿«ç…§: user={user_id}, subject={subject}"
                        )
                    except Exception as e:
                        # å•ä¸ªå­¦ç§‘å¿«ç…§æ›´æ–°å¤±è´¥ä¸å½±å“å…¶ä»–å­¦ç§‘
                        logger.warning(
                            f"âš ï¸ æ›´æ–°å­¦ç§‘ {subject} å¿«ç…§å¤±è´¥: {e}ï¼Œç»§ç»­å¤„ç†å…¶ä»–å­¦ç§‘"
                        )

                # æäº¤å¿«ç…§æ›´æ–°
                await self.db.commit()

            except Exception as e:
                # å¿«ç…§æ›´æ–°å¤±è´¥ä¸å›æ»šåˆ é™¤æ“ä½œ
                logger.warning(
                    f"âš ï¸ çŸ¥è¯†å›¾è°±å¿«ç…§æ›´æ–°å¤±è´¥: {e}ï¼Œä½†é”™é¢˜å·²æˆåŠŸåˆ é™¤", exc_info=True
                )
                # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œç¡®ä¿åˆ é™¤æ“ä½œæˆåŠŸ

    async def get_today_review_tasks(self, user_id: UUID) -> TodayReviewResponse:
        """
        è·å–ä»Šæ—¥å¤ä¹ ä»»åŠ¡

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            ä»Šæ—¥å¤ä¹ ä»»åŠ¡å“åº”
        """
        mistakes = await self.mistake_repo.find_due_for_review(
            user_id=user_id, limit=50
        )

        tasks = []
        total_minutes = 0

        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        for mistake in mistakes:
            # ğŸ› ï¸ å®‰å…¨åœ°æå–ORMå±æ€§
            mistake_id_str = extract_orm_uuid_str(mistake, "id")
            next_review = getattr(mistake, "next_review_at", None)

            tasks.append(
                TodayReviewTask(
                    id=UUID(mistake_id_str),
                    mistake_id=UUID(mistake_id_str),
                    title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
                    subject=extract_orm_str(mistake, "subject"),
                    review_round=(extract_orm_int(mistake, "review_count") or 0) + 1,
                    due_date=(
                        next_review.isoformat()
                        if next_review and hasattr(next_review, "isoformat")
                        else datetime.now().isoformat()
                    ),
                    question_content=extract_orm_str(mistake, "ocr_text") or "",
                    image_urls=getattr(mistake, "image_urls", None) or [],
                )
            )
            estimated_time = extract_orm_int(mistake, "estimated_time")
            total_minutes += estimated_time if estimated_time else 5

        logger.info(
            f"Retrieved {len(tasks)} review tasks for user {user_id}, estimated {total_minutes} minutes"
        )

        return TodayReviewResponse(
            tasks=tasks,
            total_count=len(tasks),
            completed_count=0,
            estimated_minutes=total_minutes,
        )

    async def complete_review(
        self, mistake_id: UUID, user_id: UUID, request: ReviewCompleteRequest
    ) -> ReviewCompleteResponse:
        """
        å®Œæˆå¤ä¹ 

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
            request: å¤ä¹ å®Œæˆè¯·æ±‚

        Returns:
            å¤ä¹ å®Œæˆå“åº”
        """
        # 1. è·å–é”™é¢˜å¹¶éªŒè¯å½’å±
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        # 2. åˆ›å»ºå¤ä¹ è®°å½•æ•°æ®
        review_data = {
            "mistake_id": str(mistake_id),
            "user_id": str(user_id),
            "review_date": datetime.now(),
            "review_result": request.review_result,
            "time_spent": request.time_spent,
            "confidence_level": request.confidence_level,
            "user_answer": request.user_answer,
            "notes": request.notes,
            "review_method": "manual",
        }

        # 3. è·å–å¤ä¹ å†å²å¹¶è®¡ç®—æŒæ¡åº¦
        review_history = await self.review_repo.find_by_mistake(mistake_id)
        current_mastery = self.algorithm.calculate_mastery_level(review_history)

        # 4. è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´
        from src.utils.type_converters import extract_orm_int

        next_review, interval = self.algorithm.calculate_next_review(
            review_count=extract_orm_int(mistake, "review_count")
            or 0,  # ğŸ› ï¸ ä½¿ç”¨extract_orm_int
            review_result=request.review_result,
            current_mastery=current_mastery,
            last_review_date=datetime.now(),
        )

        # 5. æ›´æ–°å¤ä¹ è®°å½•æ•°æ®
        review_data["mastery_level"] = current_mastery
        review_data["next_review_date"] = next_review
        review_data["interval_days"] = interval

        # 6. ä¿å­˜å¤ä¹ è®°å½•
        review = await self.review_repo.create(review_data)

        from src.utils.type_converters import extract_orm_uuid_str

        # 7. æ›´æ–°é”™é¢˜çŠ¶æ€
        update_data = {
            "review_count": mistake.review_count + 1,
            "last_review_at": datetime.now(),
            "next_review_at": next_review,
        }

        if request.review_result == "correct":
            update_data["correct_count"] = mistake.correct_count + 1

        # 8. åˆ¤æ–­æ˜¯å¦å·²æŒæ¡
        consecutive_correct = update_data.get("correct_count", mistake.correct_count)
        is_mastered = self.algorithm.is_mastered(
            mastery_level=current_mastery,
            consecutive_correct=consecutive_correct,
            min_reviews=3,
        )

        if is_mastered:
            update_data["mastery_status"] = "mastered"
        elif current_mastery >= 0.5:
            update_data["mastery_status"] = "reviewing"

        await self.mistake_repo.update(str(mistake_id), update_data)

        # ã€æ–°å¢ã€‘æ›´æ–°çŸ¥è¯†ç‚¹æŒæ¡åº¦
        try:
            from src.services.knowledge_graph_service import KnowledgeGraphService

            kg_service = KnowledgeGraphService(self.db, self.bailian_service)

            # è°ƒç”¨çŸ¥è¯†å›¾è°±æœåŠ¡æ›´æ–°æŒæ¡åº¦
            await kg_service.update_knowledge_mastery_after_review(
                mistake_id=mistake_id,
                review_result=request.review_result,
                confidence_level=request.confidence_level,
            )

            logger.info(f"å·²æ›´æ–°é”™é¢˜ {mistake_id} å…³è”çš„çŸ¥è¯†ç‚¹æŒæ¡åº¦")
        except Exception as e:
            # çŸ¥è¯†ç‚¹æŒæ¡åº¦æ›´æ–°å¤±è´¥ä¸å½±å“å¤ä¹ æµç¨‹
            logger.warning(f"çŸ¥è¯†ç‚¹æŒæ¡åº¦æ›´æ–°å¤±è´¥: {e}")

        logger.info(
            f"Completed review for mistake {mistake_id}, mastery: {current_mastery}, next review: {next_review}"
        )

        return ReviewCompleteResponse(
            review_id=UUID(extract_orm_uuid_str(review, "id")),
            mastery_level=current_mastery,
            next_review_date=next_review,
            is_mastered=is_mastered,
        )

    async def get_review_history(
        self, mistake_id: UUID, user_id: UUID
    ) -> ReviewHistoryResponse:
        """
        è·å–å¤ä¹ å†å²

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            å¤ä¹ å†å²å“åº”
        """
        # éªŒè¯æƒé™
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        # è·å–å¤ä¹ å†å²
        reviews = await self.review_repo.find_by_mistake(mistake_id, limit=50)

        # è®¡ç®—å¹³å‡æŒæ¡åº¦
        avg_mastery = await self.review_repo.calculate_average_mastery(mistake_id)

        # æœ€æ–°æŒæ¡åº¦
        latest_mastery = reviews[0].mastery_level if reviews else 0.0

        from src.schemas.mistake import ReviewHistoryItem
        from src.utils.type_converters import (
            extract_orm_float,
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
            extract_orm_value,
        )

        items = [
            ReviewHistoryItem(
                id=UUID(extract_orm_uuid_str(r, "id")),
                review_date=extract_orm_value(r, "review_date", datetime.now()),
                review_result=extract_orm_str(r, "review_result"),
                mastery_level=extract_orm_float(r, "mastery_level") or 0.0,
                time_spent=extract_orm_int(r, "time_spent"),
                confidence_level=extract_orm_int(r, "confidence_level") or 0,
                notes=extract_orm_str(r, "notes"),
            )
            for r in reviews
        ]

        latest_mastery_value = (
            extract_orm_float(reviews[0], "mastery_level") or 0.0 if reviews else 0.0
        )

        return ReviewHistoryResponse(
            items=items,
            total=len(reviews),
            average_mastery=avg_mastery,
            latest_mastery=latest_mastery_value,
        )

    async def get_statistics(self, user_id: UUID) -> MistakeStatisticsResponse:
        """
        è·å–é”™é¢˜ç»Ÿè®¡

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            ç»Ÿè®¡å“åº”
        """
        stats = await self.mistake_repo.get_statistics(user_id)

        # è·å–è¿ç»­å¤ä¹ å¤©æ•°
        streak_days = await self.review_repo.get_review_streak(user_id)

        # æœ¬å‘¨å¤ä¹ æ¬¡æ•°
        week_start = datetime.now() - timedelta(days=7)
        week_reviews = await self.review_repo.count_reviews_by_date_range(
            user_id, week_start, datetime.now()
        )

        return MistakeStatisticsResponse(
            total_mistakes=stats["total"],
            not_mastered=stats["learning"],
            reviewing=stats["reviewing"],
            mastered=stats["mastered"],
            by_subject=stats["by_subject"],
            by_difficulty=stats["by_difficulty"],
            review_streak_days=streak_days,
            this_week_reviews=week_reviews,
        )

    async def get_mastery_progress(
        self, user_id: UUID, days: int = 7
    ) -> MasteryProgressResponse:
        """
        è·å–æŒæ¡åº¦è¿›åº¦

        Args:
            user_id: ç”¨æˆ·ID
            days: å¤©æ•°

        Returns:
            æŒæ¡åº¦è¿›åº¦å“åº”
        """
        # è·å–æœ€è¿‘Nå¤©çš„å¤ä¹ è®°å½•
        reviews = await self.review_repo.get_recent_reviews(user_id, days)

        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        from collections import defaultdict

        from src.utils.type_converters import extract_orm_float, extract_orm_value

        daily_stats = defaultdict(lambda: {"sum": 0.0, "count": 0})

        for review in reviews:
            review_date = extract_orm_value(review, "review_date", datetime.now())
            date_str = review_date.date().isoformat()
            mastery_level = extract_orm_float(review, "mastery_level") or 0.0
            daily_stats[date_str]["sum"] += mastery_level
            daily_stats[date_str]["count"] += 1

        # æ„å»ºè¿›åº¦é¡¹
        from src.schemas.mistake import MasteryProgressItem

        items = []
        for date_str in sorted(daily_stats.keys()):
            stats = daily_stats[date_str]
            avg_mastery = stats["sum"] / stats["count"] if stats["count"] > 0 else 0.0
            items.append(
                MasteryProgressItem(
                    date=date_str,
                    mastery_level=round(avg_mastery, 2),
                    review_count=int(stats["count"]),
                )
            )

        # è®¡ç®—è¶‹åŠ¿
        trend = "stable"
        improvement = 0.0
        if len(items) >= 2:
            first_mastery = items[0].mastery_level
            last_mastery = items[-1].mastery_level
            improvement = last_mastery - first_mastery

            if improvement > 0.1:
                trend = "up"
            elif improvement < -0.1:
                trend = "down"

        return MasteryProgressResponse(
            items=items, trend=trend, improvement=round(improvement, 2)
        )

    async def analyze_mistake_with_ai(self, mistake_id: UUID, user_id: UUID) -> Dict:
        """
        ä½¿ç”¨AIåˆ†æé”™é¢˜ï¼ˆå¸¦å­¦æƒ…ä¸Šä¸‹æ–‡ï¼‰

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            AIåˆ†æç»“æœï¼ŒåŒ…å«ï¼š
            - knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨
            - error_reasons: é”™è¯¯åŸå› åˆ†æ
            - suggestions: å­¦ä¹ å»ºè®®
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        if not self.bailian_service:
            raise ServiceError("AIæœåŠ¡æœªé…ç½®")

        try:
            from src.utils.type_converters import extract_orm_int, extract_orm_str

            # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…åœ¨å¼‚å¸¸å¤„ç†ä¸­æœªç»‘å®š
            ai_content = ""

            # å®‰å…¨æå–ORMå±æ€§
            subject = extract_orm_str(mistake, "subject") or "æœªçŸ¥"
            difficulty = extract_orm_int(mistake, "difficulty_level")
            difficulty_text = str(difficulty) if difficulty else "æœªçŸ¥"
            ocr_text = extract_orm_str(mistake, "ocr_text") or "æ— é¢˜ç›®å†…å®¹"

            # ã€æ–°å¢ã€‘æ„å»ºå­¦æƒ…ä¸Šä¸‹æ–‡
            learning_context = await self._build_learning_context_for_ai(
                user_id, subject
            )

            # æ„é€ åˆ†ææç¤ºè¯ï¼ˆåŠ å…¥å­¦æƒ…ä¸Šä¸‹æ–‡ï¼‰
            analysis_prompt = f"""è¯·åˆ†æä»¥ä¸‹é”™é¢˜ï¼Œç»“åˆå­¦ç”Ÿçš„å­¦æƒ…æ•°æ®ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ç»™å‡ºä¸ªæ€§åŒ–å­¦ä¹ å»ºè®®ã€‚

{learning_context}

ã€é¢˜ç›®ä¿¡æ¯ã€‘
å­¦ç§‘ï¼š{subject}
éš¾åº¦ï¼š{difficulty_text}
é¢˜ç›®å†…å®¹ï¼š
{ocr_text}

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
1. knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨ï¼ˆæ•°ç»„ï¼Œ3-5ä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œæ¯ä¸ªçŸ¥è¯†ç‚¹éœ€åŒ…å«:
   - name: çŸ¥è¯†ç‚¹åç§°
   - relevance: ç›¸å…³æ€§ (0.0-1.0)
   - error_type: é”™è¯¯ç±»å‹ (concept_misunderstanding/calculation_error/formula_misuse/logic_error/knowledge_gap/method_confusion/other)
   - error_reason: é”™è¯¯åŸå› ï¼ˆç®€æ´æè¿°ï¼‰
   - suggestions: æ”¹è¿›å»ºè®®ï¼ˆæ•°ç»„ï¼Œ2-3æ¡å…·ä½“å»ºè®®ï¼‰
)
2. error_reason: æœ¬æ¬¡é”™é¢˜çš„ä¸»è¦é”™è¯¯åŸå› åˆ†æï¼ˆå­—ç¬¦ä¸²ï¼Œ100å­—ä»¥å†…ï¼‰
3. suggestions: å­¦ä¹ å»ºè®®ï¼ˆå­—ç¬¦ä¸²ï¼Œ150å­—ä»¥å†…ï¼Œç»“åˆå­¦ç”Ÿè–„å¼±çŸ¥è¯†ç‚¹ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®ï¼‰
4. personalized_insight: ä¸ªæ€§åŒ–æ´å¯Ÿï¼ˆå­—ç¬¦ä¸²ï¼ŒåŸºäºå­¦ç”Ÿå†å²å­¦æƒ…çš„ç‰¹åˆ«æç¤ºï¼Œå¦‚æœæ˜¯åˆæ¬¡ä½¿ç”¨å¯çœç•¥ï¼‰

ç¤ºä¾‹æ ¼å¼ï¼š
{{
    "knowledge_points": [
        {{
            "name": "ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹",
            "relevance": 0.9,
            "error_type": "concept_misunderstanding",
            "error_reason": "å¯¹åˆ¤åˆ«å¼çš„è®¡ç®—ç†è§£æœ‰è¯¯",
            "suggestions": ["å¤ä¹ åˆ¤åˆ«å¼bÂ²-4acçš„å®šä¹‰", "åš5é“åˆ¤åˆ«å¼ä¸“é¡¹ç»ƒä¹ "]
        }},
        {{
            "name": "é…æ–¹æ³•",
            "relevance": 0.7,
            "error_type": "method_confusion",
            "error_reason": "é…æ–¹æ­¥éª¤å‡ºç°é”™è¯¯",
            "suggestions": ["é‡æ–°å­¦ä¹ é…æ–¹æ³•æ­¥éª¤", "å¯¹æ¯”é…æ–¹æ³•ä¸å…¬å¼æ³•çš„åŒºåˆ«"]
        }}
    ],
    "error_reason": "å¯¹åˆ¤åˆ«å¼çš„è®¡ç®—ç†è§£æœ‰è¯¯ï¼Œå¯¼è‡´è§£é¢˜æ€è·¯é”™è¯¯ã€‚",
    "suggestions": "å»ºè®®å¤ä¹ åˆ¤åˆ«å¼çš„å®šä¹‰å’Œåº”ç”¨ï¼Œå¤šåšç›¸å…³ç»ƒä¹ é¢˜ï¼Œé‡ç‚¹æŒæ¡bÂ²-4acçš„è®¡ç®—æ–¹æ³•ã€‚ç»“åˆä½ åœ¨'ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹'ä¸Šçš„è–„å¼±æƒ…å†µï¼Œå»ºè®®ä»åŸºç¡€ä¾‹é¢˜å…¥æ‰‹ï¼Œé€æ­¥æå‡éš¾åº¦ã€‚",
    "personalized_insight": "ä½ åœ¨ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹ç›¸å…³é¢˜ç›®ä¸Šå·²ç»å‡ºç°3æ¬¡é”™è¯¯ï¼Œè¿™æ˜¯éœ€è¦é‡ç‚¹çªç ´çš„çŸ¥è¯†ç‚¹ã€‚"
}}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

            # è°ƒç”¨ç™¾ç‚¼AIæœåŠ¡
            logger.info(f"å¼€å§‹AIåˆ†æé”™é¢˜ï¼ˆå¸¦å­¦æƒ…ä¸Šä¸‹æ–‡ï¼‰: {mistake_id}")

            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å­¦ç§‘æ•™å¸ˆï¼Œæ“…é•¿åˆ†æå­¦ç”Ÿçš„é”™é¢˜ï¼Œæ‰¾å‡ºçŸ¥è¯†ç›²ç‚¹å¹¶ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®ã€‚ä½ ä¼šæ ¹æ®å­¦ç”Ÿçš„å†å²å­¦æƒ…æ•°æ®ï¼Œæä¾›ä¸ªæ€§åŒ–çš„å­¦ä¹ æŒ‡å¯¼ã€‚",
                },
                {"role": "user", "content": analysis_prompt},
            ]

            response = await self.bailian_service.chat_completion(
                messages=messages,
                stream=False,
                temperature=0.7,  # é€‚ä¸­çš„åˆ›é€ æ€§
                max_tokens=1500,  # å¢åŠ tokenä»¥æ”¯æŒæ›´è¯¦ç»†çš„åˆ†æ
            )

            if not response.success:
                logger.error(f"AIåˆ†æå¤±è´¥: {response.error_message}")
                # é™çº§æ–¹æ¡ˆï¼šè¿”å›åŸºç¡€ä¿¡æ¯
                return self._fallback_analysis(mistake)

            # è§£æAIè¿”å›çš„JSON
            ai_content = response.content.strip() if response.content else ""

            # å°è¯•æå–JSONï¼ˆå¤„ç†AIå¯èƒ½è¿”å›çš„é¢å¤–æ–‡æœ¬ï¼‰
            json_match = re.search(r"\{.*\}", ai_content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                analysis_result = json.loads(json_str)
            else:
                # å¦‚æœæ— æ³•æå–JSONï¼Œå°è¯•ç›´æ¥è§£æ
                analysis_result = json.loads(ai_content)

            # ã€æ–°å¢ã€‘æ ‡å‡†åŒ–çŸ¥è¯†ç‚¹æ ¼å¼
            knowledge_points = self._standardize_knowledge_points(
                analysis_result.get("knowledge_points", [])
            )

            # éªŒè¯å’Œæ ‡å‡†åŒ–è¿”å›ç»“æœ
            result = {
                "knowledge_points": knowledge_points,
                "error_reason": analysis_result.get("error_reason", ""),
                "suggestions": analysis_result.get("suggestions", ""),
                "personalized_insight": analysis_result.get("personalized_insight", ""),
                "ai_tokens_used": response.tokens_used,
                "analysis_time": response.processing_time,
                "has_learning_context": bool(
                    learning_context and "åˆæ¬¡ä½¿ç”¨ç³»ç»Ÿ" not in learning_context
                ),
            }

            # æ›´æ–°é”™é¢˜è®°å½•ä¸­çš„AIåˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
            update_data = {}
            if result["knowledge_points"]:
                # åªå­˜å‚¨çŸ¥è¯†ç‚¹åç§°åˆ—è¡¨ï¼ˆå‘åå…¼å®¹ï¼‰
                update_data["knowledge_points"] = [
                    kp.get("name", kp) if isinstance(kp, dict) else kp
                    for kp in knowledge_points
                ]

            if update_data:
                await self.mistake_repo.update(str(mistake_id), update_data)
            else:
                await self.db.commit()

            logger.info(
                f"AIåˆ†æå®Œæˆ: {mistake_id}, "
                f"çŸ¥è¯†ç‚¹æ•°é‡: {len(result['knowledge_points'])}, "
                f"Tokenä½¿ç”¨: {response.tokens_used}, "
                f"å­¦æƒ…ä¸Šä¸‹æ–‡: {result['has_learning_context']}"
            )

            return result

        except json.JSONDecodeError as e:
            content_preview = ai_content[:200] if ai_content else "æ— AIå“åº”å†…å®¹"  # type: ignore[possibly-unbound]
            logger.error(f"AIè¿”å›çš„JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {content_preview}")
            # é™çº§æ–¹æ¡ˆ
            return self._fallback_analysis(mistake)

        except Exception as e:
            logger.error(f"AIåˆ†æé”™é¢˜å¤±è´¥: {e}", exc_info=True)
            # é™çº§æ–¹æ¡ˆï¼šè¿”å›åŸºç¡€ä¿¡æ¯
            return self._fallback_analysis(mistake)

    async def _build_learning_context_for_ai(self, user_id: UUID, subject: str) -> str:
        """
        æ„å»ºå­¦æƒ…ä¸Šä¸‹æ–‡ï¼ˆä¾›AIåˆ†æä½¿ç”¨ï¼‰

        Args:
            user_id: ç”¨æˆ·ID
            subject: å­¦ç§‘

        Returns:
            å­¦æƒ…ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        try:
            from src.services.knowledge_graph_service import KnowledgeGraphService

            kg_service = KnowledgeGraphService(self.db, self.bailian_service)
            learning_context = await kg_service.build_learning_context(user_id, subject)

            return learning_context

        except Exception as e:
            logger.warning(f"æ„å»ºå­¦æƒ…ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return "å­¦ç”Ÿæ˜¯åˆæ¬¡ä½¿ç”¨ç³»ç»Ÿï¼Œå°šæ— å†å²å­¦æƒ…æ•°æ®ã€‚"

    def _standardize_knowledge_points(self, knowledge_points: List) -> List[Dict]:
        """
        æ ‡å‡†åŒ–çŸ¥è¯†ç‚¹æ ¼å¼

        å°†AIè¿”å›çš„çŸ¥è¯†ç‚¹åˆ—è¡¨è½¬æ¢ä¸ºç»Ÿä¸€çš„å­—å…¸æ ¼å¼

        Args:
            knowledge_points: AIè¿”å›çš„çŸ¥è¯†ç‚¹åˆ—è¡¨

        Returns:
            æ ‡å‡†åŒ–çš„çŸ¥è¯†ç‚¹åˆ—è¡¨
        """
        standardized = []

        for kp in knowledge_points:
            # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—å…¸
            if isinstance(kp, str):
                standardized.append(
                    {
                        "name": kp,
                        "relevance": 0.8,
                        "error_type": "other",
                        "error_reason": "",
                        "suggestions": [],
                    }
                )
            elif isinstance(kp, dict):
                # ç¡®ä¿å¿…è¦å­—æ®µå­˜åœ¨
                standardized.append(
                    {
                        "name": kp.get("name", kp.get("knowledge_point", "æœªçŸ¥çŸ¥è¯†ç‚¹")),
                        "relevance": kp.get("relevance", 0.8),
                        "error_type": kp.get("error_type", "other"),
                        "error_reason": kp.get("error_reason", ""),
                        "suggestions": kp.get("suggestions", []),
                    }
                )
            else:
                logger.warning(f"æœªçŸ¥çš„çŸ¥è¯†ç‚¹æ ¼å¼: {type(kp)}")

        return standardized

    def _fallback_analysis(self, mistake) -> Dict:
        """
        AIåˆ†æå¤±è´¥æ—¶çš„é™çº§æ–¹æ¡ˆ

        Args:
            mistake: é”™é¢˜è®°å½•

        Returns:
            åŸºç¡€åˆ†æç»“æœ
        """
        logger.warning(f"ä½¿ç”¨é™çº§åˆ†ææ–¹æ¡ˆ: {mistake.id}")

        # æ ¹æ®å­¦ç§‘æä¾›é»˜è®¤çš„å­¦ä¹ å»ºè®®
        subject_suggestions = {
            "math": "å»ºè®®å›é¡¾ç›¸å…³ç« èŠ‚çš„åŸºç¡€æ¦‚å¿µï¼Œå¤šåšç±»ä¼¼é¢˜ç›®ç»ƒä¹ ï¼Œæ³¨æ„è§£é¢˜æ­¥éª¤çš„è§„èŒƒæ€§ã€‚",
            "chinese": "å»ºè®®åŠ å¼ºåŸºç¡€çŸ¥è¯†çš„ç§¯ç´¯ï¼Œå¤šé˜…è¯»ä¼˜ç§€èŒƒæ–‡ï¼Œæ³¨æ„ç­”é¢˜æŠ€å·§å’Œè¡¨è¾¾è§„èŒƒã€‚",
            "english": "å»ºè®®å¤ä¹ ç›¸å…³è¯­æ³•ç‚¹ï¼Œç§¯ç´¯è¯æ±‡ï¼Œå¤šåšé˜…è¯»å’Œå†™ä½œç»ƒä¹ ã€‚",
            "physics": "å»ºè®®ç†è§£ç‰©ç†æ¦‚å¿µçš„æœ¬è´¨ï¼ŒæŒæ¡å…¬å¼çš„æ¨å¯¼è¿‡ç¨‹ï¼Œå¤šåšå®éªŒåˆ†æé¢˜ã€‚",
            "chemistry": "å»ºè®®ç†Ÿè®°åŒ–å­¦æ–¹ç¨‹å¼ï¼Œç†è§£ååº”åŸç†ï¼Œæ³¨æ„å®éªŒæ“ä½œçš„ç»†èŠ‚ã€‚",
            "biology": "å»ºè®®ç³»ç»Ÿå¤ä¹ ç›¸å…³çŸ¥è¯†ç‚¹ï¼Œç†è§£ç”Ÿç‰©è¿‡ç¨‹ï¼Œæ³¨æ„å›¾è¡¨åˆ†æèƒ½åŠ›çš„åŸ¹å…»ã€‚",
        }

        return {
            "knowledge_points": mistake.knowledge_points or [],
            "error_reason": "å»ºè®®ä»”ç»†åˆ†æé¢˜ç›®è¦æ±‚ï¼Œå¯¹æ¯”æ­£ç¡®ç­”æ¡ˆæ‰¾å‡ºå·®å¼‚ã€‚",
            "suggestions": subject_suggestions.get(
                mistake.subject, "å»ºè®®å›é¡¾è¯¾æœ¬çŸ¥è¯†ï¼Œå¤šåšç»ƒä¹ ï¼ŒåŠæ—¶è¯·æ•™è€å¸ˆæˆ–åŒå­¦ã€‚"
            ),
            "ai_tokens_used": 0,
            "analysis_time": 0.0,
            "is_fallback": True,
        }
