"""
é”™é¢˜æ‰‹å†ŒæœåŠ¡å±‚
æä¾›é”™é¢˜ç®¡ç†ã€å¤ä¹ è®¡åˆ’ã€ç»Ÿè®¡åˆ†æç­‰ä¸šåŠ¡é€»è¾‘

ä½œè€…: AI Agent
åˆ›å»ºæ—¶é—´: 2025-10-12
ç‰ˆæœ¬: v1.0
"""

import json
import logging
import re
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional
from uuid import UUID

from sqlalchemy.ext.asyncio import AsyncSession

from src.core.exceptions import NotFoundError, ServiceError, ValidationError
from src.models.base import is_sqlite
from src.models.study import MistakeRecord, MistakeReview
from src.repositories.mistake_repository import MistakeRepository
from src.repositories.mistake_review_repository import MistakeReviewRepository
from src.schemas.mistake import (
    CreateMistakeRequest,
    MasteryProgressResponse,
    MistakeDetailResponse,
    MistakeListItem,
    MistakeListResponse,
    MistakeStatisticsResponse,
    ReviewCompleteRequest,
    ReviewCompleteResponse,
    ReviewHistoryResponse,
    TodayReviewResponse,
    TodayReviewTask,
    UpdateMistakeRequest,
)
from src.services.algorithms.spaced_repetition import SpacedRepetitionAlgorithm

logger = logging.getLogger(__name__)


class MistakeService:
    """é”™é¢˜æœåŠ¡"""

    def __init__(self, db: AsyncSession, bailian_service=None):
        self.db = db
        self.mistake_repo = MistakeRepository(MistakeRecord, db)
        self.review_repo = MistakeReviewRepository(MistakeReview, db)
        self.algorithm = SpacedRepetitionAlgorithm()
        self.bailian_service = bailian_service

    @staticmethod
    def _safe_extract_orm(obj: Any, attr: str, default: Any = None) -> Any:
        """å®‰å…¨åœ°ä»ORMå¯¹è±¡æå–å±æ€§å€¼"""
        try:
            value = getattr(obj, attr, default)
            # å¦‚æœæ˜¯Columnå¯¹è±¡ï¼Œè¿”å›é»˜è®¤å€¼
            if hasattr(value, "__class__") and "Column" in str(type(value)):
                return default
            return value if value is not None else default
        except Exception:
            return default

    def _to_list_item(self, mistake: MistakeRecord) -> MistakeListItem:
        """è½¬æ¢ä¸ºåˆ—è¡¨é¡¹"""
        from uuid import UUID as UUIDType

        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        # åœ¨SQLiteä¸­ï¼Œæ—¥æœŸå­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼›åœ¨PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡
        # éœ€è¦å¤„ç†ä¸¤ç§æƒ…å†µ
        def to_iso_string(value):
            """å°†æ—¥æœŸå­—æ®µè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²"""
            if value is None:
                return None
            if isinstance(value, str):
                return value  # SQLiteä¸­å·²ç»æ˜¯å­—ç¬¦ä¸²
            return value.isoformat()  # PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡

        def parse_json_field(value):
            """è§£æJSONå­—æ®µï¼Œå…¼å®¹å­—ç¬¦ä¸²å’Œå·²è§£æçš„å¯¹è±¡"""
            if value is None:
                return []
            if isinstance(value, list):
                return value  # å·²ç»æ˜¯åˆ—è¡¨
            if isinstance(value, str):
                try:
                    parsed = json.loads(value)
                    return parsed if isinstance(parsed, list) else []
                except (json.JSONDecodeError, ValueError):
                    return []
            return []

        return MistakeListItem(
            id=UUID(extract_orm_uuid_str(mistake, "id")),
            title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
            subject=extract_orm_str(mistake, "subject"),
            difficulty_level=extract_orm_int(mistake, "difficulty_level"),
            source=extract_orm_str(mistake, "source"),
            source_id=None,
            mastery_status=extract_orm_str(mistake, "mastery_status"),
            correct_count=extract_orm_int(mistake, "correct_count") or 0,
            total_reviews=extract_orm_int(mistake, "review_count") or 0,
            next_review_date=to_iso_string(getattr(mistake, "next_review_at", None)),
            created_at=to_iso_string(getattr(mistake, "created_at", None)) or "",
            updated_at=to_iso_string(
                getattr(mistake, "updated_at", None)
            ),  # âœ… æ·»åŠ updated_at
            knowledge_points=parse_json_field(
                getattr(mistake, "knowledge_points", None)
            ),
        )

    def _to_detail_response(self, mistake: MistakeRecord) -> MistakeDetailResponse:
        """è½¬æ¢ä¸ºè¯¦æƒ…å“åº”"""
        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        # åœ¨SQLiteä¸­ï¼Œæ—¥æœŸå­—æ®µæ˜¯å­—ç¬¦ä¸²ï¼›åœ¨PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡
        # éœ€è¦å¤„ç†ä¸¤ç§æƒ…å†µ
        def to_iso_string(value):
            """å°†æ—¥æœŸå­—æ®µè½¬æ¢ä¸ºISOæ ¼å¼å­—ç¬¦ä¸²"""
            if value is None:
                return None
            if isinstance(value, str):
                return value  # SQLiteä¸­å·²ç»æ˜¯å­—ç¬¦ä¸²
            return value.isoformat()  # PostgreSQLä¸­æ˜¯datetimeå¯¹è±¡

        def parse_json_field(value):
            """è§£æJSONå­—æ®µï¼Œå…¼å®¹å­—ç¬¦ä¸²å’Œå·²è§£æçš„å¯¹è±¡"""
            if value is None:
                return []
            if isinstance(value, list):
                return value  # å·²ç»æ˜¯åˆ—è¡¨
            if isinstance(value, str):
                try:
                    parsed = json.loads(value)
                    return parsed if isinstance(parsed, list) else []
                except (json.JSONDecodeError, ValueError):
                    return []
            return []

        # ğŸ› ï¸ ä½¿ç”¨extract_orm_*å‡½æ•°æå–ORMå¯¹è±¡çš„å€¼
        return MistakeDetailResponse(
            id=UUID(extract_orm_uuid_str(mistake, "id")),
            title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
            description=None,
            subject=extract_orm_str(mistake, "subject"),
            difficulty_level=extract_orm_int(mistake, "difficulty_level"),
            source=extract_orm_str(mistake, "source"),
            source_id=None,
            question_content=extract_orm_str(mistake, "ocr_text") or "",
            student_answer=extract_orm_str(mistake, "student_answer")
            or None,  # ğŸ› ï¸ ä»æ•°æ®åº“è¯»å–
            correct_answer=extract_orm_str(mistake, "correct_answer")
            or None,  # ğŸ› ï¸ ä»æ•°æ®åº“è¯»å–
            explanation=None,  # æ¨¡å‹ä¸­æ²¡æœ‰è¯¥å­—æ®µï¼Œä¿æŒNone
            knowledge_points=parse_json_field(
                getattr(mistake, "knowledge_points", None)
            ),
            mastery_status=extract_orm_str(mistake, "mastery_status"),
            correct_count=extract_orm_int(mistake, "correct_count") or 0,
            total_reviews=extract_orm_int(mistake, "review_count") or 0,
            next_review_date=to_iso_string(getattr(mistake, "next_review_at", None)),
            created_at=to_iso_string(getattr(mistake, "created_at", None)) or "",
            updated_at=to_iso_string(getattr(mistake, "updated_at", None)) or "",
            image_urls=parse_json_field(getattr(mistake, "image_urls", None)),
        )

    async def get_mistake_list(
        self,
        user_id: UUID,
        page: int,
        page_size: int,
        filters: Optional[Dict] = None,
    ) -> MistakeListResponse:
        """
        è·å–é”™é¢˜åˆ—è¡¨

        Args:
            user_id: ç”¨æˆ·ID
            page: é¡µç 
            page_size: æ¯é¡µæ•°é‡
            filters: ç­›é€‰æ¡ä»¶ï¼ˆsubject, mastery_statusç­‰ï¼‰

        Returns:
            é”™é¢˜åˆ—è¡¨å“åº”
        """
        subject = filters.get("subject") if filters else None
        mastery_status = filters.get("mastery_status") if filters else None

        items, total = await self.mistake_repo.find_by_user(
            user_id=user_id,
            subject=subject,
            mastery_status=mastery_status,
            page=page,
            page_size=page_size,
        )

        return MistakeListResponse(
            items=[self._to_list_item(item) for item in items],
            total=total,
            page=page,
            page_size=page_size,
        )

    async def get_mistake_detail(
        self, mistake_id: UUID, user_id: UUID
    ) -> MistakeDetailResponse:
        """
        è·å–é”™é¢˜è¯¦æƒ…

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            é”™é¢˜è¯¦æƒ…å“åº”
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        return self._to_detail_response(mistake)

    async def create_mistake(
        self, user_id: UUID, request: CreateMistakeRequest
    ) -> MistakeDetailResponse:
        """
        åˆ›å»ºé”™é¢˜

        Args:
            user_id: ç”¨æˆ·ID
            request: åˆ›å»ºè¯·æ±‚

        Returns:
            é”™é¢˜è¯¦æƒ…å“åº”
        """
        # æ„é€ æ•°æ®
        data = {
            "user_id": (
                str(user_id) if is_sqlite else user_id
            ),  # SQLiteä½¿ç”¨å­—ç¬¦ä¸²ï¼ŒPostgreSQLä½¿ç”¨UUID
            "subject": request.subject,
            "title": request.title,
            "ocr_text": request.question_content,
            "image_urls": request.image_urls,
            "difficulty_level": request.difficulty_level or 2,
            "knowledge_points": request.knowledge_points,
            "mastery_status": "learning",
            "next_review_at": datetime.now() + timedelta(days=1),
            "source": "manual",
        }

        # åˆ›å»ºè®°å½•
        mistake = await self.mistake_repo.create(data)

        logger.info(f"Created mistake {mistake.id} for user {user_id}")

        return self._to_detail_response(mistake)

    async def update_mistake(
        self, mistake_id: UUID, user_id: UUID, request: UpdateMistakeRequest
    ) -> MistakeDetailResponse:
        """
        æ›´æ–°é”™é¢˜

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
            request: æ›´æ–°è¯·æ±‚

        Returns:
            æ›´æ–°åçš„é”™é¢˜è¯¦æƒ…
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        update_data = {}
        if request.title is not None:
            update_data["title"] = request.title
        if request.notes is not None:
            update_data["notes"] = request.notes
        if request.tags is not None:
            update_data["tags"] = request.tags

        if update_data:
            mistake = await self.mistake_repo.update(str(mistake_id), update_data)

        logger.info(f"Updated mistake {mistake_id}")

        return self._to_detail_response(mistake)

    async def delete_mistake(self, mistake_id: UUID, user_id: UUID) -> None:
        """
        åˆ é™¤é”™é¢˜

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))

        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        await self.mistake_repo.delete(str(mistake_id))

        logger.info(f"Deleted mistake {mistake_id}")

    async def get_today_review_tasks(self, user_id: UUID) -> TodayReviewResponse:
        """
        è·å–ä»Šæ—¥å¤ä¹ ä»»åŠ¡

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            ä»Šæ—¥å¤ä¹ ä»»åŠ¡å“åº”
        """
        mistakes = await self.mistake_repo.find_due_for_review(
            user_id=user_id, limit=50
        )

        tasks = []
        total_minutes = 0

        from src.utils.type_converters import (
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
        )

        for mistake in mistakes:
            # ğŸ› ï¸ å®‰å…¨åœ°æå–ORMå±æ€§
            mistake_id_str = extract_orm_uuid_str(mistake, "id")
            next_review = getattr(mistake, "next_review_at", None)

            tasks.append(
                TodayReviewTask(
                    id=UUID(mistake_id_str),
                    mistake_id=UUID(mistake_id_str),
                    title=extract_orm_str(mistake, "title") or "æœªå‘½åé”™é¢˜",
                    subject=extract_orm_str(mistake, "subject"),
                    review_round=(extract_orm_int(mistake, "review_count") or 0) + 1,
                    due_date=(
                        next_review.isoformat()
                        if next_review and hasattr(next_review, "isoformat")
                        else datetime.now().isoformat()
                    ),
                    question_content=extract_orm_str(mistake, "ocr_text") or "",
                    image_urls=getattr(mistake, "image_urls", None) or [],
                )
            )
            estimated_time = extract_orm_int(mistake, "estimated_time")
            total_minutes += estimated_time if estimated_time else 5

        logger.info(
            f"Retrieved {len(tasks)} review tasks for user {user_id}, estimated {total_minutes} minutes"
        )

        return TodayReviewResponse(
            tasks=tasks,
            total_count=len(tasks),
            completed_count=0,
            estimated_minutes=total_minutes,
        )

    async def complete_review(
        self, mistake_id: UUID, user_id: UUID, request: ReviewCompleteRequest
    ) -> ReviewCompleteResponse:
        """
        å®Œæˆå¤ä¹ 

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID
            request: å¤ä¹ å®Œæˆè¯·æ±‚

        Returns:
            å¤ä¹ å®Œæˆå“åº”
        """
        # 1. è·å–é”™é¢˜å¹¶éªŒè¯å½’å±
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        # 2. åˆ›å»ºå¤ä¹ è®°å½•æ•°æ®
        review_data = {
            "mistake_id": str(mistake_id),
            "user_id": str(user_id),
            "review_date": datetime.now(),
            "review_result": request.review_result,
            "time_spent": request.time_spent,
            "confidence_level": request.confidence_level,
            "user_answer": request.user_answer,
            "notes": request.notes,
            "review_method": "manual",
        }

        # 3. è·å–å¤ä¹ å†å²å¹¶è®¡ç®—æŒæ¡åº¦
        review_history = await self.review_repo.find_by_mistake(mistake_id)
        current_mastery = self.algorithm.calculate_mastery_level(review_history)

        # 4. è®¡ç®—ä¸‹æ¬¡å¤ä¹ æ—¶é—´
        from src.utils.type_converters import extract_orm_int

        next_review, interval = self.algorithm.calculate_next_review(
            review_count=extract_orm_int(mistake, "review_count")
            or 0,  # ğŸ› ï¸ ä½¿ç”¨extract_orm_int
            review_result=request.review_result,
            current_mastery=current_mastery,
            last_review_date=datetime.now(),
        )

        # 5. æ›´æ–°å¤ä¹ è®°å½•æ•°æ®
        review_data["mastery_level"] = current_mastery
        review_data["next_review_date"] = next_review
        review_data["interval_days"] = interval

        # 6. ä¿å­˜å¤ä¹ è®°å½•
        review = await self.review_repo.create(review_data)

        from src.utils.type_converters import extract_orm_uuid_str

        # 7. æ›´æ–°é”™é¢˜çŠ¶æ€
        update_data = {
            "review_count": mistake.review_count + 1,
            "last_review_at": datetime.now(),
            "next_review_at": next_review,
        }

        if request.review_result == "correct":
            update_data["correct_count"] = mistake.correct_count + 1

        # 8. åˆ¤æ–­æ˜¯å¦å·²æŒæ¡
        consecutive_correct = update_data.get("correct_count", mistake.correct_count)
        is_mastered = self.algorithm.is_mastered(
            mastery_level=current_mastery,
            consecutive_correct=consecutive_correct,
            min_reviews=3,
        )

        if is_mastered:
            update_data["mastery_status"] = "mastered"
        elif current_mastery >= 0.5:
            update_data["mastery_status"] = "reviewing"

        await self.mistake_repo.update(str(mistake_id), update_data)

        logger.info(
            f"Completed review for mistake {mistake_id}, mastery: {current_mastery}, next review: {next_review}"
        )

        return ReviewCompleteResponse(
            review_id=UUID(extract_orm_uuid_str(review, "id")),
            mastery_level=current_mastery,
            next_review_date=next_review,
            is_mastered=is_mastered,
        )

    async def get_review_history(
        self, mistake_id: UUID, user_id: UUID
    ) -> ReviewHistoryResponse:
        """
        è·å–å¤ä¹ å†å²

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            å¤ä¹ å†å²å“åº”
        """
        # éªŒè¯æƒé™
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        # è·å–å¤ä¹ å†å²
        reviews = await self.review_repo.find_by_mistake(mistake_id, limit=50)

        # è®¡ç®—å¹³å‡æŒæ¡åº¦
        avg_mastery = await self.review_repo.calculate_average_mastery(mistake_id)

        # æœ€æ–°æŒæ¡åº¦
        latest_mastery = reviews[0].mastery_level if reviews else 0.0

        from src.schemas.mistake import ReviewHistoryItem
        from src.utils.type_converters import (
            extract_orm_float,
            extract_orm_int,
            extract_orm_str,
            extract_orm_uuid_str,
            extract_orm_value,
        )

        items = [
            ReviewHistoryItem(
                id=UUID(extract_orm_uuid_str(r, "id")),
                review_date=extract_orm_value(r, "review_date", datetime.now()),
                review_result=extract_orm_str(r, "review_result"),
                mastery_level=extract_orm_float(r, "mastery_level") or 0.0,
                time_spent=extract_orm_int(r, "time_spent"),
                confidence_level=extract_orm_int(r, "confidence_level") or 0,
                notes=extract_orm_str(r, "notes"),
            )
            for r in reviews
        ]

        latest_mastery_value = (
            extract_orm_float(reviews[0], "mastery_level") or 0.0 if reviews else 0.0
        )

        return ReviewHistoryResponse(
            items=items,
            total=len(reviews),
            average_mastery=avg_mastery,
            latest_mastery=latest_mastery_value,
        )

    async def get_statistics(self, user_id: UUID) -> MistakeStatisticsResponse:
        """
        è·å–é”™é¢˜ç»Ÿè®¡

        Args:
            user_id: ç”¨æˆ·ID

        Returns:
            ç»Ÿè®¡å“åº”
        """
        stats = await self.mistake_repo.get_statistics(user_id)

        # è·å–è¿ç»­å¤ä¹ å¤©æ•°
        streak_days = await self.review_repo.get_review_streak(user_id)

        # æœ¬å‘¨å¤ä¹ æ¬¡æ•°
        week_start = datetime.now() - timedelta(days=7)
        week_reviews = await self.review_repo.count_reviews_by_date_range(
            user_id, week_start, datetime.now()
        )

        return MistakeStatisticsResponse(
            total_mistakes=stats["total"],
            not_mastered=stats["learning"],
            reviewing=stats["reviewing"],
            mastered=stats["mastered"],
            by_subject=stats["by_subject"],
            by_difficulty=stats["by_difficulty"],
            review_streak_days=streak_days,
            this_week_reviews=week_reviews,
        )

    async def get_mastery_progress(
        self, user_id: UUID, days: int = 7
    ) -> MasteryProgressResponse:
        """
        è·å–æŒæ¡åº¦è¿›åº¦

        Args:
            user_id: ç”¨æˆ·ID
            days: å¤©æ•°

        Returns:
            æŒæ¡åº¦è¿›åº¦å“åº”
        """
        # è·å–æœ€è¿‘Nå¤©çš„å¤ä¹ è®°å½•
        reviews = await self.review_repo.get_recent_reviews(user_id, days)

        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        from collections import defaultdict

        from src.utils.type_converters import extract_orm_float, extract_orm_value

        daily_stats = defaultdict(lambda: {"sum": 0.0, "count": 0})

        for review in reviews:
            review_date = extract_orm_value(review, "review_date", datetime.now())
            date_str = review_date.date().isoformat()
            mastery_level = extract_orm_float(review, "mastery_level") or 0.0
            daily_stats[date_str]["sum"] += mastery_level
            daily_stats[date_str]["count"] += 1

        # æ„å»ºè¿›åº¦é¡¹
        from src.schemas.mistake import MasteryProgressItem

        items = []
        for date_str in sorted(daily_stats.keys()):
            stats = daily_stats[date_str]
            avg_mastery = stats["sum"] / stats["count"] if stats["count"] > 0 else 0.0
            items.append(
                MasteryProgressItem(
                    date=date_str,
                    mastery_level=round(avg_mastery, 2),
                    review_count=int(stats["count"]),
                )
            )

        # è®¡ç®—è¶‹åŠ¿
        trend = "stable"
        improvement = 0.0
        if len(items) >= 2:
            first_mastery = items[0].mastery_level
            last_mastery = items[-1].mastery_level
            improvement = last_mastery - first_mastery

            if improvement > 0.1:
                trend = "up"
            elif improvement < -0.1:
                trend = "down"

        return MasteryProgressResponse(
            items=items, trend=trend, improvement=round(improvement, 2)
        )

    async def analyze_mistake_with_ai(self, mistake_id: UUID, user_id: UUID) -> Dict:
        """
        ä½¿ç”¨AIåˆ†æé”™é¢˜

        Args:
            mistake_id: é”™é¢˜ID
            user_id: ç”¨æˆ·ID

        Returns:
            AIåˆ†æç»“æœï¼ŒåŒ…å«ï¼š
            - knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨
            - error_reasons: é”™è¯¯åŸå› åˆ†æ
            - suggestions: å­¦ä¹ å»ºè®®
        """
        mistake = await self.mistake_repo.get_by_id(str(mistake_id))
        if not mistake or str(mistake.user_id) != str(user_id):
            raise NotFoundError(f"é”™é¢˜ {mistake_id} ä¸å­˜åœ¨")

        if not self.bailian_service:
            raise ServiceError("AIæœåŠ¡æœªé…ç½®")

        try:
            from src.utils.type_converters import extract_orm_int, extract_orm_str

            # åˆå§‹åŒ–å˜é‡ï¼Œé¿å…åœ¨å¼‚å¸¸å¤„ç†ä¸­æœªç»‘å®š
            ai_content = ""

            # å®‰å…¨æå–ORMå±æ€§
            subject = extract_orm_str(mistake, "subject") or "æœªçŸ¥"
            difficulty = extract_orm_int(mistake, "difficulty_level")
            difficulty_text = str(difficulty) if difficulty else "æœªçŸ¥"
            ocr_text = extract_orm_str(mistake, "ocr_text") or "æ— é¢˜ç›®å†…å®¹"

            # æ„é€ åˆ†ææç¤ºè¯
            analysis_prompt = f"""è¯·åˆ†æä»¥ä¸‹é”™é¢˜ï¼Œæå–å…³é”®ä¿¡æ¯å¹¶ç»™å‡ºå­¦ä¹ å»ºè®®ã€‚

ã€é¢˜ç›®ä¿¡æ¯ã€‘
å­¦ç§‘ï¼š{subject}
éš¾åº¦ï¼š{difficulty_text}
é¢˜ç›®å†…å®¹ï¼š
{ocr_text}

ã€ä»»åŠ¡è¦æ±‚ã€‘
è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
1. knowledge_points: çŸ¥è¯†ç‚¹åˆ—è¡¨ï¼ˆæ•°ç»„ï¼Œ3-5ä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼‰
2. error_reason: é”™è¯¯åŸå› åˆ†æï¼ˆå­—ç¬¦ä¸²ï¼Œ100å­—ä»¥å†…ï¼‰
3. suggestions: å­¦ä¹ å»ºè®®ï¼ˆå­—ç¬¦ä¸²ï¼Œ150å­—ä»¥å†…ï¼Œç»™å‡ºå…·ä½“å¯è¡Œçš„å­¦ä¹ å»ºè®®ï¼‰

ç¤ºä¾‹æ ¼å¼ï¼š
{{
    "knowledge_points": ["ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹", "é…æ–¹æ³•", "åˆ¤åˆ«å¼"],
    "error_reason": "å¯¹åˆ¤åˆ«å¼çš„è®¡ç®—ç†è§£æœ‰è¯¯ï¼Œå¯¼è‡´è§£é¢˜æ€è·¯é”™è¯¯ã€‚",
    "suggestions": "å»ºè®®å¤ä¹ åˆ¤åˆ«å¼çš„å®šä¹‰å’Œåº”ç”¨ï¼Œå¤šåšç›¸å…³ç»ƒä¹ é¢˜ï¼Œé‡ç‚¹æŒæ¡bÂ²-4acçš„è®¡ç®—æ–¹æ³•ã€‚å¯ä»¥ä»ç®€å•é¢˜ç›®å…¥æ‰‹ï¼Œé€æ­¥æå‡éš¾åº¦ã€‚"
}}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å«å…¶ä»–å†…å®¹ã€‚"""

            # è°ƒç”¨ç™¾ç‚¼AIæœåŠ¡
            logger.info(f"å¼€å§‹AIåˆ†æé”™é¢˜: {mistake_id}")

            messages = [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„å­¦ç§‘æ•™å¸ˆï¼Œæ“…é•¿åˆ†æå­¦ç”Ÿçš„é”™é¢˜ï¼Œæ‰¾å‡ºçŸ¥è¯†ç›²ç‚¹å¹¶ç»™å‡ºé’ˆå¯¹æ€§å»ºè®®ã€‚",
                },
                {"role": "user", "content": analysis_prompt},
            ]

            response = await self.bailian_service.chat_completion(
                messages=messages,
                stream=False,
                temperature=0.7,  # é€‚ä¸­çš„åˆ›é€ æ€§
                max_tokens=1000,  # è¶³å¤Ÿçš„tokenç”¨äºè¯¦ç»†åˆ†æ
            )

            if not response.success:
                logger.error(f"AIåˆ†æå¤±è´¥: {response.error_message}")
                # é™çº§æ–¹æ¡ˆï¼šè¿”å›åŸºç¡€ä¿¡æ¯
                return self._fallback_analysis(mistake)

            # è§£æAIè¿”å›çš„JSON
            ai_content = response.content.strip() if response.content else ""

            # å°è¯•æå–JSONï¼ˆå¤„ç†AIå¯èƒ½è¿”å›çš„é¢å¤–æ–‡æœ¬ï¼‰
            json_match = re.search(r"\{.*\}", ai_content, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                analysis_result = json.loads(json_str)
            else:
                # å¦‚æœæ— æ³•æå–JSONï¼Œå°è¯•ç›´æ¥è§£æ
                analysis_result = json.loads(ai_content)

            # éªŒè¯å’Œæ ‡å‡†åŒ–è¿”å›ç»“æœ
            result = {
                "knowledge_points": analysis_result.get("knowledge_points", []),
                "error_reason": analysis_result.get("error_reason", ""),
                "suggestions": analysis_result.get("suggestions", ""),
                "ai_tokens_used": response.tokens_used,
                "analysis_time": response.processing_time,
            }

            # æ›´æ–°é”™é¢˜è®°å½•ä¸­çš„AIåˆ†æç»“æœï¼ˆå¯é€‰ï¼‰
            update_data = {}
            if result["knowledge_points"]:
                update_data["knowledge_points"] = result["knowledge_points"]

            if update_data:
                await self.mistake_repo.update(str(mistake_id), update_data)
            else:
                await self.db.commit()

            logger.info(
                f"AIåˆ†æå®Œæˆ: {mistake_id}, "
                f"çŸ¥è¯†ç‚¹æ•°é‡: {len(result['knowledge_points'])}, "
                f"Tokenä½¿ç”¨: {response.tokens_used}"
            )

            return result

        except json.JSONDecodeError as e:
            content_preview = ai_content[:200] if ai_content else "æ— AIå“åº”å†…å®¹"  # type: ignore[possibly-unbound]
            logger.error(f"AIè¿”å›çš„JSONè§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {content_preview}")
            # é™çº§æ–¹æ¡ˆ
            return self._fallback_analysis(mistake)

        except Exception as e:
            logger.error(f"AIåˆ†æé”™é¢˜å¤±è´¥: {e}", exc_info=True)
            # é™çº§æ–¹æ¡ˆï¼šè¿”å›åŸºç¡€ä¿¡æ¯
            return self._fallback_analysis(mistake)

    def _fallback_analysis(self, mistake) -> Dict:
        """
        AIåˆ†æå¤±è´¥æ—¶çš„é™çº§æ–¹æ¡ˆ

        Args:
            mistake: é”™é¢˜è®°å½•

        Returns:
            åŸºç¡€åˆ†æç»“æœ
        """
        logger.warning(f"ä½¿ç”¨é™çº§åˆ†ææ–¹æ¡ˆ: {mistake.id}")

        # æ ¹æ®å­¦ç§‘æä¾›é»˜è®¤çš„å­¦ä¹ å»ºè®®
        subject_suggestions = {
            "math": "å»ºè®®å›é¡¾ç›¸å…³ç« èŠ‚çš„åŸºç¡€æ¦‚å¿µï¼Œå¤šåšç±»ä¼¼é¢˜ç›®ç»ƒä¹ ï¼Œæ³¨æ„è§£é¢˜æ­¥éª¤çš„è§„èŒƒæ€§ã€‚",
            "chinese": "å»ºè®®åŠ å¼ºåŸºç¡€çŸ¥è¯†çš„ç§¯ç´¯ï¼Œå¤šé˜…è¯»ä¼˜ç§€èŒƒæ–‡ï¼Œæ³¨æ„ç­”é¢˜æŠ€å·§å’Œè¡¨è¾¾è§„èŒƒã€‚",
            "english": "å»ºè®®å¤ä¹ ç›¸å…³è¯­æ³•ç‚¹ï¼Œç§¯ç´¯è¯æ±‡ï¼Œå¤šåšé˜…è¯»å’Œå†™ä½œç»ƒä¹ ã€‚",
            "physics": "å»ºè®®ç†è§£ç‰©ç†æ¦‚å¿µçš„æœ¬è´¨ï¼ŒæŒæ¡å…¬å¼çš„æ¨å¯¼è¿‡ç¨‹ï¼Œå¤šåšå®éªŒåˆ†æé¢˜ã€‚",
            "chemistry": "å»ºè®®ç†Ÿè®°åŒ–å­¦æ–¹ç¨‹å¼ï¼Œç†è§£ååº”åŸç†ï¼Œæ³¨æ„å®éªŒæ“ä½œçš„ç»†èŠ‚ã€‚",
            "biology": "å»ºè®®ç³»ç»Ÿå¤ä¹ ç›¸å…³çŸ¥è¯†ç‚¹ï¼Œç†è§£ç”Ÿç‰©è¿‡ç¨‹ï¼Œæ³¨æ„å›¾è¡¨åˆ†æèƒ½åŠ›çš„åŸ¹å…»ã€‚",
        }

        return {
            "knowledge_points": mistake.knowledge_points or [],
            "error_reason": "å»ºè®®ä»”ç»†åˆ†æé¢˜ç›®è¦æ±‚ï¼Œå¯¹æ¯”æ­£ç¡®ç­”æ¡ˆæ‰¾å‡ºå·®å¼‚ã€‚",
            "suggestions": subject_suggestions.get(
                mistake.subject, "å»ºè®®å›é¡¾è¯¾æœ¬çŸ¥è¯†ï¼Œå¤šåšç»ƒä¹ ï¼ŒåŠæ—¶è¯·æ•™è€å¸ˆæˆ–åŒå­¦ã€‚"
            ),
            "ai_tokens_used": 0,
            "analysis_time": 0.0,
            "is_fallback": True,
        }
