"""
KnowledgeContextBuilder æœåŠ¡ - MCPä¸Šä¸‹æ–‡æ„å»ºå™¨

è´Ÿè´£ä¸ºAIä¸ªæ€§åŒ–é—®ç­”æ„å»ºç”¨æˆ·å­¦æƒ…ä¸Šä¸‹æ–‡ï¼ŒåŒ…æ‹¬ï¼š
- è–„å¼±çŸ¥è¯†ç‚¹åˆ†æ
- å­¦ä¹ åå¥½æå–
- ä¸Šä¸‹æ–‡æ‘˜è¦ç”Ÿæˆ
"""

import json
import math
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

from sqlalchemy import and_, func, select
from sqlalchemy.ext.asyncio import AsyncSession

from src.core.logging import get_logger
from src.models.homework import Homework, HomeworkSubmission
from src.models.learning import Question

logger = get_logger(__name__)


@dataclass
class WeakKnowledgePoint:
    """è–„å¼±çŸ¥è¯†ç‚¹æ•°æ®æ¨¡å‹"""

    knowledge_id: str
    knowledge_name: str
    subject: str
    error_rate: float  # é”™è¯¯ç‡ (0-1)
    error_count: int  # é”™è¯¯æ¬¡æ•°
    total_count: int  # æ€»å°è¯•æ¬¡æ•°
    last_error_time: datetime
    severity_score: float  # ä¸¥é‡ç¨‹åº¦è¯„åˆ† (0-1)
    prerequisite_knowledge: List[str]  # å‰ç½®çŸ¥è¯†ç‚¹


@dataclass
class LearningPreference:
    """å­¦ä¹ åå¥½æ•°æ®æ¨¡å‹"""

    active_subjects: Dict[str, float]  # æ´»è·ƒå­¦ç§‘åˆ†å¸ƒ
    difficulty_preference: Dict[str, float]  # éš¾åº¦åå¥½
    time_preference: Dict[str, int]  # æ—¶é—´åå¥½(å°æ—¶åˆ†å¸ƒ)
    interaction_preference: Dict[str, float]  # äº¤äº’åå¥½
    learning_pace: str  # å­¦ä¹ èŠ‚å¥: slow/medium/fast
    focus_duration: int  # ä¸“æ³¨æ—¶é•¿(åˆ†é’Ÿ)


@dataclass
class ContextSummary:
    """ä¸Šä¸‹æ–‡æ‘˜è¦æ•°æ®æ¨¡å‹"""

    total_questions: int
    total_study_time: int  # åˆ†é’Ÿ
    recent_activity_days: int
    dominant_subject: str
    current_level: str  # beginner/intermediate/advanced
    learning_streak: int  # è¿ç»­å­¦ä¹ å¤©æ•°


@dataclass
class LearningContext:
    """å®Œæ•´å­¦ä¹ ä¸Šä¸‹æ–‡æ•°æ®æ¨¡å‹"""

    user_id: str
    generated_at: datetime
    weak_knowledge_points: List[WeakKnowledgePoint]
    learning_preferences: LearningPreference
    context_summary: ContextSummary
    recent_errors: List[Dict[str, Any]]
    knowledge_mastery: Dict[str, float]  # çŸ¥è¯†ç‚¹æŒæ¡åº¦
    study_patterns: Dict[str, Any]  # å­¦ä¹ æ¨¡å¼


class KnowledgeContextBuilder:
    """ç”¨æˆ·å­¦æƒ…ä¸Šä¸‹æ–‡æ„å»ºå™¨

    ä¸ºAIä¸ªæ€§åŒ–é—®ç­”æä¾›ç”¨æˆ·çš„å­¦ä¹ ä¸Šä¸‹æ–‡ä¿¡æ¯
    """

    def __init__(self):
        self.weak_threshold = 0.6  # è–„å¼±çŸ¥è¯†ç‚¹é”™è¯¯ç‡é˜ˆå€¼
        self.time_decay_factor = 0.1  # æ—¶é—´è¡°å‡å› å­
        self.max_context_days = 90  # æœ€å¤§ä¸Šä¸‹æ–‡å¤©æ•°

    async def build_context(
        self,
        user_id: str,
        subject: Optional[str] = None,
        session_type: str = "learning",
    ) -> LearningContext:
        """æ„å»ºç”¨æˆ·å­¦æƒ…ä¸Šä¸‹æ–‡

        Args:
            user_id: ç”¨æˆ·ID
            subject: å­¦ç§‘ç­›é€‰ï¼ˆå¯é€‰ï¼‰
            session_type: ä¼šè¯ç±»å‹ learning/homework

        Returns:
            LearningContext: å®Œæ•´çš„å­¦ä¹ ä¸Šä¸‹æ–‡
        """
        from src.core.database import AsyncSessionLocal

        async with AsyncSessionLocal() as session:
            # å¹¶è¡Œè·å–å„ç±»ä¸Šä¸‹æ–‡æ•°æ®
            weak_points = await self._analyze_weak_knowledge_points(
                session, user_id, subject
            )
            preferences = await self._extract_learning_preferences(
                session, user_id, subject
            )
            summary = await self._generate_context_summary(session, user_id, subject)
            recent_errors = await self._get_recent_errors(session, user_id, subject)
            
            # ğŸ¯ NEW: ä¼˜å…ˆä»çŸ¥è¯†å›¾è°±å¿«ç…§è·å–æŒæ¡åº¦
            mastery = await self._get_mastery_from_snapshot(
                session, user_id, subject
            ) or await self._calculate_knowledge_mastery(session, user_id, subject)
            
            patterns = await self._analyze_study_patterns(session, user_id, subject)

            return LearningContext(
                user_id=user_id,
                generated_at=datetime.utcnow(),
                weak_knowledge_points=weak_points,
                learning_preferences=preferences,
                context_summary=summary,
                recent_errors=recent_errors,
                knowledge_mastery=mastery,
                study_patterns=patterns,
            )

    async def _analyze_weak_knowledge_points(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> List[WeakKnowledgePoint]:
        """åˆ†æè–„å¼±çŸ¥è¯†ç‚¹

        ç®—æ³•æ ¸å¿ƒï¼š
        1. æŸ¥è¯¢ç”¨æˆ·ä½œä¸šæäº¤å’Œé—®ç­”è®°å½•
        2. ç»Ÿè®¡å„çŸ¥è¯†ç‚¹é”™è¯¯ç‡ï¼Œåº”ç”¨æ—¶é—´è¡°å‡æƒé‡
        3. ç­›é€‰é”™è¯¯ç‡>=é˜ˆå€¼çš„çŸ¥è¯†ç‚¹å¹¶æ’åº
        """
        weak_points = []

        try:
            # æŸ¥è¯¢ä½œä¸šæäº¤è®°å½•
            homework_query = select(HomeworkSubmission).where(
                and_(
                    HomeworkSubmission.student_id == user_id,
                    HomeworkSubmission.status == "reviewed",
                    HomeworkSubmission.weak_knowledge_points.is_not(None),
                )
            )

            if subject:
                homework_query = homework_query.join(Homework).where(
                    Homework.subject == subject
                )

            homework_result = await session.execute(homework_query)
            submissions = homework_result.scalars().all()

            # ç»Ÿè®¡çŸ¥è¯†ç‚¹é”™è¯¯æƒ…å†µ
            knowledge_stats = {}

            for submission in submissions:
                submitted_at = submission.submitted_at or submission.created_at
                # ç±»å‹è½¬æ¢ï¼šç¡®ä¿æ˜¯ datetime å¯¹è±¡
                if submitted_at is None:
                    submitted_at = datetime.utcnow()
                elif hasattr(submitted_at, "replace") and hasattr(
                    submitted_at, "tzinfo"
                ):
                    # æ˜¯ datetime å¯¹è±¡ï¼Œç§»é™¤æ—¶åŒºä¿¡æ¯
                    submitted_at = (
                        submitted_at.replace(tzinfo=None)
                        if submitted_at.tzinfo
                        else submitted_at
                    )
                else:
                    # å…¶ä»–æƒ…å†µï¼Œä½¿ç”¨å½“å‰æ—¶é—´
                    submitted_at = datetime.utcnow()

                time_weight = self._calculate_time_decay_weight(submitted_at)  # type: ignore

                # è§£æè–„å¼±çŸ¥è¯†ç‚¹æ•°æ®
                weak_points_data = submission.weak_knowledge_points or []
                if isinstance(weak_points_data, str):
                    try:
                        weak_points_data = json.loads(weak_points_data)
                    except json.JSONDecodeError:
                        continue

                # å¤„ç†çŸ¥è¯†ç‚¹ç»Ÿè®¡
                for point_data in weak_points_data:
                    if isinstance(point_data, dict):
                        knowledge_id = point_data.get("knowledge_id") or point_data.get(
                            "name", "unknown"
                        )
                        knowledge_name = point_data.get("name", knowledge_id)
                        error_count = point_data.get("error_count", 1)
                        total_count = point_data.get("total_count", 1)

                        if knowledge_id not in knowledge_stats:
                            knowledge_stats[knowledge_id] = {
                                "name": knowledge_name,
                                "total_errors": 0,
                                "total_attempts": 0,
                                "weighted_errors": 0,
                                "weighted_attempts": 0,
                                "last_error_time": submitted_at,
                                "subject": getattr(submission, "homework", {}).get(
                                    "subject"
                                )
                                or subject
                                or "æ•°å­¦",
                            }

                        stats = knowledge_stats[knowledge_id]
                        stats["total_errors"] += error_count
                        stats["total_attempts"] += total_count
                        stats["weighted_errors"] += error_count * time_weight
                        stats["weighted_attempts"] += total_count * time_weight

                        if submitted_at > stats["last_error_time"]:
                            stats["last_error_time"] = submitted_at

            # ä»é—®ç­”è®°å½•è¡¥å……æ•°æ®
            question_query = select(Question).where(Question.user_id == user_id)
            if subject:
                question_query = question_query.where(Question.subject == subject)

            question_result = await session.execute(question_query)
            questions = question_result.scalars().all()

            for question in questions:
                question_time = question.created_at
                # ç±»å‹è½¬æ¢ï¼šç¡®ä¿æ˜¯ datetime å¯¹è±¡
                if question_time is None:
                    question_time = datetime.utcnow()
                elif hasattr(question_time, "replace") and hasattr(
                    question_time, "tzinfo"
                ):
                    question_time = (
                        question_time.replace(tzinfo=None)
                        if question_time.tzinfo
                        else question_time
                    )
                else:
                    question_time = datetime.utcnow()

                time_weight = self._calculate_time_decay_weight(question_time)  # type: ignore
                content = question.content.lower()

                # ä»é—®é¢˜å†…å®¹æ¨æ–­è–„å¼±çŸ¥è¯†ç‚¹
                inferred_points = self._extract_knowledge_from_question(
                    content, subject
                )

                for point_name in inferred_points:
                    knowledge_id = f"inferred_{point_name}"

                    if knowledge_id not in knowledge_stats:
                        knowledge_stats[knowledge_id] = {
                            "name": point_name,
                            "total_errors": 0,
                            "total_attempts": 0,
                            "weighted_errors": 0,
                            "weighted_attempts": 0,
                            "last_error_time": question_time,
                            "subject": getattr(question, "subject", None)
                            or subject
                            or "æ•°å­¦",
                        }

                    stats = knowledge_stats[knowledge_id]
                    stats["total_attempts"] += 1
                    stats["weighted_attempts"] += time_weight

                    if self._is_help_seeking_question(content):
                        stats["total_errors"] += 1
                        stats["weighted_errors"] += time_weight
                        if question_time > stats["last_error_time"]:
                            stats["last_error_time"] = question_time

            # è®¡ç®—é”™è¯¯ç‡å¹¶ç­›é€‰è–„å¼±çŸ¥è¯†ç‚¹
            for knowledge_id, stats in knowledge_stats.items():
                if stats["total_attempts"] == 0:
                    continue

                # ä½¿ç”¨åŠ æƒé”™è¯¯ç‡
                if stats["weighted_attempts"] > 0:
                    error_rate = stats["weighted_errors"] / stats["weighted_attempts"]
                else:
                    error_rate = stats["total_errors"] / stats["total_attempts"]

                # ç­›é€‰é”™è¯¯ç‡è¶…è¿‡é˜ˆå€¼çš„çŸ¥è¯†ç‚¹
                if error_rate >= self.weak_threshold:
                    last_error_time = stats["last_error_time"]
                    time_weight = self._calculate_time_decay_weight(last_error_time)
                    severity_score = self._calculate_severity_score(
                        error_rate, stats["total_errors"], time_weight
                    )

                    weak_point = WeakKnowledgePoint(
                        knowledge_id=knowledge_id,
                        knowledge_name=stats["name"],
                        subject=stats["subject"],
                        error_rate=error_rate,
                        error_count=stats["total_errors"],
                        total_count=stats["total_attempts"],
                        last_error_time=last_error_time,
                        severity_score=severity_score,
                        prerequisite_knowledge=[],
                    )
                    weak_points.append(weak_point)

            # æŒ‰ä¸¥é‡ç¨‹åº¦æ’åºï¼Œé™åˆ¶è¿”å›æ•°é‡
            weak_points.sort(key=lambda x: x.severity_score, reverse=True)
            return weak_points[:20]

        except Exception as e:
            logger.error(f"åˆ†æè–„å¼±çŸ¥è¯†ç‚¹å¤±è´¥: {str(e)}")
            return []

    async def _extract_learning_preferences(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> LearningPreference:
        """æå–å­¦ä¹ åå¥½

        åŸºäºç”¨æˆ·å†å²å­¦ä¹ è¡Œä¸ºåˆ†æåå¥½ç‰¹å¾
        """
        try:
            # 1. åˆ†ææ´»è·ƒå­¦ç§‘åˆ†å¸ƒ
            subject_query = (
                select(
                    func.coalesce(Question.subject, "æ•°å­¦").label("subject"),
                    func.count().label("count"),
                )
                .where(Question.user_id == user_id)
                .group_by(Question.subject)
            )

            subject_result = await session.execute(subject_query)
            subject_rows = subject_result.fetchall()

            total_questions = 0
            count_list = []
            for row in subject_rows:
                count_list.append(getattr(row, "count", 0))
            total_questions = sum(count_list) if count_list else 0

            active_subjects = {}
            if total_questions > 0:
                for row in subject_rows:
                    subject_name = getattr(row, "subject", None) or "æ•°å­¦"
                    count_val = getattr(row, "count", 0)
                    active_subjects[subject_name] = count_val / total_questions
            else:
                active_subjects = {"æ•°å­¦": 1.0}

            # 2. åˆ†ææ—¶é—´åå¥½ï¼ˆåŸºäºæé—®æ—¶é—´åˆ†å¸ƒï¼‰
            time_preference = {}
            for i in range(24):
                time_preference[str(i)] = 0

            questions_query = select(Question.created_at).where(
                Question.user_id == user_id
            )
            questions_result = await session.execute(questions_query)
            question_times = questions_result.scalars().all()

            if question_times:
                for created_at in question_times:
                    if created_at and hasattr(created_at, "hour"):
                        hour = str(created_at.hour)
                        time_preference[hour] = time_preference.get(hour, 0) + 1
            else:
                # é»˜è®¤æ´»è·ƒæ—¶é—´ï¼ˆå­¦ä¹ æ—¶é—´ï¼‰
                time_preference.update({"9": 2, "14": 3, "19": 5, "20": 4})

            # 3. åˆ†æéš¾åº¦åå¥½ï¼ˆåŸºäºä½œä¸šéš¾åº¦åˆ†å¸ƒï¼‰
            # difficulty_level: 1=easy, 2=medium, 3=hard
            difficulty_query = (
                select(
                    func.coalesce(Homework.difficulty_level, 2).label("difficulty"),
                    func.count().label("count"),
                )
                .select_from(HomeworkSubmission.__table__.join(Homework.__table__))
                .where(HomeworkSubmission.student_id == user_id)
                .group_by(Homework.difficulty_level)
            )

            difficulty_result = await session.execute(difficulty_query)
            difficulty_rows = difficulty_result.fetchall()

            total_homeworks = 0
            homework_count_list = []
            for row in difficulty_rows:
                homework_count_list.append(getattr(row, "count", 0))
            total_homeworks = sum(homework_count_list) if homework_count_list else 0

            # éš¾åº¦çº§åˆ«æ˜ å°„: 1=easy, 2=medium, 3=hard
            difficulty_level_map = {1: "easy", 2: "medium", 3: "hard"}
            difficulty_preference = {}
            if total_homeworks > 0:
                for row in difficulty_rows:
                    difficulty_int = getattr(row, "difficulty", None) or 2
                    difficulty_level = difficulty_level_map.get(
                        difficulty_int, "medium"
                    )
                    count_val = getattr(row, "count", 0)
                    difficulty_preference[difficulty_level] = (
                        count_val / total_homeworks
                    )
            else:
                difficulty_preference = {"easy": 0.3, "medium": 0.5, "hard": 0.2}

            # 4. åˆ†æäº¤äº’åå¥½ï¼ˆåŸºäºé—®é¢˜å†…å®¹ç‰¹å¾ï¼‰
            interaction_preference = {"text": 0.7, "image": 0.2, "voice": 0.1}

            # 5. æ¨æ–­å­¦ä¹ èŠ‚å¥å’Œä¸“æ³¨æ—¶é•¿
            learning_pace = "medium"
            focus_duration = 30

            # åŸºäºé—®é¢˜æé—®é¢‘ç‡æ¨æ–­å­¦ä¹ èŠ‚å¥
            if total_questions > 50:
                learning_pace = "fast"
                focus_duration = 45
            elif total_questions < 10:
                learning_pace = "slow"
                focus_duration = 20

            return LearningPreference(
                active_subjects=active_subjects,
                difficulty_preference=difficulty_preference,
                time_preference=time_preference,
                interaction_preference=interaction_preference,
                learning_pace=learning_pace,
                focus_duration=focus_duration,
            )

        except Exception as e:
            logger.error(f"æå–å­¦ä¹ åå¥½å¤±è´¥: {str(e)}")
            # è¿”å›é»˜è®¤åå¥½
            return LearningPreference(
                active_subjects={"æ•°å­¦": 1.0},
                difficulty_preference={"easy": 0.3, "medium": 0.5, "hard": 0.2},
                time_preference={"19": 5, "20": 4, "21": 3},
                interaction_preference={"text": 0.7, "image": 0.2, "voice": 0.1},
                learning_pace="medium",
                focus_duration=30,
            )

    async def _generate_context_summary(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> ContextSummary:
        """ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦

        ç»Ÿè®¡ç”¨æˆ·å­¦ä¹ æ¦‚å†µ
        """
        try:
            # 1. ç»Ÿè®¡æ€»é—®é¢˜æ•°
            questions_query = (
                select(func.count())
                .select_from(Question)
                .where(Question.user_id == user_id)
            )
            if subject:
                questions_query = questions_query.where(Question.subject == subject)

            questions_result = await session.execute(questions_query)
            total_questions = questions_result.scalar() or 0

            # 2. ç»Ÿè®¡æ€»å­¦ä¹ æ—¶é—´ï¼ˆä¼°ç®—ï¼‰
            # å‡è®¾æ¯ä¸ªé—®é¢˜å¹³å‡éœ€è¦5åˆ†é’Ÿæ€è€ƒå’Œæé—®
            total_study_time = total_questions * 5

            # 3. ç»Ÿè®¡æœ€è¿‘æ´»è·ƒå¤©æ•°
            thirty_days_ago = datetime.utcnow() - timedelta(days=30)
            recent_activity_query = select(
                func.count(func.distinct(func.date(Question.created_at)))
            ).where(
                and_(
                    Question.user_id == user_id, Question.created_at >= thirty_days_ago
                )
            )

            if subject:
                recent_activity_query = recent_activity_query.where(
                    Question.subject == subject
                )

            recent_activity_result = await session.execute(recent_activity_query)
            recent_activity_days = recent_activity_result.scalar() or 0

            # 4. ç¡®å®šä¸»å¯¼å­¦ç§‘
            dominant_subject_query = (
                select(func.coalesce(Question.subject, "æ•°å­¦").label("subject"))
                .where(Question.user_id == user_id)
                .group_by(Question.subject)
                .order_by(func.count().desc())
                .limit(1)
            )

            dominant_result = await session.execute(dominant_subject_query)
            dominant_subject = dominant_result.scalar() or "æ•°å­¦"

            # 5. è¯„ä¼°å½“å‰æ°´å¹³
            current_level = "beginner"
            if total_questions > 20:
                current_level = "intermediate"
            if total_questions > 100:
                current_level = "advanced"

            # 6. è®¡ç®—å­¦ä¹ è¿ç»­æ€§
            learning_streak = min(recent_activity_days, 30)

            return ContextSummary(
                total_questions=total_questions,
                total_study_time=total_study_time,
                recent_activity_days=recent_activity_days,
                dominant_subject=dominant_subject,
                current_level=current_level,
                learning_streak=learning_streak,
            )

        except Exception as e:
            logger.error(f"ç”Ÿæˆä¸Šä¸‹æ–‡æ‘˜è¦å¤±è´¥: {str(e)}")
            return ContextSummary(
                total_questions=0,
                total_study_time=0,
                recent_activity_days=0,
                dominant_subject="æ•°å­¦",
                current_level="beginner",
                learning_streak=0,
            )

    def _calculate_time_decay_weight(self, timestamp: datetime) -> float:
        """è®¡ç®—æ—¶é—´è¡°å‡æƒé‡"""
        current_time = datetime.utcnow()
        time_diff = (current_time - timestamp).total_seconds() / 86400  # è½¬æ¢ä¸ºå¤©æ•°

        # æŒ‡æ•°è¡°å‡: weight = e^(-decay_factor * days)
        weight = math.exp(-self.time_decay_factor * time_diff)
        return max(weight, 0.1)  # æœ€å°æƒé‡0.1

    def _calculate_severity_score(
        self, error_rate: float, error_count: int, time_weight: float
    ) -> float:
        """è®¡ç®—è–„å¼±çŸ¥è¯†ç‚¹ä¸¥é‡ç¨‹åº¦è¯„åˆ†"""
        # ç»¼åˆè€ƒè™‘é”™è¯¯ç‡ã€é”™è¯¯æ¬¡æ•°å’Œæ—¶é—´æƒé‡
        base_score = error_rate * 0.6  # é”™è¯¯ç‡å 60%
        frequency_score = min(error_count / 10, 1.0) * 0.3  # é”™è¯¯é¢‘æ¬¡å 30%
        recency_score = time_weight * 0.1  # æ—¶é—´æƒé‡å 10%

        return min(base_score + frequency_score + recency_score, 1.0)

    def _extract_knowledge_from_question(
        self, content: str, subject: Optional[str]
    ) -> List[str]:
        """ä»é—®é¢˜å†…å®¹æå–çŸ¥è¯†ç‚¹ï¼ˆç®€åŒ–å®ç°ï¼‰"""
        knowledge_keywords = {
            "æ•°å­¦": ["å‡½æ•°", "æ–¹ç¨‹", "å‡ ä½•", "ä»£æ•°", "æ¦‚ç‡", "ç»Ÿè®¡", "å¾®ç§¯åˆ†"],
            "è¯­æ–‡": ["é˜…è¯»ç†è§£", "ä½œæ–‡", "å¤è¯—è¯", "æ–‡è¨€æ–‡", "è¯­æ³•"],
            "è‹±è¯­": ["è¯­æ³•", "è¯æ±‡", "é˜…è¯»", "å†™ä½œ", "å¬åŠ›", "å£è¯­"],
        }

        current_subject = subject or "æ•°å­¦"
        keywords = knowledge_keywords.get(current_subject, [])

        found_points = []
        for keyword in keywords:
            if keyword in content:
                found_points.append(keyword)

        return found_points

    def _is_help_seeking_question(self, content: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºæ±‚åŠ©æ€§è´¨çš„é—®é¢˜"""
        help_indicators = ["æ€ä¹ˆ", "å¦‚ä½•", "ä¸ä¼š", "ä¸æ‡‚", "å¸®åŠ©", "è§£ç­”", "ä¸æ˜ç™½"]
        return any(indicator in content for indicator in help_indicators)

    async def _get_recent_errors(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> List[Dict[str, Any]]:
        """è·å–æœ€è¿‘é”™é¢˜"""
        # TODO: æŸ¥è¯¢æœ€è¿‘çš„é”™é¢˜è®°å½•
        return []

    async def _get_mastery_from_snapshot(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> Optional[Dict[str, float]]:
        """
        ä»çŸ¥è¯†å›¾è°±å¿«ç…§è·å–æŒæ¡åº¦
        
        Returns:
            Dict[str, float]: çŸ¥è¯†ç‚¹åç§° -> æŒæ¡åº¦ (0-1)
        """
        try:
            from src.models.knowledge_graph import UserKnowledgeGraphSnapshot
            from uuid import UUID
            
            # æŸ¥è¯¢æœ€æ–°å¿«ç…§
            stmt = (
                select(UserKnowledgeGraphSnapshot)
                .where(UserKnowledgeGraphSnapshot.user_id == UUID(user_id))
                .order_by(UserKnowledgeGraphSnapshot.snapshot_date.desc())
                .limit(1)
            )
            
            if subject:
                stmt = stmt.where(UserKnowledgeGraphSnapshot.subject == subject)
            
            result = await session.execute(stmt)
            snapshot = result.scalar_one_or_none()
            
            if not snapshot:
                logger.info(f"æœªæ‰¾åˆ°ç”¨æˆ· {user_id} çš„çŸ¥è¯†å›¾è°±å¿«ç…§")
                return None
            
            # ä»å¿«ç…§ä¸­æå–æŒæ¡åº¦
            knowledge_points = snapshot.knowledge_points
            if isinstance(knowledge_points, str):
                knowledge_points = json.loads(knowledge_points)
            
            mastery_dict = {}
            for kp in knowledge_points:
                if isinstance(kp, dict):
                    name = kp.get("name") or kp.get("knowledge_point")
                    mastery = kp.get("mastery", 0.0)
                    if name:
                        mastery_dict[name] = mastery
            
            logger.info(
                f"âœ… ä»å¿«ç…§è·å–æŒæ¡åº¦: user={user_id}, "
                f"knowledge_points={len(mastery_dict)}"
            )
            return mastery_dict
            
        except Exception as e:
            logger.error(f"ä»å¿«ç…§è·å–æŒæ¡åº¦å¤±è´¥: {e}")
            return None

    async def _calculate_knowledge_mastery(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> Dict[str, float]:
        """è®¡ç®—çŸ¥è¯†ç‚¹æŒæ¡åº¦"""
        # TODO: åˆ†æå„çŸ¥è¯†ç‚¹çš„æŒæ¡ç¨‹åº¦
        return {}

    async def _analyze_study_patterns(
        self, session: AsyncSession, user_id: str, subject: Optional[str] = None
    ) -> Dict[str, Any]:
        """åˆ†æå­¦ä¹ æ¨¡å¼"""
        # TODO: åˆ†æç”¨æˆ·å­¦ä¹ ä¹ æƒ¯å’Œæ¨¡å¼
        return {}


# å•ä¾‹å®ä¾‹
knowledge_context_builder = KnowledgeContextBuilder()


async def main():
    """æµ‹è¯•å‡½æ•°"""
    # æµ‹è¯•ç”¨ä¾‹
    test_user_id = "test-user-123"

    builder = KnowledgeContextBuilder()
    context = await builder.build_context(test_user_id)

    print(f"ç”¨æˆ· {test_user_id} çš„å­¦æƒ…ä¸Šä¸‹æ–‡:")
    print(f"- è–„å¼±çŸ¥è¯†ç‚¹æ•°é‡: {len(context.weak_knowledge_points)}")
    print(f"- å­¦ä¹ åå¥½: {context.learning_preferences.learning_pace}")
    print(f"- ç”Ÿæˆæ—¶é—´: {context.generated_at}")


if __name__ == "__main__":
    import asyncio

    asyncio.run(main())
