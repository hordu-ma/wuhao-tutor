"""
é˜¿é‡Œäº‘ç™¾ç‚¼æ™ºèƒ½ä½“æœåŠ¡

è¯¥æ¨¡å—æä¾›ç»Ÿä¸€çš„ç™¾ç‚¼æ™ºèƒ½ä½“è°ƒç”¨æ¥å£ï¼Œæ”¯æŒï¼š
- èŠå¤©è¡¥å…¨ï¼ˆChat Completionï¼‰
- é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- è¯·æ±‚/å“åº”æ—¥å¿—è®°å½•
- æˆæœ¬ç›‘æ§ï¼ˆTokenä½¿ç”¨é‡ï¼‰
"""

import asyncio
import json
import logging
import time
from dataclasses import asdict, dataclass
from enum import Enum
from typing import Any, Dict, List, Optional, Union

import httpx
from pydantic import BaseModel, Field

from src.core.config import get_settings
from src.core.exceptions import (
    BailianAuthError,
    BailianRateLimitError,
    BailianServiceError,
    BailianTimeoutError,
)

logger = logging.getLogger("bailian_service")
settings = get_settings()


class MessageRole(str, Enum):
    """æ¶ˆæ¯è§’è‰²æšä¸¾"""

    USER = "user"
    ASSISTANT = "assistant"
    SYSTEM = "system"


@dataclass
class ChatMessage:
    """èŠå¤©æ¶ˆæ¯"""

    role: MessageRole
    content: str
    image_urls: Optional[List[str]] = None


@dataclass
class AIContext:
    """AIè°ƒç”¨ä¸Šä¸‹æ–‡"""

    user_id: Optional[str] = None
    subject: Optional[str] = None
    grade_level: Optional[int] = None
    session_id: Optional[str] = None
    metadata: Optional[Dict[str, Any]] = None


@dataclass
class ChatCompletionResponse:
    """èŠå¤©è¡¥å…¨å“åº”"""

    content: str
    tokens_used: int
    processing_time: float
    model: str
    request_id: str
    success: bool = True
    error_message: Optional[str] = None


class BailianService:
    """é˜¿é‡Œäº‘ç™¾ç‚¼æ™ºèƒ½ä½“æœåŠ¡"""

    def __init__(self, settings_override=None):
        _settings = settings_override or get_settings()
        self.application_id = _settings.BAILIAN_APPLICATION_ID
        self.api_key = _settings.BAILIAN_API_KEY
        self.base_url = _settings.BAILIAN_BASE_URL
        self.timeout = _settings.BAILIAN_TIMEOUT
        self.max_retries = _settings.BAILIAN_MAX_RETRIES

        # HTTPå®¢æˆ·ç«¯é…ç½®
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(self.timeout),
            headers={
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json",
                "User-Agent": "wuhao-tutor/0.1.0",
            },
        )

        logger.info(f"ç™¾ç‚¼æœåŠ¡åˆå§‹åŒ–æˆåŠŸ: {self.application_id[:8]}...")

    async def chat_completion(
        self,
        messages: List[Union[Dict[str, Any], ChatMessage]],
        context: Optional[AIContext] = None,
        **kwargs,
    ) -> ChatCompletionResponse:
        """
        èŠå¤©è¡¥å…¨æ¥å£

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            context: è°ƒç”¨ä¸Šä¸‹æ–‡
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰

        Returns:
            ChatCompletionResponse: èŠå¤©è¡¥å…¨å“åº”

        Raises:
            BailianServiceError: æœåŠ¡è°ƒç”¨å¤±è´¥
        """
        start_time = time.time()

        try:
            # æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼
            formatted_messages = self._format_messages(messages)

            # æ„å»ºè¯·æ±‚è½½è·
            payload = self._build_request_payload(formatted_messages, context, **kwargs)

            # è®°å½•è¯·æ±‚æ—¥å¿—
            self._log_request(payload, context)

            # è°ƒç”¨APIï¼ˆå¸¦é‡è¯•ï¼‰
            response_data = await self._call_bailian_api_with_retry(payload)

            # è§£æå“åº”
            response = self._parse_response(response_data, start_time)

            # è®°å½•å“åº”æ—¥å¿—
            self._log_response(response, context)

            return response

        except Exception as e:
            processing_time = time.time() - start_time
            error_response = ChatCompletionResponse(
                content="",
                tokens_used=0,
                processing_time=processing_time,
                model="",
                request_id="",
                success=False,
                error_message=str(e),
            )

            logger.error(f"ç™¾ç‚¼APIè°ƒç”¨å¤±è´¥: {e}")
            if context:
                logger.error(f"è°ƒç”¨ä¸Šä¸‹æ–‡: {asdict(context)}")

            raise BailianServiceError(f"èŠå¤©è¡¥å…¨è°ƒç”¨å¤±è´¥: {str(e)}") from e

    async def chat_completion_stream(
        self,
        messages: List[Union[Dict[str, Any], ChatMessage]],
        context: Optional[AIContext] = None,
        **kwargs,
    ):
        """
        æµå¼èŠå¤©è¡¥å…¨æ¥å£ (SSE)

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            context: è°ƒç”¨ä¸Šä¸‹æ–‡
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆtemperature, max_tokensç­‰ï¼‰

        Yields:
            Dict[str, Any]: SSE æ•°æ®å— {"content": str, "finish_reason": str, "usage": dict}

        Raises:
            BailianServiceError: æœåŠ¡è°ƒç”¨å¤±è´¥
        """
        start_time = time.time()

        try:
            # æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼
            formatted_messages = self._format_messages(messages)

            # æ„å»ºè¯·æ±‚è½½è·ï¼ˆå¯ç”¨æµå¼ï¼‰
            payload = self._build_request_payload(formatted_messages, context, **kwargs)
            payload["parameters"]["incremental_output"] = True  # å¯ç”¨æµå¼è¾“å‡º

            # è®°å½•è¯·æ±‚æ—¥å¿—
            self._log_request(payload, context)

            # æµå¼è°ƒç”¨API
            async for chunk in self._call_bailian_stream_api(payload):
                yield chunk

        except Exception as e:
            logger.error(f"ç™¾ç‚¼æµå¼APIè°ƒç”¨å¤±è´¥: {e}")
            if context:
                logger.error(f"è°ƒç”¨ä¸Šä¸‹æ–‡: {asdict(context)}")

            raise BailianServiceError(f"æµå¼èŠå¤©è¡¥å…¨è°ƒç”¨å¤±è´¥: {str(e)}") from e

    async def _call_bailian_stream_api(self, payload: Dict[str, Any]):
        """
        æµå¼è°ƒç”¨ç™¾ç‚¼API (SSE)

        ä½¿ç”¨ OpenAI å…¼å®¹ APIï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ï¼‰

        Args:
            payload: è¯·æ±‚è½½è·

        Yields:
            Dict: SSE æ•°æ®å—
        """
        # ä½¿ç”¨ OpenAI å…¼å®¹ç«¯ç‚¹ï¼Œæ”¯æŒå¤šæ¨¡æ€æµå¼
        # base_url å¯èƒ½åŒ…å« /api/v1ï¼Œéœ€è¦å»æ‰åå†æ‹¼æ¥
        base_domain = self.base_url.replace("/api/v1", "")
        url = f"{base_domain}/compatible-mode/v1/chat/completions"

        logger.debug(f"æµå¼API URL: {url}")

        # è½¬æ¢ä¸º OpenAI æ ¼å¼
        openai_payload = self._convert_to_openai_format(payload)
        openai_payload["stream"] = True
        openai_payload["stream_options"] = {"include_usage": True}

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json",
        }

        try:
            async with self.client.stream(
                "POST", url, json=openai_payload, headers=headers, timeout=120.0
            ) as response:
                # å¤„ç†HTTPé”™è¯¯
                if response.status_code == 401:
                    raise BailianAuthError("APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
                elif response.status_code == 429:
                    retry_after = response.headers.get("Retry-After", 60)
                    raise BailianRateLimitError(
                        f"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·{retry_after}ç§’åé‡è¯•"
                    )
                elif response.status_code >= 400:
                    error_text = await response.aread()
                    raise BailianServiceError(
                        f"HTTPé”™è¯¯ {response.status_code}: {error_text.decode('utf-8')}"
                    )

                # è§£æSSEæµ (OpenAI æ ¼å¼)
                full_content = ""
                is_finished = False  # ğŸ”§ æ ‡å¿—ï¼šç¡®ä¿åªå‘é€ä¸€æ¬¡ finish_reason="stop"

                async for line in response.aiter_lines():
                    if not line or not line.strip():
                        continue

                    # SSEæ ¼å¼: data: {json}
                    if line.startswith("data:"):
                        data_str = line[5:].strip()

                        # å¤„ç†ç»“æŸæ ‡è®°
                        if data_str == "[DONE]":
                            break

                        try:
                            data = json.loads(data_str)

                            # æå–å¢é‡å†…å®¹ (OpenAI æ ¼å¼)
                            choices = data.get("choices", [])

                            if choices:
                                delta = choices[0].get("delta", {})
                                content = delta.get("content", "")
                                finish_reason = choices[0].get("finish_reason")

                                if content:
                                    full_content += content

                                # ğŸ”§ ç¡®ä¿ usage æ°¸è¿œä¸ä¸º Noneï¼ˆ.get() é»˜è®¤å€¼åªåœ¨ key ä¸å­˜åœ¨æ—¶ç”Ÿæ•ˆï¼‰
                                usage = data.get("usage") or {}

                                # è¿”å›æ•°æ®å—
                                chunk = {
                                    "content": content,  # å¢é‡å†…å®¹
                                    "full_content": full_content,  # å®Œæ•´å†…å®¹ï¼ˆç´¯ç§¯ï¼‰
                                    "finish_reason": finish_reason,
                                    "usage": usage,
                                    "request_id": data.get("id", ""),
                                    "model": data.get("model", "qwen-vl-max"),
                                }

                                yield chunk

                                # å¦‚æœå®Œæˆï¼Œè®°å½•æ—¥å¿—å¹¶æ ‡è®°
                                if finish_reason == "stop":
                                    is_finished = True
                                    logger.info(
                                        f"æµå¼å“åº”å®Œæˆ: request_id={chunk['request_id']}, "
                                        f"total_tokens={usage.get('total_tokens', 0)}"
                                    )

                            elif data.get("usage") and not is_finished:
                                # ğŸ”§ ä¿®å¤ï¼šå¤„ç†åªåŒ…å« usage çš„æœ€åä¸€ä¸ª chunkï¼ˆchoices ä¸ºç©ºï¼‰
                                # åªæœ‰åœ¨ä¹‹å‰æ²¡æœ‰æ”¶åˆ° finish_reason="stop" æ—¶æ‰å¤„ç†
                                usage = data.get("usage") or {}

                                chunk = {
                                    "content": "",
                                    "full_content": full_content,
                                    "finish_reason": "stop",  # æ˜ç¡®æ ‡è®°å®Œæˆ
                                    "usage": usage,
                                    "request_id": data.get("id", ""),
                                    "model": data.get("model", "qwen-vl-max"),
                                }

                                yield chunk
                                is_finished = True

                                logger.info(
                                    f"æµå¼å“åº”å®Œæˆï¼ˆusage-only chunkï¼‰: request_id={chunk['request_id']}, "
                                    f"total_tokens={usage.get('total_tokens', 0)}"
                                )

                        except json.JSONDecodeError as e:
                            logger.warning(f"SSEæ•°æ®è§£æå¤±è´¥: {e}, line={line}")
                            continue

        except httpx.TimeoutException:
            raise BailianTimeoutError(f"APIè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰")
        except httpx.RequestError as e:
            raise BailianServiceError(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}") from e

    async def _call_bailian_api_with_retry(
        self, payload: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨

        Args:
            payload: è¯·æ±‚è½½è·

        Returns:
            Dict: APIå“åº”æ•°æ®
        """
        last_exception = None

        for attempt in range(self.max_retries + 1):
            try:
                if attempt > 0:
                    # æŒ‡æ•°é€€é¿
                    wait_time = min(2**attempt, 30)
                    logger.info(f"ç™¾ç‚¼APIé‡è¯•ç¬¬{attempt}æ¬¡ï¼Œç­‰å¾…{wait_time}ç§’...")
                    await asyncio.sleep(wait_time)

                return await self._call_bailian_api(payload)

            except BailianRateLimitError as e:
                last_exception = e
                if attempt == self.max_retries:
                    raise BailianServiceError(
                        f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}"
                    ) from e
                logger.warning(f"é‡åˆ°é™æµï¼Œå‡†å¤‡é‡è¯•: {e}")

            except BailianTimeoutError as e:
                last_exception = e
                if attempt == self.max_retries:
                    raise BailianServiceError(
                        f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡: {str(e)}"
                    ) from e
                logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œå‡†å¤‡é‡è¯•: {e}")

            except (BailianAuthError, BailianServiceError) as e:
                # è®¤è¯é”™è¯¯å’ŒæœåŠ¡é”™è¯¯ä¸é‡è¯•
                raise e

            except Exception as e:
                last_exception = e
                if attempt == self.max_retries:
                    raise BailianServiceError(f"APIè°ƒç”¨å¤±è´¥: {str(e)}") from e
                logger.warning(f"æœªçŸ¥é”™è¯¯ï¼Œå‡†å¤‡é‡è¯•: {e}")

        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        raise BailianServiceError(
            f"APIè°ƒç”¨å¤±è´¥ï¼Œå·²é‡è¯•{self.max_retries}æ¬¡"
        ) from last_exception

    async def _call_bailian_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨ç™¾ç‚¼API

        Args:
            payload: è¯·æ±‚è½½è·

        Returns:
            Dict: APIå“åº”æ•°æ®

        Raises:
            BailianServiceError: å„ç§APIè°ƒç”¨é”™è¯¯
        """
        model = payload.get("model", "")

        # VLæ¨¡å‹ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼
        if self._is_vl_model(model):
            logger.info(
                f"ä½¿ç”¨VLæ¨¡å‹OpenAIå…¼å®¹æ¨¡å¼è°ƒç”¨: {model}",
                extra={
                    "model": model,
                    "api_mode": "openai_compatible",
                    "message_count": len(payload.get("input", {}).get("messages", [])),
                },
            )
            return await self._call_vl_model_api(payload)  # æ™®é€šæ¨¡å‹ä½¿ç”¨åŸç”ŸAPI
        url = f"{self.base_url}/services/aigc/text-generation/generation"

        try:
            response = await self.client.post(url, json=payload)

            # å¤„ç†HTTPé”™è¯¯
            if response.status_code == 401:
                raise BailianAuthError("APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            elif response.status_code == 429:
                retry_after = response.headers.get("Retry-After", 60)
                raise BailianRateLimitError(f"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·{retry_after}ç§’åé‡è¯•")
            elif response.status_code >= 400:
                error_text = response.text
                raise BailianServiceError(
                    f"HTTPé”™è¯¯ {response.status_code}: {error_text}"
                )

            # è§£æJSONå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                raise BailianServiceError(f"æ— æ•ˆçš„JSONå“åº”: {response.text}")

            # æ£€æŸ¥ä¸šåŠ¡é”™è¯¯
            if not response_data.get("success", True):
                error_msg = response_data.get("message", "æœªçŸ¥ä¸šåŠ¡é”™è¯¯")
                error_code = response_data.get("code", "UNKNOWN")
                raise BailianServiceError(f"ä¸šåŠ¡é”™è¯¯ [{error_code}]: {error_msg}")

            return response_data

        except httpx.TimeoutException:
            raise BailianTimeoutError(f"APIè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰")
        except httpx.RequestError as e:
            raise BailianServiceError(f"ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}") from e

    def _format_messages(
        self, messages: List[Union[Dict[str, Any], ChatMessage]]
    ) -> List[Dict[str, Any]]:
        """
        æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼ï¼Œæ”¯æŒå¤šæ¨¡æ€å†…å®¹

        Args:
            messages: åŸå§‹æ¶ˆæ¯åˆ—è¡¨

        Returns:
            List[Dict]: æ ‡å‡†åŒ–çš„æ¶ˆæ¯åˆ—è¡¨ï¼Œæ”¯æŒæ–‡æœ¬å’Œå›¾ç‰‡
        """
        formatted = []

        for msg in messages:
            if isinstance(msg, ChatMessage):
                # å¤„ç† ChatMessage å¯¹è±¡
                formatted_msg: Dict[str, Any] = {"role": msg.role.value}

                # å¦‚æœæœ‰å›¾ç‰‡URLsï¼Œè½¬æ¢ä¸ºå¤šæ¨¡æ€æ ¼å¼
                if hasattr(msg, "image_urls") and msg.image_urls:
                    formatted_msg["content"] = self._build_multimodal_content(
                        msg.content, msg.image_urls
                    )
                else:
                    # çº¯æ–‡æœ¬å†…å®¹
                    formatted_msg["content"] = msg.content

                formatted.append(formatted_msg)

            elif isinstance(msg, dict):
                # éªŒè¯å¿…è¦å­—æ®µ
                if "role" not in msg:
                    raise ValueError("æ¶ˆæ¯å¿…é¡»åŒ…å«'role'å­—æ®µ")

                formatted_msg: Dict[str, Any] = {"role": msg["role"]}

                # å¤„ç†å†…å®¹å­—æ®µï¼Œæ”¯æŒå¤šæ¨¡æ€
                if "content" in msg and "image_urls" in msg and msg["image_urls"]:
                    # æ„å»ºå¤šæ¨¡æ€å†…å®¹
                    formatted_msg["content"] = self._build_multimodal_content(
                        str(msg["content"]), msg["image_urls"]
                    )
                elif "content" in msg:
                    # çº¯æ–‡æœ¬å†…å®¹
                    formatted_msg["content"] = str(msg["content"])
                else:
                    raise ValueError("æ¶ˆæ¯å¿…é¡»åŒ…å«'content'å­—æ®µ")

                formatted.append(formatted_msg)

            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ¶ˆæ¯ç±»å‹: {type(msg)}")

        return formatted

    def _build_multimodal_content(
        self, text_content: str, image_urls: List[str]
    ) -> List[Dict[str, Any]]:
        """
        æ„å»ºå¤šæ¨¡æ€å†…å®¹æ ¼å¼

        Args:
            text_content: æ–‡æœ¬å†…å®¹
            image_urls: å›¾ç‰‡URLåˆ—è¡¨

        Returns:
            List[Dict]: å¤šæ¨¡æ€å†…å®¹æ•°ç»„
        """
        content = []

        # æ·»åŠ æ–‡æœ¬éƒ¨åˆ†
        if text_content and text_content.strip():
            content.append({"type": "text", "text": text_content})

        # æ·»åŠ å›¾ç‰‡éƒ¨åˆ†
        for image_url in image_urls:
            if image_url and image_url.strip():
                content.append({"type": "image_url", "image_url": {"url": image_url}})

                # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ¯ä¸ªå›¾ç‰‡URL
                logger.info(
                    f"æ·»åŠ å›¾ç‰‡åˆ°å¤šæ¨¡æ€å†…å®¹: {image_url[:100]}...",
                    extra={"image_url": image_url, "url_length": len(image_url)},
                )

        logger.info(
            f"æ„å»ºå¤šæ¨¡æ€å†…å®¹å®Œæˆ: text_parts={1 if text_content else 0}, image_parts={len(image_urls)}",
            extra={
                "content_parts": len(content),
                "has_text": bool(text_content),
                "image_count": len(image_urls),
            },
        )

        return content

    def _has_images_in_messages(self, messages: List[Dict[str, Any]]) -> bool:
        """
        æ£€æŸ¥æ¶ˆæ¯åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å«å›¾ç‰‡

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦åŒ…å«å›¾ç‰‡
        """
        for message in messages:
            content = message.get("content")
            if isinstance(content, list):
                # å¤šæ¨¡æ€å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ç±»å‹
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "image_url":
                        return True
        return False

    def _build_request_payload(
        self,
        messages: List[Dict[str, Any]],
        context: Optional[AIContext] = None,
        **kwargs,
    ) -> Dict[str, Any]:
        """
        æ„å»ºAPIè¯·æ±‚è½½è·ï¼Œæ”¯æŒå¤šæ¨¡æ€æ¶ˆæ¯

        Args:
            messages: æ ¼å¼åŒ–çš„æ¶ˆæ¯åˆ—è¡¨ï¼ˆå¯èƒ½åŒ…å«å›¾ç‰‡ï¼‰
            context: è°ƒç”¨ä¸Šä¸‹æ–‡
            **kwargs: å…¶ä»–å‚æ•°

        Returns:
            Dict: è¯·æ±‚è½½è·
        """
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å›¾ç‰‡ï¼Œå¦‚æœæœ‰åˆ™ä½¿ç”¨è§†è§‰æ¨¡å‹
        has_images = self._has_images_in_messages(messages)
        model = "qwen-vl-max" if has_images else "qwen-turbo"

        # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šè®°å½•æ¨¡å‹é€‰æ‹©å’Œå›¾ç‰‡æ£€æµ‹
        if has_images:
            logger.info(
                f"æ£€æµ‹åˆ°å›¾ç‰‡æ¶ˆæ¯ï¼Œä½¿ç”¨VLæ¨¡å‹: {model}",
                extra={
                    "model": model,
                    "has_images": has_images,
                    "message_count": len(messages),
                },
            )
        else:
            logger.debug(f"çº¯æ–‡æœ¬æ¶ˆæ¯ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å‹: {model}")

        payload = {
            "model": model,
            "input": {"messages": messages},
            "parameters": {
                "result_format": "message",
                "max_tokens": kwargs.get("max_tokens", 1500),
                "temperature": kwargs.get("temperature", 0.7),
                "top_p": kwargs.get("top_p", 0.8),
                "top_k": kwargs.get("top_k", 100),
            },
        }

        # æ·»åŠ åº”ç”¨ID
        if self.application_id:
            payload["app_id"] = self.application_id

        # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
        if context:
            if context.user_id:
                payload["user_id"] = context.user_id
            if context.session_id:
                payload["session_id"] = context.session_id
            if context.metadata:
                payload.setdefault("parameters", {}).update(context.metadata)

        return payload

    def _convert_to_openai_format(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†ç™¾ç‚¼åŸç”Ÿæ ¼å¼è½¬æ¢ä¸º OpenAI å…¼å®¹æ ¼å¼

        Args:
            payload: ç™¾ç‚¼åŸç”Ÿè¯·æ±‚è½½è·

        Returns:
            Dict: OpenAI æ ¼å¼è½½è·
        """
        messages = payload.get("input", {}).get("messages", [])
        parameters = payload.get("parameters", {})

        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        openai_messages = []
        for msg in messages:
            role = msg.get("role", "user")
            content = msg.get("content")

            # å¦‚æœ content æ˜¯åˆ—è¡¨ï¼ˆå¤šæ¨¡æ€ï¼‰ï¼Œéœ€è¦è½¬æ¢æ ¼å¼
            if isinstance(content, list):
                openai_content = []
                for item in content:
                    if isinstance(item, dict):
                        # æ–‡æœ¬å†…å®¹
                        if "text" in item:
                            openai_content.append(
                                {"type": "text", "text": item["text"]}
                            )
                        # å›¾ç‰‡å†…å®¹ (image æˆ– image_url æ ¼å¼)
                        elif "image" in item:
                            openai_content.append(
                                {
                                    "type": "image_url",
                                    "image_url": {"url": item["image"]},
                                }
                            )
                        elif item.get("type") == "image_url":
                            openai_content.append(item)

                openai_messages.append({"role": role, "content": openai_content})
            else:
                # çº¯æ–‡æœ¬å†…å®¹
                openai_messages.append({"role": role, "content": content})

        # æ„å»º OpenAI æ ¼å¼è½½è·
        openai_payload = {
            "model": payload.get("model", "qwen-vl-max"),
            "messages": openai_messages,
            "max_tokens": parameters.get("max_tokens", 1500),
            "temperature": parameters.get("temperature", 0.7),
            "top_p": parameters.get("top_p", 0.8),
        }

        return openai_payload

    def _parse_response(
        self, response_data: Dict[str, Any], start_time: float
    ) -> ChatCompletionResponse:
        """
        è§£æAPIå“åº”

        Args:
            response_data: APIå“åº”æ•°æ®
            start_time: è¯·æ±‚å¼€å§‹æ—¶é—´

        Returns:
            ChatCompletionResponse: è§£æåçš„å“åº”
        """
        processing_time = time.time() - start_time

        # æå–å“åº”å†…å®¹
        output = response_data.get("output", {})
        choices = output.get("choices", [])

        if not choices:
            raise BailianServiceError("APIå“åº”ä¸­æ²¡æœ‰ç”Ÿæˆå†…å®¹")

        # è·å–ç¬¬ä¸€ä¸ªé€‰æ‹©çš„å†…å®¹
        first_choice = choices[0]
        message = first_choice.get("message", {})
        content = message.get("content", "")

        # æå–ä½¿ç”¨ç»Ÿè®¡
        usage = response_data.get("usage", {})
        tokens_used = usage.get("total_tokens", 0)

        # æå–è¯·æ±‚ID
        request_id = response_data.get("request_id", "")

        # æå–æ¨¡å‹ä¿¡æ¯
        model = response_data.get("model", "unknown")

        return ChatCompletionResponse(
            content=content,
            tokens_used=tokens_used,
            processing_time=processing_time,
            model=model,
            request_id=request_id,
            success=True,
        )

    def _log_request(
        self, payload: Dict[str, Any], context: Optional[AIContext]
    ) -> None:
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        log_data = {
            "action": "bailian_request",
            "model": payload.get("model"),
            "message_count": len(payload.get("input", {}).get("messages", [])),
            "max_tokens": payload.get("parameters", {}).get("max_tokens"),
            "temperature": payload.get("parameters", {}).get("temperature"),
        }

        if context:
            log_data.update(
                {
                    "user_id": context.user_id,
                    "subject": context.subject,
                    "grade_level": context.grade_level,
                    "session_id": context.session_id,
                }
            )

        logger.info("ç™¾ç‚¼APIè¯·æ±‚", extra=log_data)

    async def _call_vl_model_api(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        è°ƒç”¨VLæ¨¡å‹ä¸“ç”¨APIï¼ˆOpenAIå…¼å®¹æ¨¡å¼ï¼‰

        VLæ¨¡å‹ä½¿ç”¨ä¸åŒçš„ç«¯ç‚¹å’Œè¯·æ±‚æ ¼å¼
        """
        # VLæ¨¡å‹ä½¿ç”¨OpenAIå…¼å®¹æ¨¡å¼ç«¯ç‚¹
        url = "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"

        # è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
        openai_payload = self._convert_to_openai_format(payload)

        try:
            response = await self.client.post(url, json=openai_payload)

            # å¤„ç†HTTPé”™è¯¯
            if response.status_code == 401:
                raise BailianAuthError("APIå¯†é’¥æ— æ•ˆæˆ–è¿‡æœŸ")
            elif response.status_code == 429:
                retry_after = response.headers.get("Retry-After", 60)
                raise BailianRateLimitError(f"APIè°ƒç”¨é¢‘ç‡è¿‡é«˜ï¼Œè¯·{retry_after}ç§’åé‡è¯•")
            elif response.status_code >= 400:
                error_text = response.text
                raise BailianServiceError(
                    f"VLæ¨¡å‹HTTPé”™è¯¯ {response.status_code}: {error_text}"
                )

            # è§£æJSONå“åº”
            try:
                response_data = response.json()
            except json.JSONDecodeError:
                raise BailianServiceError(f"VLæ¨¡å‹æ— æ•ˆçš„JSONå“åº”: {response.text}")

            # è½¬æ¢å›æ ‡å‡†æ ¼å¼
            return self._convert_from_openai_format(response_data)

        except httpx.TimeoutException:
            raise BailianTimeoutError(f"VLæ¨¡å‹APIè°ƒç”¨è¶…æ—¶ï¼ˆ{self.timeout}ç§’ï¼‰")
        except httpx.RequestError as e:
            raise BailianServiceError(f"VLæ¨¡å‹ç½‘ç»œè¯·æ±‚é”™è¯¯: {str(e)}") from e

    def _convert_to_openai_format(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        å°†åŸç”ŸAPIæ ¼å¼è½¬æ¢ä¸ºOpenAIå…¼å®¹æ ¼å¼
        """
        model = payload.get("model", "qwen-vl-max")
        messages = payload.get("input", {}).get("messages", [])
        parameters = payload.get("parameters", {})

        openai_payload = {
            "model": model,
            "messages": messages,
            "max_tokens": parameters.get("max_tokens", 1500),
            "temperature": parameters.get("temperature", 0.7),
            "top_p": parameters.get("top_p", 0.8),
        }

        logger.debug(f"è½¬æ¢ä¸ºOpenAIæ ¼å¼: {openai_payload}")
        return openai_payload

    def _convert_from_openai_format(
        self, response_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        å°†OpenAIæ ¼å¼å“åº”è½¬æ¢ä¸ºåŸç”ŸAPIæ ¼å¼
        """
        choices = response_data.get("choices", [])
        if not choices:
            raise BailianServiceError("VLæ¨¡å‹å“åº”ä¸­æ²¡æœ‰choices")

        message = choices[0].get("message", {})
        content = message.get("content", "")

        # æ„å»ºæ ‡å‡†å“åº”æ ¼å¼
        standard_response = {
            "output": {"text": content, "choices": [{"message": {"content": content}}]},
            "usage": response_data.get("usage", {}),
            "request_id": response_data.get("id", ""),
        }

        return standard_response

    def _is_vl_model(self, model: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºVLæ¨¡å‹
        """
        vl_models = ["qwen-vl-max", "qwen-vl-plus", "qwen-vl-max-latest"]
        return model in vl_models

    def _has_multimodal_content(self, messages: List[Dict[str, Any]]) -> bool:
        """
        æ£€æŸ¥æ¶ˆæ¯ä¸­æ˜¯å¦åŒ…å«å¤šæ¨¡æ€å†…å®¹ï¼ˆå›¾ç‰‡ï¼‰

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            bool: æ˜¯å¦åŒ…å«å¤šæ¨¡æ€å†…å®¹
        """
        for message in messages:
            content = message.get("content")
            # æ£€æŸ¥contentæ˜¯å¦ä¸ºæ•°ç»„ï¼ˆå¤šæ¨¡æ€æ ¼å¼ï¼‰
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "image_url":
                        return True
        return False

    def _log_response(
        self, response: ChatCompletionResponse, context: Optional[AIContext]
    ) -> None:
        """è®°å½•å“åº”æ—¥å¿—"""
        log_data = {
            "action": "bailian_response",
            "success": response.success,
            "tokens_used": response.tokens_used,
            "processing_time": round(response.processing_time, 3),
            "model": response.model,
            "request_id": response.request_id,
            "content_length": len(response.content),
        }

        if context:
            log_data.update(
                {
                    "user_id": context.user_id,
                    "session_id": context.session_id,
                }
            )

        if response.success:
            logger.info("ç™¾ç‚¼APIå“åº”æˆåŠŸ", extra=log_data)
        else:
            log_data["error_message"] = response.error_message
            logger.error("ç™¾ç‚¼APIå“åº”å¤±è´¥", extra=log_data)

    async def __aenter__(self):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        await self.client.aclose()

    async def close(self):
        """å…³é—­HTTPå®¢æˆ·ç«¯"""
        await self.client.aclose()
        logger.info("ç™¾ç‚¼æœåŠ¡å·²å…³é—­")


# åˆ›å»ºå…¨å±€æœåŠ¡å®ä¾‹
_bailian_service: Optional[BailianService] = None


def get_bailian_service() -> BailianService:
    """
    è·å–ç™¾ç‚¼æœåŠ¡å•ä¾‹

    Returns:
        BailianService: ç™¾ç‚¼æœåŠ¡å®ä¾‹
    """
    global _bailian_service
    if _bailian_service is None:
        _bailian_service = BailianService()
    return _bailian_service


async def close_bailian_service():
    """å…³é—­å…¨å±€ç™¾ç‚¼æœåŠ¡å®ä¾‹"""
    global _bailian_service
    if _bailian_service:
        await _bailian_service.close()
        _bailian_service = None
